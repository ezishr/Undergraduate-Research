{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK\n",
    "\n",
    "- Create comparison func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ezishr/anaconda3/envs/python_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ezishr/Library/CloudStorage/OneDrive-UniversityofCincinnati/Undergraduate Research/Check points/Big Bench Hard\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../Modules/')\n",
    "sys.path.append('../../Modules/Processors from Prof')\n",
    "from Packages import *\n",
    "from My_Json_processor import *\n",
    "from My_Utilities_processor import *\n",
    "\n",
    "# Import processors from Prof\n",
    "from ipynb.fs.full.Utilities import *\n",
    "from ipynb.fs.full.Json_Processor import *\n",
    "from ipynb.fs.full.CSV_Processor import *\n",
    "\n",
    "from ipynb.fs.full.My_Reading_Level import *\n",
    "from ipynb.fs.full.Word_Processing import *\n",
    "from Wordcloud import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boolean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get & Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   input          250 non-null    object\n",
      " 1   target         250 non-null    bool  \n",
      " 2   gemini_output  250 non-null    bool  \n",
      "dtypes: bool(2), object(1)\n",
      "memory usage: 2.6+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "      <th>gemini_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not ( True ) and ( True ) is</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True and not not ( not False ) is</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not True or False or ( False ) is</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False or not ( True ) and False is</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True or not False and True and False is</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     input  target  gemini_output\n",
       "0             not ( True ) and ( True ) is   False          False\n",
       "1        True and not not ( not False ) is    True           True\n",
       "2        not True or False or ( False ) is   False           True\n",
       "3       False or not ( True ) and False is   False          False\n",
       "4  True or not False and True and False is    True          False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemini_boolean = pd.read_csv('gemini_boolean_df.csv')\n",
    "print(gemini_boolean.info())\n",
    "\n",
    "gemini_boolean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   input         250 non-null    object\n",
      " 1   target        250 non-null    bool  \n",
      " 2   llama_output  250 non-null    object\n",
      "dtypes: bool(1), object(2)\n",
      "memory usage: 4.3+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "      <th>llama_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not ( True ) and ( True ) is</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True and not not ( not False ) is</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not True or False or ( False ) is</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False or not ( True ) and False is</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True or not False and True and False is</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     input  target llama_output\n",
       "0             not ( True ) and ( True ) is   False        False\n",
       "1        True and not not ( not False ) is    True         True\n",
       "2        not True or False or ( False ) is   False         True\n",
       "3       False or not ( True ) and False is   False        False\n",
       "4  True or not False and True and False is    True        False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_boolean = pd.read_csv('groq_boolean_df.csv')\n",
    "print(groq_boolean.info())\n",
    "groq_boolean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in gemini_boolean.columns.tolist():\n",
    "    gemini_boolean[col] = gemini_boolean[col].astype(str).str.lower().str.strip()\n",
    "\n",
    "\n",
    "for col in groq_boolean.columns.tolist():\n",
    "    groq_boolean[col] = groq_boolean[col].astype(str).str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_correct_gemini = gemini_boolean['gemini_output'].astype(str).str.strip().str.lower() == gemini_boolean['target'].astype(str).str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     197\n",
       "False     53\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolean_correct_gemini.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Gemini is:\n",
      "True     197\n",
      "False     53\n",
      "Name: count, dtype: int64 \n",
      "Accuracy rate: 0.788\n",
      "\n",
      "\n",
      "Accuracy of Llama-3.3 is:\n",
      "True     155\n",
      "False     95\n",
      "Name: count, dtype: int64 \n",
      "Accuracy rate: 0.62\n"
     ]
    }
   ],
   "source": [
    "comparison(gemini_boolean, 'target', 'gemini_output', 'Gemini')\n",
    "print(\"\\n\")\n",
    "comparison(groq_boolean, 'target', 'llama_output', 'Llama-3.3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Flesch-Kincaid Grade': -1.2,\n",
       " 'Flesch-Kincaid Reading Ease': 115.13,\n",
       " 'GunningFog': 2.8,\n",
       " 'ColemanLiau': -0.87,\n",
       " 'ARI': -1.2,\n",
       " 'SMOG': 0.0,\n",
       " 'LIX': 7.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Reading_Level.compute_readability_indices(\"Big Bench Hard\", gemini_boolean.loc[1,'input'], file_name = \"boolean1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal_judgement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_causal = pd.read_csv('gemini_causal_judgement.csv')\n",
    "print(gemini_causal.info())\n",
    "gemini_causal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_causal = pd.read_csv('groq_causal_judgement.csv')\n",
    "print(groq_causal.info())\n",
    "groq_causal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_causal = reduntdant_characters(gemini_causal, ['gemini_output'], [\".\"])\n",
    "groq_causal = reduntdant_characters(groq_causal, ['llama_output'], [\".\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in gemini_causal.columns.tolist():\n",
    "    gemini_causal[col] = gemini_causal[col].astype(str).str.lower().str.strip()\n",
    "\n",
    "\n",
    "for col in groq_causal.columns.tolist():\n",
    "    groq_causal[col] = groq_causal[col].astype(str).str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison(gemini_causal, 'target', 'gemini_output', 'Gemini')\n",
    "print(\"\\n\")\n",
    "comparison(groq_causal, 'target', 'llama_output', 'Llama-3.3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disambiguation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get & Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_disambiguation = pd.read_csv('gemini_disambiguation.csv')\n",
    "gemini_disambiguation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_disambiguation = pd.read_csv('groq_disambiguation_qa.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean redundant characters\n",
    "gemini_disambiguation['target'] = gemini_disambiguation['target'].str.replace('(',\"\").str.replace(')',\"\")\n",
    "gemini_disambiguation['gemini_output'] = gemini_disambiguation['gemini_output'].str.replace('(',\"\").str.replace(')',\"\")\n",
    "\n",
    "# Clean redundant characters\n",
    "groq_disambiguation['target'] = groq_disambiguation['target'].str.replace('(',\"\").str.replace(')',\"\")\n",
    "groq_disambiguation['llama_output'] = groq_disambiguation['llama_output'].str.replace('(',\"\").str.replace(')',\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in gemini_disambiguation.columns.tolist():\n",
    "    gemini_disambiguation[col] = gemini_disambiguation[col].astype(str).str.lower().str.strip()\n",
    "\n",
    "for col in groq_disambiguation.columns.tolist():\n",
    "    groq_disambiguation[col] = groq_disambiguation[col].astype(str).str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geometric_shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get & Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_geometric_shapes = pd.read_csv('gemini_geomnetric_shapes.csv')\n",
    "gemini_geometric_shapes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_geometric = pd.read_csv(\"groq_geomnetric_shapes.csv\")\n",
    "groq_geometric.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean redundant characters\n",
    "gemini_geometric_shapes['target'] = gemini_geometric_shapes['target'].str.replace('(',\"\").str.replace(')',\"\")\n",
    "gemini_geometric_shapes['gemini_output'] = gemini_geometric_shapes['gemini_output'].str.replace('(',\"\").str.replace(')',\"\")\n",
    "\n",
    "# Clean redundant characters\n",
    "groq_geometric['target'] = groq_geometric['target'].str.replace('(',\"\").str.replace(')',\"\")\n",
    "groq_geometric['llama_output'] = groq_geometric['llama_output'].str.replace('(',\"\").str.replace(')',\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in gemini_geometric_shapes.columns.tolist():\n",
    "    gemini_geometric_shapes[col] = gemini_geometric_shapes[col].astype(str).str.lower().str.strip()\n",
    "\n",
    "for col in groq_geometric.columns.tolist():\n",
    "    groq_geometric[col] = groq_geometric[col].astype(str).str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperbaton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get & Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_hyperbaton = pd.read_csv('gemini_hyperbaton.csv')\n",
    "gemini_hyperbaton = reduntdant_characters(gemini_hyperbaton, col_names=['target', 'gemini_output'], characters=['(', ')'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_hyperbaton = pd.read_csv('groq_hyperbaton.csv')\n",
    "groq_hyperbaton = reduntdant_characters(groq_hyperbaton, col_names=['target', 'llama_output'], characters=['(', ')'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean redundant characters\n",
    "gemini_hyperbaton['target'] = gemini_hyperbaton['target'].str.replace('(',\"\").str.replace(')',\"\")\n",
    "gemini_hyperbaton['gemini_output'] = gemini_hyperbaton['gemini_output'].str.replace('(',\"\").str.replace(')',\"\")\n",
    "\n",
    "# Clean redundant characters\n",
    "groq_hyperbaton['target'] = groq_hyperbaton['target'].str.replace('(',\"\").str.replace(')',\"\")\n",
    "groq_hyperbaton['llama_output'] = groq_hyperbaton['llama_output'].str.replace('(',\"\").str.replace(')',\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logical deduction five"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get & Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_logical_five = pd.read_csv('gemini_logical_deduction_five.csv')\n",
    "groq_logical_five = pd.read_csv('groq_logical_five.csv')\n",
    "gemini_logical_five.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_logical_five = reduntdant_characters(gemini_logical_five, col_names=['target', 'gemini_output'], characters=['(', ')'])\n",
    "groq_logical_five = reduntdant_characters(groq_logical_five, col_names=['target', 'llama_output'], characters=['(', ')'])\n",
    "\n",
    "for col in gemini_logical_five.columns.tolist():\n",
    "    gemini_logical_five[col] = gemini_logical_five[col].astype(str).str.lower().str.strip()\n",
    "\n",
    "for col in groq_logical_five.columns.tolist():\n",
    "    groq_logical_five[col] = groq_logical_five[col].astype(str).str.lower().str.strip() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logical deduction seven"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get & Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_logical_seven = pd.read_csv('gemini_logical_deduction_seven.csv')\n",
    "groq_logical_seven = pd.read_csv('groq_logical_seven.csv')\n",
    "gemini_logical_seven.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_logical_seven = reduntdant_characters(gemini_logical_seven, col_names=['target', 'gemini_output'], characters=['(', ')'])\n",
    "groq_logical_seven = reduntdant_characters(groq_logical_seven, col_names=['target', 'llama_output'], characters=['(', ')'])\n",
    "\n",
    "for col in gemini_logical_seven.columns.tolist():\n",
    "    gemini_logical_seven[col] = gemini_logical_seven[col].astype(str).str.lower().str.strip()\n",
    "\n",
    "for col in groq_logical_seven.columns.tolist():\n",
    "    groq_logical_seven[col] = groq_logical_seven[col].astype(str).str.lower().str.strip() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logical deduction three"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get & Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_logical_three = pd.read_csv('gemini_logical_deduction_three.csv')\n",
    "groq_logical_three = pd.read_csv('groq_logical_three.csv')\n",
    "\n",
    "gemini_logical_three = reduntdant_characters(gemini_logical_three, col_names=['target', 'gemini_output'], characters=['(', ')'])\n",
    "groq_logical_three = reduntdant_characters(groq_logical_three, col_names=['target', 'llama_output'], characters=['(', ')'])\n",
    "\n",
    "for col in gemini_logical_three.columns.tolist():\n",
    "    gemini_logical_three[col] = gemini_logical_three[col].astype(str).str.lower().str.strip()\n",
    "\n",
    "for col in groq_logical_three.columns.tolist():\n",
    "    groq_logical_three[col] = groq_logical_three[col].astype(str).str.lower().str.strip() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_logical_three.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get & Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_movie = pd.read_csv('gemini_movie_recommendation.csv')\n",
    "groq_movie = pd.read_csv('groq_movie_recommendation.csv')\n",
    "\n",
    "gemini_movie.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"None of the\"\n",
    "gemini_movie['matching'] = gemini_movie['gemini_output'].apply(lambda x: \"None\" if re.match(pattern, x) else \"False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_movie['matching'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_movie.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_options = gemini_movie[gemini_movie['matching'] == \"False\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_options['gemini_output'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_options.loc[false_options['gemini_output'] ==  \"* **The Fugitive:**  None of the options are particularly similar to The Fugitive's thriller/chase aspects.\\n\\n* **Terminator 2: Judgment Day:** None of the options are close matches to T2's sci-fi action.\\n\\n* **Aladdin:** (C) The Lion King is a similar animated Disney musical.\\n\\n* **Toy Story:** None of the options are particularly similar to Toy Story's CGI animated adventure.\\n\\n\\nTherefore, the best answer is **(C) The Lion King** due to its similarity to Aladdin.\", 'matching'] = \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_options['matching'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"is\\s*\\((.*?)\\)\"\n",
    "false_options1 = false_options[false_options['matching']=='False'].copy()\n",
    "\n",
    "false_options1['matching'] = false_options1['gemini_output'].apply(lambda x: re.search(pattern, x).group(1) if re.search(pattern, x) else \"False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_options1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_options1['matching'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in false_options.index.tolist():\n",
    "    gemini_movie.loc[idx, 'matching'] = false_options.loc[idx, 'matching']\n",
    "\n",
    "for idx in false_options1.index.tolist():\n",
    "    gemini_movie.loc[idx, 'matching'] = false_options1.loc[idx, 'matching']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_movie['matching'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_movie[gemini_movie['matching']==\"False\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The best fit from the options is **(C) Independence Day**. While not a perfect match for any single film, Independence Day shares the blockbuster action spectacle of *Mission Impossible* and the high-stakes, world-saving scenario that's present in *Jurassic Park*. The other options are significantly different in tone and genre.\"\n",
    "pattern = r\"\\*\\*\\(([^)]+)\\)\"\n",
    "\n",
    "print(re.search(pattern, text).group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_options2 = gemini_movie[gemini_movie['matching']==\"False\"].copy()\n",
    "\n",
    "pattern = r\"\\*\\*\\(([^)]+)\\)\"\n",
    "false_options2['matching'] = false_options2['gemini_output'].apply(lambda x: re.search(pattern, x).group(1) if re.search(pattern, x) else \"False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in false_options2.index.tolist():\n",
    "    gemini_movie.loc[i, 'matching'] = false_options2.loc[i, 'matching']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_movie['gemini_output'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_movie['gemini_output'] = gemini_movie['matching']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_movie.drop(columns=['matching'], inplace=True)\n",
    "gemini_movie.to_csv(\"gemini_movie_recommendation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multistep arithmetic two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get & Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_multistep_two = pd.read_csv('gemini_multistep_arithmetic_two.csv')\n",
    "gemini_multistep_two.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get & Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_navigate = pd.read_csv('gemini_navigate.csv')\n",
    "gemini_navigate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object_counting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get & Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_object = pd.read_csv('gemini_object_counting.csv')\n",
    "gemini_object.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Penguins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get & Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_penguins = pd.read_csv('gemini_penguins_in_a_table.csv')\n",
    "gemini_penguins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_penguins['gemini_output'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"\\((.*?)\\)\"\n",
    "for idx in gemini_penguins.index.tolist():\n",
    "    gemini_penguins.loc[idx, 'gemini_output'] = re.search(pattern, gemini_penguins.loc[idx, 'gemini_output']).group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_penguins['gemini_output'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reasoning_colored obejcts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get & Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_reasoning_objects = pd.read_csv('gemini_reasoning_colored_objects.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_reasoning_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_reasoning_objects['gemini_output'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"\\((.*?)\\)\"\n",
    "gemini_reasoning_objects['gemini_output'] = gemini_reasoning_objects['gemini_output'].apply(lambda x: re.search(pattern, x).group(1) if re.search(pattern, x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_reasoning_objects['gemini_output'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_reasoning_objects[gemini_reasoning_objects['gemini_output'] == 'cup, stress ball, and envelope']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import google.generativeai as genai\n",
    "\n",
    "# os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyCM-GWMhMPoBZpvlXWqKr5nKnY02OIVdf4\"\n",
    "\n",
    "# genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    system_instruction=\"Only answer one of the provided options.\"\n",
    ")\n",
    "\n",
    "response = model.generate_content(\"On the desk, there are three black sheets of paper, two black envelopes, one brown cup, one brown stress ball, one brown envelope, one brown sheet of paper, and one black cup. If I remove all the brown objects from the desk, how many envelopes remain on it?\\nOptions:\\n(A) zero\\n(B) one\\n(C) two\\n(D) three\\n(E) four\\n(F) five\\n(G) six\\n(H) seven\\n(I) eight\\n(J) nine\\n(K) ten\\n(L) eleven\\n(M) twelve\\n(N) thirteen\\n(O) fourteen\\n(P) fifteen\\n(Q) sixteen\t\")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_reasoning_objects.loc[238,\"gemini_output\"] = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_reasoning_objects.to_csv('gemini_reasoning_colored_objects.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ruin Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get & Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_ruin_names = pd.read_csv('gemini_ruin_names.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_ruin_names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_ruin_names['gemini_output'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = gemini_ruin_names.copy()\n",
    "sample['match'] = None\n",
    "\n",
    "pattern = \"\\((.*?)\\)\"\n",
    "sample['match'] =  sample['gemini_output'].apply(lambda x: re.search(pattern, x).group(1) if re.search(pattern, x) else \"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['match'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.loc[sample['match'] == 'A, B, C, or D','match'] = \"None\"\n",
    "sample.loc[sample['match']=='A, B, C, D','match'] = \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_ruin_names['gemini_output'] = sample['match']\n",
    "gemini_ruin_names['gemini_output'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_ruin_names.to_csv(\"gemini_ruin_names.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salient detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get & Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_salient_detection = pd.read_csv(\"gemini_salient_detection.csv\")\n",
    "gemini_salient_detection.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_salient_detection['gemini_output'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_salient_detection.loc[gemini_salient_detection['gemini_output'] ==        'A\\n\\nThe translation incorrectly changes \"drittgrößte\" (third largest) to \"third smallest\".  This is an error in modifiers or adjectives.','gemini_output'] = \"A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"\\((.*?)\\)\"\n",
    "gemini_salient_detection['match'] = gemini_salient_detection['gemini_output'].apply(lambda x: re.search(pattern, x).group(1) if re.search(pattern, x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_salient_detection['gemini_output'] = gemini_salient_detection['match']\n",
    "gemini_salient_detection.drop(columns=['match'], inplace=True)\n",
    "gemini_salient_detection.to_csv(\"gemini_salient_detection.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get & Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_snarks = pd.read_csv('gemini_snarks.csv')\n",
    "gemini_snarks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_snarks['match'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"\\((.*?)\\)\"\n",
    "gemini_snarks['match'] = gemini_snarks['gemini_output'].apply(lambda x: re.search(pattern, x).group(1) if re.search(pattern, x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_snarks.loc[gemini_snarks['gemini_output'].str.startswith(\"A\"), \"match\"] = \"A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_snarks['gemini_output'] = gemini_snarks['match']\n",
    "gemini_snarks.drop(columns=['match'], inplace=True)\n",
    "gemini_snarks.to_csv(\"gemini_snarks.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sports Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get & Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_sports = pd.read_csv('gemini_sports_understanding.csv')\n",
    "gemini_sports.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_sports['gemini_output'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get & Clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_temporal = pd.read_csv(\"gemini_temporal_sequences.csv\")\n",
    "gemini_temporal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_temporal['match'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gemini_temporal['match'] = None\n",
    "# gemini_temporal.loc[gemini_temporal['gemini_output'].str.startswith(\"None\"), \"match\"] = \"None\"\n",
    "gemini_temporal.loc[gemini_temporal['gemini_output'].str.startswith(\"C\"), \"match\"] = \"A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"\\((.*?)\\)\"\n",
    "gemini_temporal['match'] = gemini_temporal['gemini_output'].apply(lambda x: re.search(pattern, x).group(1) if re.search(pattern, x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_temporal.to_csv(\"gemini_temporal_sequences.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track three - LỖI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get & Clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_track_three = pd.read_csv(\"gemini_track_three.csv\")\n",
    "print(gemini_track_three.head())\n",
    "\n",
    "print(gemini_track_three['gemini_output'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track five"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get & Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_track_five = pd.read_csv(\"gemini_tracking_five.csv\")\n",
    "gemini_track_five.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gemini_track_five['gemini_output'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"\\(\\w\\)\"\n",
    "gemini_track_five['match'] = gemini_track_five['gemini_output'].apply(lambda x: re.findall(pattern, x)[0] if re.search(pattern, x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_track_five['match'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_track_five[gemini_track_five['match'] == '(E)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_track_five.to_csv(\"gemini_tracking_five.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track seven"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get & Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_track_seven = pd.read_csv(\"gemini_tracking_seven.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_track_seven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"\\(\\w\\)\"\n",
    "gemini_track_seven['match'] = gemini_track_seven['gemini_output'].apply(lambda x: re.findall(pattern, x)[0] if re.search(pattern, x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_track_seven['match'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_track_seven.loc[216,\"match\"] = \"(G)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_track_seven.to_csv(\"gemini_tracking_seven.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web of lies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get & Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_web = pd.read_csv(\"gemini_web_of_lies.csv\")\n",
    "gemini_web.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get & Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_word_sorting = pd.read_csv(\"gemini_word_sorting.csv\")\n",
    "gemini_word_sorting.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gemini_word_sorting.loc[1, 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"artillery\\nbainite\\ndoris\\nfda\\nharm\\nincongruous\\nmonkey\\nprosody\\nvegetate\\nvivian\"\n",
    "text.replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_word_sorting['gemini_output'] = gemini_word_sorting['gemini_output'].apply(lambda x: x.replace(\"\\n\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_word_sorting.loc[gemini_word_sorting['gemini_output'].str.startswith(\"List\"),'gemini_output'] = \"syndrome therefrom\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This is an example text to analyze readability scores.\"\n",
    "readability_score = textstat.flesch_reading_ease(text)\n",
    "print(\"Flesch Reading Ease Score:\", readability_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.Reading_Level import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"This is an example text to analyze readability scores.\"\n",
    "print(\"Flesch Reading Ease Score:\", Reading_Level.compute_readability_indices(benchmark_name= \"Big Bench Hard\", text = text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.Word_Processing import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Word_Processing.split_text(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Word_Processing.load_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Word_Processing.compute_word_frequency(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Word_Processing.compute_longest_words(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Wordcloud import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = Wordcloud()\n",
    "wc.generate(text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduntdant_characters(data, col_names, characters):\n",
    "    for col in col_names:\n",
    "        for character in characters:\n",
    "            data[col] = data[col].str.replace(character,\"\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_hyperbaton = pd.read_csv('gemini_hyperbaton.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = reduntdant_characters(gemini_hyperbaton, ['target', 'gemini_output'], '(')\n",
    "sample = reduntdant_characters(gemini_hyperbaton, ['target', 'gemini_output'], ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
