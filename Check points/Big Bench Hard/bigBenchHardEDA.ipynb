{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ezishr/anaconda3/envs/python_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../Modules/')\n",
    "sys.path.append('../../Modules/Processors from Prof')\n",
    "from Packages import *\n",
    "from My_Json_processor import *\n",
    "from My_Utilities_processor import *\n",
    "\n",
    "# Import processors from Prof\n",
    "from ipynb.fs.full.Utilities import *\n",
    "from ipynb.fs.full.Json_Processor import *\n",
    "from ipynb.fs.full.CSV_Processor import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get GEMINI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "# os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyAP8QMlHxlLhX518vKYJbd3bQuKZlb6pD0\"\n",
    "os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyCM-GWMhMPoBZpvlXWqKr5nKnY02OIVdf4\"\n",
    "\n",
    "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get GROQ API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "\n",
    "# os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
    "\n",
    "client = Groq(\n",
    "    api_key=os.environ['GROQ_API_KEY'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to generate GEMINI Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = Big_Bench_Json_Processor_my('Big Bench Hard', 'boolean_expressions.json').convert_df().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD\n",
    "\n",
    "model=genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-flash\",\n",
    "  system_instruction=\"You only answer True or False to the following questions.\",)\n",
    "\n",
    "sample['gemini_output'] = None\n",
    "\n",
    "for i in range(len(sample)):\n",
    "    response = model.generate_content(sample['input'][i])\n",
    "    print(response.text)\n",
    "    sample.loc[i, 'gemini_output'] = response.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = []\n",
    "\n",
    "for i in range(len(sample)):\n",
    "    content.append(sample['input'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(\n",
    "    model_name = \"gemini-1.5-flash\",\n",
    "    system_instruction=\"You only answer True or False to the following questions.\",\n",
    ")\n",
    "\n",
    "\n",
    "response = model.generate_content(content)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "GROQ\n",
    "\n",
    "The function is to generate GROQ answers for the given data.\n",
    "\n",
    "@params: data(initial dataframe), system_message(message for Gemini system)\n",
    "@return: sample(dataframe with gemini_output column)\n",
    "\"\"\"\n",
    "\n",
    "def groq(data, system_message, model_name):\n",
    "\n",
    "    import time\n",
    "    total_requests = 0\n",
    "    successful_requests = 0\n",
    "    client = Groq(api_key=os.environ['GROQ_API_KEY'],)\n",
    "\n",
    "    sample = data.copy()\n",
    "    sample[model_name] = None\n",
    "\n",
    "\n",
    "    for i in range(len(sample)):\n",
    "        success = False\n",
    "        retries = 3\n",
    "\n",
    "        while not success and retries > 0:\n",
    "            try:\n",
    "                total_requests += 1\n",
    "                \n",
    "                # Make a request to the GROQ API\n",
    "                chat_completion = client.chat.completions.create(\n",
    "                    messages=[\n",
    "                        {\n",
    "                            \"role\":\"user\",\n",
    "                            \"content\": sample.loc[i, 'input']\n",
    "                        },\n",
    "                        {\n",
    "                            'role': 'system',\n",
    "                            'content': system_message\n",
    "                        }\n",
    "                    ],\n",
    "                    model = model_name\n",
    "                )\n",
    "\n",
    "                response = chat_completion.choices[0].message.content\n",
    "\n",
    "                sample.loc[i, model_name] = response.strip()\n",
    "                success = True\n",
    "                successful_requests += 1\n",
    "                # print(response)\n",
    "                time.sleep(5)\n",
    "\n",
    "            except Exception as e:\n",
    "                # print(f\"Error: {e}\")\n",
    "                retries -= 1\n",
    "                time.sleep(5)\n",
    "                total_requests += 1\n",
    "\n",
    "    print(f\"Total requests made: {total_requests}\")\n",
    "    print(f\"Successful requests: {successful_requests}\")\n",
    "\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "GROQ\n",
    "\n",
    "The function is to generate GROQ answers for the given data ROWS.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def groq_line_generate(raw_dataset, output_dataset, start_idx, end_idx, system_message, model_name):\n",
    "    sample = raw_dataset.loc[start_idx:end_idx, ].copy()\n",
    "    sample.reset_index(drop=True, inplace=True)\n",
    "    groq_sample = groq(sample, system_message, model_name)\n",
    "    output_dataset.loc[start_idx:end_idx, \"llama_output\"] = groq_sample[model_name].values\n",
    "    return output_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "GEMINI\n",
    "\n",
    "The function is to generate Gemini answers for the given data.\n",
    "\n",
    "@params: data(initial dataframe), system_message(message for Gemini system)\n",
    "@return: sample(dataframe with gemini_output column)\n",
    "\"\"\"\n",
    "\n",
    "def gemini_generator(data, system_message):\n",
    "\n",
    "    import time\n",
    "    total_requests = 0\n",
    "    successful_requests = 0\n",
    "\n",
    "\n",
    "    model=genai.GenerativeModel(\n",
    "        model_name=\"gemini-1.5-flash\",\n",
    "        system_instruction=system_message,\n",
    "    )\n",
    "\n",
    "    sample = data.copy()\n",
    "    sample['gemini_output'] = None\n",
    "\n",
    "    for i in range(len(sample)):\n",
    "        success = False\n",
    "        retries = 3\n",
    "\n",
    "        while not success and retries > 0:\n",
    "            try:\n",
    "                total_requests += 1\n",
    "\n",
    "                # Make API request\n",
    "                response = model.generate_content(sample['input'][i])\n",
    "                # print(response.text)\n",
    "                sample.loc[i, 'gemini_output'] = response.text.strip()\n",
    "                success = True\n",
    "                successful_requests += 1\n",
    "                time.sleep(5)\n",
    "\n",
    "            except Exception as e:\n",
    "                # print(f\"Error: {e}\")\n",
    "                retries -= 1\n",
    "                time.sleep(5)\n",
    "                total_requests += 1\n",
    "\n",
    "    print(f\"Total requests made: {total_requests}\")\n",
    "    print(f\"Successful requests: {successful_requests}\")\n",
    "\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The function is to export the dataframe to a csv file.\n",
    "\n",
    "@params: folder_name(name of the folder), df(dataframe)\n",
    "@return: True if the dataframe is exported successfully, False otherwise\n",
    "\"\"\"\n",
    "\n",
    "def df_to_csv(folder_name, df, file_name, output_col):\n",
    "    base_path = r'/Users/ezishr/Library/CloudStorage/OneDrive-UniversityofCincinnati/Undergraduate Research/Check points'\n",
    "    if (df[output_col].isnull().sum() == 0) or (df[output_col].isnull().sum() == 0):\n",
    "        file_path = os.path.join(base_path, folder_name, f'{file_name}.csv')\n",
    "        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "        df.to_csv(file_path, index=False)\n",
    "        print(f\"DataFrame exported successfully to {file_path}!\")\n",
    "    else:\n",
    "        print(\"Export failed: DataFrame contains null values in 'gemini_output'.\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Testing - boolean_expressions.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_df = Big_Bench_Json_Processor_my('Big Bench Hard', 'boolean_expressions.json').convert_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(boolean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GEMINI applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample0_10 = boolean_df.head(10)\n",
    "gemini_sample0_10 = gemini_generator(sample0_10, \"You only answer True or False to the following questions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "total_requests = 0\n",
    "successful_requests = 0\n",
    "\n",
    "\n",
    "model=genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-flash\",\n",
    "  system_instruction=\"You only answer True or False to the following questions.\",\n",
    "  )\n",
    "\n",
    "sample2 = boolean_df.copy()\n",
    "sample2['gemini_output'] = None\n",
    "\n",
    "for i in range(len(sample2)):\n",
    "    success = False\n",
    "    retries = 3\n",
    "\n",
    "    while not success and retries > 0:\n",
    "        try:\n",
    "            total_requests += 1\n",
    "\n",
    "            # Make API request\n",
    "            response = model.generate_content(sample2['input'][i])\n",
    "            # print(response.text)\n",
    "            sample2.loc[i, 'gemini_output'] = response.text.strip()\n",
    "            success = True\n",
    "            successful_requests += 1\n",
    "            time.sleep(5)\n",
    "\n",
    "        except Exception as e:\n",
    "            # print(f\"Error: {e}\")\n",
    "            retries -= 1\n",
    "            time.sleep(5)\n",
    "            total_requests += 1 \n",
    "\n",
    "\n",
    "\n",
    "print(f\"Total requests made: {total_requests}\")\n",
    "print(f\"Successful requests: {successful_requests}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample2['gemini_output'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "\n",
    "model=genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-flash\",\n",
    "  system_instruction=\"You only answer True or False to the following questions.\",\n",
    "  )\n",
    "\n",
    "\n",
    "total_requests = 0\n",
    "\n",
    "successful_requests = 0\n",
    "unsuccesful_requests = 0\n",
    "\n",
    "sample3 = boolean_df.copy()\n",
    "sample3['gemini_output'] = None\n",
    "\n",
    "while sample3['gemini_output'].isna().sum() > 0:\n",
    "    for i in range(len(sample2)):\n",
    "        if sample3['gemini_output'][i] == None:\n",
    "            try:\n",
    "                response = model.generate_content(sample2['input'][i])\n",
    "                # print(response.text)\n",
    "                sample3.loc[i, 'gemini_output'] = response.text.strip()\n",
    "                successful_requests += 1\n",
    "                time.sleep(5)\n",
    "\n",
    "            except Exception as e:\n",
    "                # print(f\"Error: {e}\")\n",
    "                unsuccesful_requests += 1\n",
    "                time.sleep(5)\n",
    "\n",
    "            total_requests += 1\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "print(f\"Successful requests: {successful_requests}\")\n",
    "print(f\"Unsuccessful requests: {unsuccesful_requests}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_boolean_df = sample2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_boolean_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_csv(\"Big Bench Hard\", gemini_boolean_df, file_name = \"gemini_boolean_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GROQ Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_df.info()\n",
    "boolean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_boolean_df = boolean_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_boolean_df = groq_line_generate(raw_dataset = boolean_df, output_dataset = groq_boolean_df, start_idx=11, end_idx=19, system_message=\"You only answer True or False to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_boolean_df = groq_line_generate(raw_dataset = boolean_df, output_dataset = groq_boolean_df, start_idx=20, end_idx=29, system_message=\"You only answer True or False to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_boolean_df = groq_line_generate(raw_dataset = boolean_df, output_dataset = groq_boolean_df, start_idx=30, end_idx=39, system_message=\"You only answer True or False to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_boolean_df = groq_line_generate(raw_dataset = boolean_df, output_dataset = groq_boolean_df, start_idx=40, end_idx=49, system_message=\"You only answer True or False to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_boolean_df = groq_line_generate(raw_dataset = boolean_df, output_dataset = groq_boolean_df, start_idx=50, end_idx=59, system_message=\"You only answer True or False to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_boolean_df = groq_line_generate(raw_dataset = boolean_df, output_dataset = groq_boolean_df, start_idx=60, end_idx=69, system_message=\"You only answer True or False to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_boolean_df = groq_line_generate(raw_dataset = boolean_df, output_dataset = groq_boolean_df, start_idx=70, end_idx=79, system_message=\"You only answer True or False to the following questions.\", model_name=\"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_boolean_df = groq_line_generate(raw_dataset = boolean_df, output_dataset = groq_boolean_df, start_idx=80, end_idx=89, system_message=\"You only answer True or False to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_boolean_df = groq_line_generate(raw_dataset = boolean_df, output_dataset = groq_boolean_df, start_idx=90, end_idx=99, system_message=\"You only answer True or False to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_boolean_df = groq_line_generate(raw_dataset = boolean_df, output_dataset = groq_boolean_df, start_idx=100, end_idx=109, system_message=\"You only answer True or False to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_boolean_df = groq_line_generate(raw_dataset = boolean_df, output_dataset = groq_boolean_df, start_idx=110, end_idx=119, system_message=\"You only answer True or False to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_boolean_df = groq_line_generate(raw_dataset = boolean_df, output_dataset = groq_boolean_df, start_idx=120, end_idx=129, system_message=\"You only answer True or False to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_boolean_df = groq_line_generate(raw_dataset = boolean_df, output_dataset = groq_boolean_df, start_idx=130, end_idx=139, system_message=\"You only answer True or False to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_boolean_df = groq_line_generate(raw_dataset = boolean_df, output_dataset = groq_boolean_df, start_idx=140, end_idx=149, system_message=\"You only answer True or False to the following questions.\", model_name=\"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_boolean_df = groq_line_generate(raw_dataset = boolean_df, output_dataset = groq_boolean_df, start_idx=150, end_idx=159, system_message=\"You only answer True or False to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_boolean_df = groq_line_generate(raw_dataset = boolean_df, output_dataset = groq_boolean_df, start_idx=160, end_idx=169, system_message=\"You only answer True or False to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_boolean_df = groq_line_generate(raw_dataset = boolean_df, output_dataset = groq_boolean_df, start_idx=170, end_idx=179, system_message=\"You only answer True or False to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_boolean_df = groq_line_generate(raw_dataset = boolean_df, output_dataset = groq_boolean_df, start_idx=180, end_idx=189, system_message=\"You only answer True or False to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_boolean_df = groq_line_generate(raw_dataset = boolean_df, output_dataset = groq_boolean_df, start_idx=190, end_idx=199, system_message=\"You only answer True or False to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_boolean_df = groq_line_generate(raw_dataset = boolean_df, output_dataset = groq_boolean_df, start_idx=200, end_idx=209, system_message=\"You only answer True or False to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_boolean_df = groq_line_generate(raw_dataset = boolean_df, output_dataset = groq_boolean_df, start_idx=210, end_idx=219, system_message=\"You only answer True or False to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_boolean_df = groq_line_generate(raw_dataset = boolean_df, output_dataset = groq_boolean_df, start_idx=220, end_idx=229, system_message=\"You only answer True or False to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_boolean_df = groq_line_generate(raw_dataset = boolean_df, output_dataset = groq_boolean_df, start_idx=230, end_idx=239, system_message=\"You only answer True or False to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_boolean_df = groq_line_generate(raw_dataset = boolean_df, output_dataset = groq_boolean_df, start_idx=240, end_idx=250, system_message=\"You only answer True or False to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_boolean_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_csv(\"Big Bench Hard\", groq_boolean_df, file_name = \"groq_boolean_df\", output_col = \"llama_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Testing - causal_judgement.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_judgement = Big_Bench_Json_Processor_my('Big Bench Hard', 'causal_judgement.json').convert_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_judgement.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GEMINI Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "total_requests = 0\n",
    "successful_requests = 0\n",
    "\n",
    "\n",
    "model=genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-flash\",\n",
    "  system_instruction=\"You only answer Yes or No to the following questions.\",\n",
    "  )\n",
    "\n",
    "sample = causal_judgement.copy()\n",
    "sample['gemini_output'] = None\n",
    "\n",
    "for i in range(len(sample)):\n",
    "    success = False\n",
    "    retries = 3\n",
    "\n",
    "    while not success and retries > 0:\n",
    "        try:\n",
    "            total_requests += 1\n",
    "\n",
    "            # Make API request\n",
    "            response = model.generate_content(sample['input'][i])\n",
    "            # print(response.text)\n",
    "            sample.loc[i, 'gemini_output'] = response.text.strip()\n",
    "            success = True\n",
    "            successful_requests += 1\n",
    "            time.sleep(5)\n",
    "\n",
    "        except Exception as e:\n",
    "            # print(f\"Error: {e}\")\n",
    "            retries -= 1\n",
    "            time.sleep(5)\n",
    "            total_requests += 1 \n",
    "\n",
    "\n",
    "\n",
    "print(f\"Total requests made: {total_requests}\")\n",
    "print(f\"Successful requests: {successful_requests}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_causal_judgement = sample.copy()\n",
    "# gemini_causal_judgement.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_csv(\"Big Bench Hard\", gemini_causal_judgement, file_name = \"gemini_causal_judgement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GROQ - llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_causal_judgement = causal_judgement.copy()\n",
    "groq_causal_judgement[\"llama_output\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_causal_judgement = groq_line_generate(raw_dataset = causal_judgement, output_dataset = groq_causal_judgement, start_idx=0, end_idx=9, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_causal_judgement = groq_line_generate(raw_dataset = causal_judgement, output_dataset = groq_causal_judgement, start_idx=10, end_idx=19, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_causal_judgement = groq_line_generate(raw_dataset = causal_judgement, output_dataset = groq_causal_judgement, start_idx=20, end_idx=29, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_causal_judgement = groq_line_generate(raw_dataset = causal_judgement, output_dataset = groq_causal_judgement, start_idx=30, end_idx=39, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_causal_judgement = groq_line_generate(raw_dataset = causal_judgement, output_dataset = groq_causal_judgement, start_idx=40, end_idx=49, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_causal_judgement = groq_line_generate(raw_dataset = causal_judgement, output_dataset = groq_causal_judgement, start_idx=50, end_idx=59, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_causal_judgement = groq_line_generate(raw_dataset = causal_judgement, output_dataset = groq_causal_judgement, start_idx=60, end_idx=69, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_causal_judgement = groq_line_generate(raw_dataset = causal_judgement, output_dataset = groq_causal_judgement, start_idx=70, end_idx=79, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_causal_judgement = groq_line_generate(raw_dataset = causal_judgement, output_dataset = groq_causal_judgement, start_idx=80, end_idx=89, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_causal_judgement = groq_line_generate(raw_dataset = causal_judgement, output_dataset = groq_causal_judgement, start_idx=90, end_idx=99, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_causal_judgement = groq_line_generate(raw_dataset = causal_judgement, output_dataset = groq_causal_judgement, start_idx=100, end_idx=109, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_causal_judgement = groq_line_generate(raw_dataset = causal_judgement, output_dataset = groq_causal_judgement, start_idx=110, end_idx=119, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_causal_judgement = groq_line_generate(raw_dataset = causal_judgement, output_dataset = groq_causal_judgement, start_idx=120, end_idx=129, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_causal_judgement = groq_line_generate(raw_dataset = causal_judgement, output_dataset = groq_causal_judgement, start_idx=130, end_idx=139, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_causal_judgement = groq_line_generate(raw_dataset = causal_judgement, output_dataset = groq_causal_judgement, start_idx=140, end_idx=149, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_causal_judgement = groq_line_generate(raw_dataset = causal_judgement, output_dataset = groq_causal_judgement, start_idx=150, end_idx=159, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_causal_judgement = groq_line_generate(raw_dataset = causal_judgement, output_dataset = groq_causal_judgement, start_idx=160, end_idx=169, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_causal_judgement = groq_line_generate(raw_dataset = causal_judgement, output_dataset = groq_causal_judgement, start_idx=170, end_idx=179, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_causal_judgement = groq_line_generate(raw_dataset = causal_judgement, output_dataset = groq_causal_judgement, start_idx=180, end_idx=189, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_causal_judgement.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_csv(folder_name=\"Big Bench Hard\", df=groq_causal_judgement, file_name = \"groq_causal_judgement\", output_col = \"llama_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Testing - disambiguation_qa.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disambiguation_qa = Big_Bench_Json_Processor_my('Big Bench Hard', 'disambiguation_qa.json').convert_df()\n",
    "disambiguation_qa.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GEMINI Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "total_requests = 0\n",
    "successful_requests = 0\n",
    "\n",
    "\n",
    "model=genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-flash\",\n",
    "  system_instruction=\"You only answer (A, (B), (C) or (D) to the following questions.\",\n",
    "  )\n",
    "\n",
    "disambiguation_sample = disambiguation_qa.copy()\n",
    "disambiguation_sample['gemini_output'] = None\n",
    "\n",
    "for i in range(len(disambiguation_sample)):\n",
    "    success = False\n",
    "    retries = 3\n",
    "\n",
    "    while not success and retries > 0:\n",
    "        try:\n",
    "            total_requests += 1\n",
    "\n",
    "            # Make API request\n",
    "            response = model.generate_content(disambiguation_sample['input'][i])\n",
    "            # print(response.text)\n",
    "            disambiguation_sample.loc[i, 'gemini_output'] = response.text.strip()\n",
    "            success = True\n",
    "            successful_requests += 1\n",
    "            time.sleep(5)\n",
    "\n",
    "        except Exception as e:\n",
    "            # print(f\"Error: {e}\")\n",
    "            retries -= 1\n",
    "            time.sleep(5)\n",
    "            total_requests += 1 \n",
    "\n",
    "\n",
    "\n",
    "print(f\"Total requests made: {total_requests}\")\n",
    "print(f\"Successful requests: {successful_requests}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_disambiguation = disambiguation_sample.copy()\n",
    "df_to_csv(\"Big Bench Hard\", gemini_disambiguation, file_name = \"gemini_disambiguation\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GROQ - llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disambiguation_qa['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disambiguation_qa.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_disambiguation_qa = disambiguation_qa.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_disambiguation_qa = groq_line_generate(raw_dataset = disambiguation_qa, output_dataset = groq_disambiguation_qa, start_idx=0, \n",
    "end_idx=9, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_disambiguation_qa = groq_line_generate(raw_dataset = disambiguation_qa, output_dataset = groq_disambiguation_qa, start_idx=10, \n",
    "end_idx=19, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_disambiguation_qa = groq_line_generate(raw_dataset = disambiguation_qa, output_dataset = groq_disambiguation_qa, start_idx=20, \n",
    "end_idx=29, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_disambiguation_qa = groq_line_generate(raw_dataset = disambiguation_qa, output_dataset = groq_disambiguation_qa, start_idx=30, \n",
    "end_idx=39, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_disambiguation_qa = groq_line_generate(raw_dataset = disambiguation_qa, output_dataset = groq_disambiguation_qa, start_idx=40, \n",
    "end_idx=49, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_disambiguation_qa = groq_line_generate(raw_dataset = disambiguation_qa, output_dataset = groq_disambiguation_qa, start_idx=50, \n",
    "end_idx=59, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_disambiguation_qa = groq_line_generate(raw_dataset = disambiguation_qa, output_dataset = groq_disambiguation_qa, start_idx=60, \n",
    "end_idx=69, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_disambiguation_qa = groq_line_generate(raw_dataset = disambiguation_qa, output_dataset = groq_disambiguation_qa, start_idx=70, \n",
    "end_idx=79, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_disambiguation_qa = groq_line_generate(raw_dataset = disambiguation_qa, output_dataset = groq_disambiguation_qa, start_idx=80, \n",
    "end_idx=89, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_disambiguation_qa = groq_line_generate(raw_dataset = disambiguation_qa, output_dataset = groq_disambiguation_qa, start_idx=90, \n",
    "end_idx=99, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_disambiguation_qa = groq_line_generate(raw_dataset = disambiguation_qa, output_dataset = groq_disambiguation_qa, start_idx=100, \n",
    "end_idx=109, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_disambiguation_qa = groq_line_generate(raw_dataset = disambiguation_qa, output_dataset = groq_disambiguation_qa, start_idx=110, \n",
    "end_idx=119, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_disambiguation_qa = groq_line_generate(raw_dataset = disambiguation_qa, output_dataset = groq_disambiguation_qa, start_idx=120, \n",
    "end_idx=129, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_disambiguation_qa = groq_line_generate(raw_dataset = disambiguation_qa, output_dataset = groq_disambiguation_qa, start_idx=130, \n",
    "end_idx=139, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_disambiguation_qa = groq_line_generate(raw_dataset = disambiguation_qa, output_dataset = groq_disambiguation_qa, start_idx=140, \n",
    "end_idx=149, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_disambiguation_qa = groq_line_generate(raw_dataset = disambiguation_qa, output_dataset = groq_disambiguation_qa, start_idx=150, \n",
    "end_idx=159, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_disambiguation_qa = groq_line_generate(raw_dataset = disambiguation_qa, output_dataset = groq_disambiguation_qa, start_idx=160, \n",
    "end_idx=169, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_disambiguation_qa = groq_line_generate(raw_dataset = disambiguation_qa, output_dataset = groq_disambiguation_qa, start_idx=170, end_idx=179, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_disambiguation_qa = groq_line_generate(raw_dataset = disambiguation_qa, output_dataset = groq_disambiguation_qa, start_idx=180, end_idx=189, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_disambiguation_qa = groq_line_generate(raw_dataset = disambiguation_qa, output_dataset = groq_disambiguation_qa, start_idx=190, end_idx=199, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_disambiguation_qa = groq_line_generate(raw_dataset = disambiguation_qa, output_dataset = groq_disambiguation_qa, start_idx=200, \n",
    "end_idx=209, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_disambiguation_qa = groq_line_generate(raw_dataset = disambiguation_qa, output_dataset = groq_disambiguation_qa, start_idx=210, \n",
    "end_idx=219, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_disambiguation_qa = groq_line_generate(raw_dataset = disambiguation_qa, output_dataset = groq_disambiguation_qa, start_idx=220, \n",
    "end_idx=229, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_disambiguation_qa = groq_line_generate(raw_dataset = disambiguation_qa, output_dataset = groq_disambiguation_qa, start_idx=230, end_idx=239, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_disambiguation_qa = groq_line_generate(raw_dataset = disambiguation_qa, output_dataset = groq_disambiguation_qa, start_idx=240, \n",
    "end_idx=250, system_message=\"You only answer Yes or No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_disambiguation_qa.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_csv(\"Big Bench Hard\", groq_disambiguation_qa, file_name = \"groq_disambiguation_qa\", output_col = \"llama_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Testing - dyck_languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dyck_languages = Big_Bench_Json_Processor_my('Big Bench Hard', 'dyck_languages.json').convert_df()\n",
    "dyck_languages.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GEMINI Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_dyck_languages = gemini_generator(dyck_languages, \"You only answer set of [],{}, or () to the following questions.\")   \n",
    "\n",
    "df_to_csv(\"Big Bench Hard\", gemini_dyck_languages, file_name = \"gemini_dyck_languages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GROQ - llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dyck_languages.info()\n",
    "dyck_languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_dyck_languages = dyck_languages.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_dyck_languages = groq_line_generate(raw_dataset = dyck_languages, output_dataset = groq_dyck_languages, start_idx=0, end_idx=9, system_message=\"You only answer set of [],{}, or () to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_dyck_languages = groq_line_generate(raw_dataset = dyck_languages, output_dataset = groq_dyck_languages, start_idx=10, end_idx=19, system_message=\"You only answer set of [],{}, or () to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_dyck_languages = groq_line_generate(raw_dataset = dyck_languages, output_dataset = groq_dyck_languages, start_idx=20, end_idx=29, system_message=\"You only answer set of [],{}, or () to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_dyck_languages = groq_line_generate(raw_dataset = dyck_languages, output_dataset = groq_dyck_languages, start_idx=30, end_idx=39, system_message=\"You only answer set of [],{}, or () to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_dyck_languages = groq_line_generate(raw_dataset = dyck_languages, output_dataset = groq_dyck_languages, start_idx=40, end_idx=49, system_message=\"You only answer set of [],{}, or () to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_dyck_languages = groq_line_generate(raw_dataset = dyck_languages, output_dataset = groq_dyck_languages, start_idx=50, end_idx=59, system_message=\"You only answer set of [],{}, or () to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_dyck_languages = groq_line_generate(raw_dataset = dyck_languages, output_dataset = groq_dyck_languages, start_idx=60, end_idx=69, system_message=\"You only answer set of [],{}, or () to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_dyck_languages = groq_line_generate(raw_dataset = dyck_languages, output_dataset = groq_dyck_languages, start_idx=70, end_idx=79, system_message=\"You only answer set of [],{}, or () to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_dyck_languages = groq_line_generate(raw_dataset = dyck_languages, output_dataset = groq_dyck_languages, start_idx=80, end_idx=89, system_message=\"You only answer set of [],{}, or () to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_dyck_languages = groq_line_generate(raw_dataset = dyck_languages, output_dataset = groq_dyck_languages, start_idx=90, end_idx=99, system_message=\"You only answer set of [],{}, or () to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_dyck_languages = groq_line_generate(raw_dataset = dyck_languages, output_dataset = groq_dyck_languages, start_idx=100, end_idx=109, system_message=\"You only answer set of [],{}, or () to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_dyck_languages = groq_line_generate(raw_dataset = dyck_languages, output_dataset = groq_dyck_languages, start_idx=110, end_idx=119, system_message=\"You only answer set of [],{}, or () to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_dyck_languages = groq_line_generate(raw_dataset = dyck_languages, output_dataset = groq_dyck_languages, start_idx=120, end_idx=129, system_message=\"You only answer set of [],{}, or () to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_dyck_languages = groq_line_generate(raw_dataset = dyck_languages, output_dataset = groq_dyck_languages, start_idx=130, end_idx=139, system_message=\"You only answer set of [],{}, or () to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_dyck_languages = groq_line_generate(raw_dataset = dyck_languages, output_dataset = groq_dyck_languages, start_idx=140, end_idx=149, system_message=\"You only answer set of [],{}, or () to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_dyck_languages = groq_line_generate(raw_dataset = dyck_languages, output_dataset = groq_dyck_languages, start_idx=150, end_idx=159, system_message=\"You only answer set of [],{}, or () to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_dyck_languages = groq_line_generate(raw_dataset = dyck_languages, output_dataset = groq_dyck_languages, start_idx=160, end_idx=169, system_message=\"You only answer set of [],{}, or () to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_dyck_languages = groq_line_generate(raw_dataset = dyck_languages, output_dataset = groq_dyck_languages, start_idx=170, end_idx=179, system_message=\"You only answer set of [],{}, or () to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_dyck_languages = groq_line_generate(raw_dataset = dyck_languages, output_dataset = groq_dyck_languages, start_idx=180, end_idx=189, system_message=\"You only answer set of [],{}, or () to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_dyck_languages = groq_line_generate(raw_dataset = dyck_languages, output_dataset = groq_dyck_languages, start_idx=190, end_idx=199, system_message=\"You only answer set of [],{}, or () to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_dyck_languages = groq_line_generate(raw_dataset = dyck_languages, output_dataset = groq_dyck_languages, start_idx=200, end_idx=209, system_message=\"You only answer set of [],{}, or () to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_dyck_languages = groq_line_generate(raw_dataset = dyck_languages, output_dataset = groq_dyck_languages, start_idx=210, end_idx=219, system_message=\"You only answer set of [],{}, or () to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_dyck_languages = groq_line_generate(raw_dataset = dyck_languages, output_dataset = groq_dyck_languages, start_idx=220, end_idx=229, system_message=\"You only answer set of [],{}, or () to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_dyck_languages = groq_line_generate(raw_dataset = dyck_languages, output_dataset = groq_dyck_languages, start_idx=230, end_idx=239, system_message=\"You only answer set of [],{}, or () to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_dyck_languages = groq_line_generate(raw_dataset = dyck_languages, output_dataset = groq_dyck_languages, start_idx=240, end_idx=250, system_message=\"You only answer set of [],{}, or () to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_dyck_languages.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_csv(\"Big Bench Hard\", groq_dyck_languages, file_name = \"groq_dyck_languages\", output_col = \"llama_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Testing - formal_fallacies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formal_fallacies = Big_Bench_Json_Processor_my('Big Bench Hard', 'formal_fallacies.json').convert_df()\n",
    "formal_fallacies.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GEMINI Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_formal_fallacies = gemini_generator(formal_fallacies, \"You only answer invalid or valid to the following questions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_csv(\"Big Bench Hard\", gemini_dyck_languages, file_name = \"gemini_formal_fallacies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GROQ - llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_formal_fallacies = formal_fallacies.copy()\n",
    "groq_formal_fallacies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_formal_fallacies = groq_line_generate(raw_dataset = formal_fallacies, output_dataset = groq_formal_fallacies, start_idx=0, end_idx=9, system_message=\"You only answer invalid or valid to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_formal_fallacies = groq_line_generate(raw_dataset = formal_fallacies, output_dataset = groq_formal_fallacies, start_idx=10, end_idx=19, system_message=\"You only answer invalid or valid to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_formal_fallacies = groq_line_generate(raw_dataset = formal_fallacies, output_dataset = groq_formal_fallacies, start_idx=20, end_idx=29, system_message=\"You only answer invalid or valid to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_formal_fallacies = groq_line_generate(raw_dataset = formal_fallacies, output_dataset = groq_formal_fallacies, start_idx=30, end_idx=39, system_message=\"You only answer invalid or valid to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_formal_fallacies = groq_line_generate(raw_dataset = formal_fallacies, output_dataset = groq_formal_fallacies, start_idx=40, end_idx=49, system_message=\"You only answer invalid or valid to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_formal_fallacies = groq_line_generate(raw_dataset = formal_fallacies, output_dataset = groq_formal_fallacies, start_idx=50, end_idx=59, system_message=\"You only answer invalid or valid to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_formal_fallacies = groq_line_generate(raw_dataset = formal_fallacies, output_dataset = groq_formal_fallacies, start_idx=60, end_idx=69, system_message=\"You only answer invalid or valid to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_formal_fallacies = groq_line_generate(raw_dataset = formal_fallacies, output_dataset = groq_formal_fallacies, start_idx=70, end_idx=79, system_message=\"You only answer invalid or valid to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_formal_fallacies = groq_line_generate(raw_dataset = formal_fallacies, output_dataset = groq_formal_fallacies, start_idx=80, end_idx=89, system_message=\"You only answer invalid or valid to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_formal_fallacies = groq_line_generate(raw_dataset = formal_fallacies, output_dataset = groq_formal_fallacies, start_idx=90, end_idx=99, system_message=\"You only answer invalid or valid to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_formal_fallacies = groq_line_generate(raw_dataset = formal_fallacies, output_dataset = groq_formal_fallacies, start_idx=100, end_idx=109, system_message=\"You only answer invalid or valid to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_formal_fallacies = groq_line_generate(raw_dataset = formal_fallacies, output_dataset = groq_formal_fallacies, start_idx=110, end_idx=119, system_message=\"You only answer invalid or valid to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_formal_fallacies = groq_line_generate(raw_dataset = formal_fallacies, output_dataset = groq_formal_fallacies, start_idx=120, end_idx=129, system_message=\"You only answer invalid or valid to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_formal_fallacies = groq_line_generate(raw_dataset = formal_fallacies, output_dataset = groq_formal_fallacies, start_idx=130, end_idx=139, system_message=\"You only answer invalid or valid to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_formal_fallacies = groq_line_generate(raw_dataset = formal_fallacies, output_dataset = groq_formal_fallacies, start_idx=140, end_idx=149, system_message=\"You only answer invalid or valid to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_formal_fallacies = groq_line_generate(raw_dataset = formal_fallacies, output_dataset = groq_formal_fallacies, start_idx=150, end_idx=159, system_message=\"You only answer invalid or valid to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_formal_fallacies = groq_line_generate(raw_dataset = formal_fallacies, output_dataset = groq_formal_fallacies, start_idx=160, end_idx=169, system_message=\"You only answer invalid or valid to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_formal_fallacies = groq_line_generate(raw_dataset = formal_fallacies, output_dataset = groq_formal_fallacies, start_idx=170, end_idx=179, system_message=\"You only answer invalid or valid to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_formal_fallacies = groq_line_generate(raw_dataset = formal_fallacies, output_dataset = groq_formal_fallacies, start_idx=180, end_idx=189, system_message=\"You only answer invalid or valid to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_formal_fallacies = groq_line_generate(raw_dataset = formal_fallacies, output_dataset = groq_formal_fallacies, start_idx=190, end_idx=199, system_message=\"You only answer invalid or valid to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_formal_fallacies = groq_line_generate(raw_dataset = formal_fallacies, output_dataset = groq_formal_fallacies, start_idx=200, end_idx=209, system_message=\"You only answer invalid or valid to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_formal_fallacies = groq_line_generate(raw_dataset = formal_fallacies, output_dataset = groq_formal_fallacies, start_idx=210, end_idx=219, system_message=\"You only answer invalid or valid to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_formal_fallacies = groq_line_generate(raw_dataset = formal_fallacies, output_dataset = groq_formal_fallacies, start_idx=220, end_idx=229, system_message=\"You only answer invalid or valid to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_formal_fallacies = groq_line_generate(raw_dataset = formal_fallacies, output_dataset = groq_formal_fallacies, start_idx=230, end_idx=239, system_message=\"You only answer invalid or valid to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_formal_fallacies = groq_line_generate(raw_dataset = formal_fallacies, output_dataset = groq_formal_fallacies, start_idx=240, end_idx=250, system_message=\"You only answer invalid or valid to the following questions.\", model_name=\"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_formal_fallacies.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Need to handle the empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_csv(\"Big Bench Hard\", groq_formal_fallacies, file_name = \"groq_formal_fallacies\", output_col = \"llama_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Testing - geometric_shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometric_shapes = Big_Bench_Json_Processor_my('Big Bench Hard', 'geometric_shapes.json').convert_df()\n",
    "geometric_shapes.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometric_shapes['target'] .unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometric_shapes.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GEMINI Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_geomnetric_shapes = gemini_generator(geometric_shapes, \"You only answer A, B, C, D, E, F, J, G, H, K to the following questions.\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_csv(\"Big Bench Hard\", gemini_geomnetric_shapes, file_name = \"gemini_geomnetric_shapes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GROQ - llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_geomnetric_shapes = geometric_shapes.copy()\n",
    "groq_geomnetric_shapes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n"
     ]
    }
   ],
   "source": [
    "groq_geomnetric_shapes = groq_line_generate(raw_dataset = geometric_shapes, output_dataset = groq_geomnetric_shapes, start_idx=0, end_idx=9, system_message=\"You only answer A, B, C, D, E, F, J, G, H, K to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_geomnetric_shapes = groq_line_generate(raw_dataset = geometric_shapes, output_dataset = groq_geomnetric_shapes, start_idx=10, end_idx=19, system_message=\"You only answer A, B, C, D, E, F, J, G, H, K to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_geomnetric_shapes = groq_line_generate(raw_dataset = geometric_shapes, output_dataset = groq_geomnetric_shapes, start_idx=20, end_idx=29, system_message=\"You only answer A, B, C, D, E, F, J, G, H, K to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_geomnetric_shapes = groq_line_generate(raw_dataset = geometric_shapes, output_dataset = groq_geomnetric_shapes, start_idx=30, end_idx=39, system_message=\"You only answer A, B, C, D, E, F, J, G, H, K to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_geomnetric_shapes = groq_line_generate(raw_dataset = geometric_shapes, output_dataset = groq_geomnetric_shapes, start_idx=40, end_idx=49, system_message=\"You only answer A, B, C, D, E, F, J, G, H, K to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_geomnetric_shapes = groq_line_generate(raw_dataset = geometric_shapes, output_dataset = groq_geomnetric_shapes, start_idx=50, end_idx=59, system_message=\"You only answer A, B, C, D, E, F, J, G, H, K to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_geomnetric_shapes = groq_line_generate(raw_dataset = geometric_shapes, output_dataset = groq_geomnetric_shapes, start_idx=60, end_idx=69, system_message=\"You only answer A, B, C, D, E, F, J, G, H, K to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_geomnetric_shapes = groq_line_generate(raw_dataset = geometric_shapes, output_dataset = groq_geomnetric_shapes, start_idx=70, end_idx=79, system_message=\"You only answer A, B, C, D, E, F, J, G, H, K to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_geomnetric_shapes = groq_line_generate(raw_dataset = geometric_shapes, output_dataset = groq_geomnetric_shapes, start_idx=80, end_idx=89, system_message=\"You only answer A, B, C, D, E, F, J, G, H, K to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_geomnetric_shapes = groq_line_generate(raw_dataset = geometric_shapes, output_dataset = groq_geomnetric_shapes, start_idx=90, end_idx=99, system_message=\"You only answer A, B, C, D, E, F, J, G, H, K to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_geomnetric_shapes = groq_line_generate(raw_dataset = geometric_shapes, output_dataset = groq_geomnetric_shapes, start_idx=100, end_idx=109, system_message=\"You only answer A, B, C, D, E, F, J, G, H, K to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_geomnetric_shapes = groq_line_generate(raw_dataset = geometric_shapes, output_dataset = groq_geomnetric_shapes, start_idx=110, end_idx=119, system_message=\"You only answer A, B, C, D, E, F, J, G, H, K to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_geomnetric_shapes = groq_line_generate(raw_dataset = geometric_shapes, output_dataset = groq_geomnetric_shapes, start_idx=120, end_idx=129, system_message=\"You only answer A, B, C, D, E, F, J, G, H, K to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_geomnetric_shapes = groq_line_generate(raw_dataset = geometric_shapes, output_dataset = groq_geomnetric_shapes, start_idx=130, end_idx=139, system_message=\"You only answer A, B, C, D, E, F, J, G, H, K to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_geomnetric_shapes = groq_line_generate(raw_dataset = geometric_shapes, output_dataset = groq_geomnetric_shapes, start_idx=140, end_idx=149, system_message=\"You only answer A, B, C, D, E, F, J, G, H, K to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_geomnetric_shapes = groq_line_generate(raw_dataset = geometric_shapes, output_dataset = groq_geomnetric_shapes, start_idx=150, end_idx=159, system_message=\"You only answer A, B, C, D, E, F, J, G, H, K to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_geomnetric_shapes = groq_line_generate(raw_dataset = geometric_shapes, output_dataset = groq_geomnetric_shapes, start_idx=160, end_idx=169, system_message=\"You only answer A, B, C, D, E, F, J, G, H, K to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_geomnetric_shapes = groq_line_generate(raw_dataset = geometric_shapes, output_dataset = groq_geomnetric_shapes, start_idx=170, end_idx=179, system_message=\"You only answer A, B, C, D, E, F, J, G, H, K to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_geomnetric_shapes = groq_line_generate(raw_dataset = geometric_shapes, output_dataset = groq_geomnetric_shapes, start_idx=180, end_idx=189, system_message=\"You only answer A, B, C, D, E, F, J, G, H, K to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_geomnetric_shapes = groq_line_generate(raw_dataset = geometric_shapes, output_dataset = groq_geomnetric_shapes, start_idx=190, end_idx=199, system_message=\"You only answer A, B, C, D, E, F, J, G, H, K to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_geomnetric_shapes = groq_line_generate(raw_dataset = geometric_shapes, output_dataset = groq_geomnetric_shapes, start_idx=200, end_idx=209, system_message=\"You only answer A, B, C, D, E, F, J, G, H, K to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_geomnetric_shapes = groq_line_generate(raw_dataset = geometric_shapes, output_dataset = groq_geomnetric_shapes, start_idx=210, end_idx=219, system_message=\"You only answer A, B, C, D, E, F, J, G, H, K to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_geomnetric_shapes = groq_line_generate(raw_dataset = geometric_shapes, output_dataset = groq_geomnetric_shapes, start_idx=220, end_idx=229, system_message=\"You only answer A, B, C, D, E, F, J, G, H, K to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_geomnetric_shapes = groq_line_generate(raw_dataset = geometric_shapes, output_dataset = groq_geomnetric_shapes, start_idx=230, end_idx=239, system_message=\"You only answer A, B, C, D, E, F, J, G, H, K to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_geomnetric_shapes = groq_line_generate(raw_dataset = geometric_shapes, output_dataset = groq_geomnetric_shapes, start_idx=240, end_idx=249, system_message=\"You only answer A, B, C, D, E, F, J, G, H, K to the following questions.\", model_name=\"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   input         250 non-null    object\n",
      " 1   target        250 non-null    object\n",
      " 2   llama_output  250 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "groq_geomnetric_shapes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame exported successfully to /Users/ezishr/Library/CloudStorage/OneDrive-UniversityofCincinnati/Undergraduate Research/Check points/Big Bench Hard/groq_geomnetric_shapes.csv!\n"
     ]
    }
   ],
   "source": [
    "df_to_csv(\"Big Bench Hard\", groq_geomnetric_shapes, file_name = \"groq_geomnetric_shapes\", output_col = \"llama_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Testing - hyperbaton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   250 non-null    object\n",
      " 1   target  250 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 4.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which sentence has the correct adjective order:\\nOptions:\\n(A) midsize old grey Brazilian sweater\\n(B) midsize grey Brazilian old sweater</td>\n",
       "      <td>(A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which sentence has the correct adjective order:\\nOptions:\\n(A) rubber gray walking Mexican midsize cat\\n(B) midsize gray Mexican rubber walking cat</td>\n",
       "      <td>(B)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which sentence has the correct adjective order:\\nOptions:\\n(A) mysterious big Indian iron smoking motorcycle\\n(B) big smoking mysterious Indian iron motorcycle</td>\n",
       "      <td>(A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Which sentence has the correct adjective order:\\nOptions:\\n(A) cloth smoking rectangular motorcycle\\n(B) rectangular cloth smoking motorcycle</td>\n",
       "      <td>(B)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which sentence has the correct adjective order:\\nOptions:\\n(A) pyramidal American glass exercise surfboard\\n(B) glass exercise American pyramidal surfboard</td>\n",
       "      <td>(A)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                             input  \\\n",
       "0                        Which sentence has the correct adjective order:\\nOptions:\\n(A) midsize old grey Brazilian sweater\\n(B) midsize grey Brazilian old sweater   \n",
       "1              Which sentence has the correct adjective order:\\nOptions:\\n(A) rubber gray walking Mexican midsize cat\\n(B) midsize gray Mexican rubber walking cat   \n",
       "2  Which sentence has the correct adjective order:\\nOptions:\\n(A) mysterious big Indian iron smoking motorcycle\\n(B) big smoking mysterious Indian iron motorcycle   \n",
       "3                    Which sentence has the correct adjective order:\\nOptions:\\n(A) cloth smoking rectangular motorcycle\\n(B) rectangular cloth smoking motorcycle   \n",
       "4      Which sentence has the correct adjective order:\\nOptions:\\n(A) pyramidal American glass exercise surfboard\\n(B) glass exercise American pyramidal surfboard   \n",
       "\n",
       "  target  \n",
       "0    (A)  \n",
       "1    (B)  \n",
       "2    (A)  \n",
       "3    (B)  \n",
       "4    (A)  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperbaton = Big_Bench_Json_Processor_my('Big Bench Hard', 'hyperbaton.json').convert_df()\n",
    "hyperbaton.info()\n",
    "hyperbaton.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   250 non-null    object\n",
      " 1   target  250 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 4.0+ KB\n"
     ]
    }
   ],
   "source": [
    "hyperbaton.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GEMINI Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_hyperbaton = gemini_generator(hyperbaton, \"You only answer A or B to the following questions.\")\n",
    "df_to_csv(\"Big Bench Hard\", gemini_hyperbaton, file_name = \"gemini_hyperbaton\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GROQ - llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_hyperbaton = hyperbaton.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['(A)', '(B)'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_hyperbaton['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n"
     ]
    }
   ],
   "source": [
    "groq_hyperbaton = groq_line_generate(raw_dataset = hyperbaton, output_dataset = groq_hyperbaton, start_idx=0, end_idx=9, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_hyperbaton = groq_line_generate(raw_dataset = hyperbaton, output_dataset = groq_hyperbaton, start_idx=10, end_idx=19, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_hyperbaton = groq_line_generate(raw_dataset = hyperbaton, output_dataset = groq_hyperbaton, start_idx=20, end_idx=29, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_hyperbaton = groq_line_generate(raw_dataset = hyperbaton, output_dataset = groq_hyperbaton, start_idx=30, end_idx=39, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_hyperbaton = groq_line_generate(raw_dataset = hyperbaton, output_dataset = groq_hyperbaton, start_idx=40, end_idx=49, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_hyperbaton = groq_line_generate(raw_dataset = hyperbaton, output_dataset = groq_hyperbaton, start_idx=50, end_idx=59, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_hyperbaton = groq_line_generate(raw_dataset = hyperbaton, output_dataset = groq_hyperbaton, start_idx=60, end_idx=69, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_hyperbaton = groq_line_generate(raw_dataset = hyperbaton, output_dataset = groq_hyperbaton, start_idx=70, end_idx=79, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_hyperbaton = groq_line_generate(raw_dataset = hyperbaton, output_dataset = groq_hyperbaton, start_idx=80, end_idx=89, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_hyperbaton = groq_line_generate(raw_dataset = hyperbaton, output_dataset = groq_hyperbaton, start_idx=90, end_idx=99, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_hyperbaton = groq_line_generate(raw_dataset = hyperbaton, output_dataset = groq_hyperbaton, start_idx=100, end_idx=109, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_hyperbaton = groq_line_generate(raw_dataset = hyperbaton, output_dataset = groq_hyperbaton, start_idx=110, end_idx=119, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_hyperbaton = groq_line_generate(raw_dataset = hyperbaton, output_dataset = groq_hyperbaton, start_idx=120, end_idx=129, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_hyperbaton = groq_line_generate(raw_dataset = hyperbaton, output_dataset = groq_hyperbaton, start_idx=130, end_idx=139, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_hyperbaton = groq_line_generate(raw_dataset = hyperbaton, output_dataset = groq_hyperbaton, start_idx=140, end_idx=149, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_hyperbaton = groq_line_generate(raw_dataset = hyperbaton, output_dataset = groq_hyperbaton, start_idx=150, end_idx=159, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_hyperbaton = groq_line_generate(raw_dataset = hyperbaton, output_dataset = groq_hyperbaton, start_idx=160, end_idx=169, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_hyperbaton = groq_line_generate(raw_dataset = hyperbaton, output_dataset = groq_hyperbaton, start_idx=170, end_idx=179, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_hyperbaton = groq_line_generate(raw_dataset = hyperbaton, output_dataset = groq_hyperbaton, start_idx=180, end_idx=189, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_hyperbaton = groq_line_generate(raw_dataset = hyperbaton, output_dataset = groq_hyperbaton, start_idx=190, end_idx=199, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_hyperbaton = groq_line_generate(raw_dataset = hyperbaton, output_dataset = groq_hyperbaton, start_idx=200, end_idx=209, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_hyperbaton = groq_line_generate(raw_dataset = hyperbaton, output_dataset = groq_hyperbaton, start_idx=210, end_idx=219, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_hyperbaton = groq_line_generate(raw_dataset = hyperbaton, output_dataset = groq_hyperbaton, start_idx=220, end_idx=229, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_hyperbaton = groq_line_generate(raw_dataset = hyperbaton, output_dataset = groq_hyperbaton, start_idx=230, end_idx=239, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_hyperbaton = groq_line_generate(raw_dataset = hyperbaton, output_dataset = groq_hyperbaton, start_idx=240, end_idx=249, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   input         250 non-null    object\n",
      " 1   target        250 non-null    object\n",
      " 2   llama_output  250 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 6.0+ KB\n",
      "DataFrame exported successfully to /Users/ezishr/Library/CloudStorage/OneDrive-UniversityofCincinnati/Undergraduate Research/Check points/Big Bench Hard/groq_hyperbaton.csv!\n"
     ]
    }
   ],
   "source": [
    "groq_hyperbaton.info()\n",
    "df_to_csv(\"Big Bench Hard\", groq_hyperbaton, file_name = \"groq_hyperbaton\", output_col = \"llama_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Testing - logical_deduction_five_objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "logical_deduction_five = Big_Bench_Json_Processor_my('Big Bench Hard', 'logical_deduction_five_objects.json').convert_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The following paragraphs each describe a set of five objects arranged in a fixed order. The statements are logically consistent within each paragraph. On a branch, there are five birds: a quail, an owl, a raven, a falcon, and a robin. The owl is the leftmost. The robin is to the left of the raven. The quail is the rightmost. The raven is the third from the left.\\nOptions:\\n(A) The quail is the rightmost\\n(B) The owl is the rightmost\\n(C) The raven is the rightmost\\n(D) The falcon is the rightmost\\n(E) The robin is the rightmost</td>\n",
       "      <td>(A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The following paragraphs each describe a set of five objects arranged in a fixed order. The statements are logically consistent within each paragraph. In an antique car show, there are five vehicles: a hatchback, a bus, a convertible, a tractor, and a minivan. The tractor is older than the bus. The minivan is newer than the bus. The hatchback is the second-newest. The minivan is older than the convertible.\\nOptions:\\n(A) The hatchback is the second-oldest\\n(B) The bus is the second-oldest\\n(C) The convertible is the second-oldest\\n(D) The tractor is the second-oldest\\n(E) The minivan is the second-oldest</td>\n",
       "      <td>(B)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The following paragraphs each describe a set of five objects arranged in a fixed order. The statements are logically consistent within each paragraph. On a shelf, there are five books: a yellow book, a green book, a gray book, a blue book, and an orange book. The gray book is to the left of the green book. The gray book is the second from the right. The yellow book is to the right of the orange book. The blue book is the second from the left.\\nOptions:\\n(A) The yellow book is the leftmost\\n(B) The green book is the leftmost\\n(C) The gray book is the leftmost\\n(D) The blue book is the leftmost\\n(E) The orange book is the leftmost</td>\n",
       "      <td>(E)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The following paragraphs each describe a set of five objects arranged in a fixed order. The statements are logically consistent within each paragraph. On a branch, there are five birds: a raven, an owl, a cardinal, a hummingbird, and a robin. The cardinal is the rightmost. The raven is to the left of the owl. The robin is to the right of the hummingbird. The hummingbird is the third from the left.\\nOptions:\\n(A) The raven is the second from the left\\n(B) The owl is the second from the left\\n(C) The cardinal is the second from the left\\n(D) The hummingbird is the second from the left\\n(E) The robin is the second from the left</td>\n",
       "      <td>(B)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The following paragraphs each describe a set of five objects arranged in a fixed order. The statements are logically consistent within each paragraph. On a shelf, there are five books: a green book, an orange book, a gray book, a yellow book, and a purple book. The green book is the rightmost. The gray book is to the right of the orange book. The purple book is to the left of the yellow book. The purple book is to the right of the gray book.\\nOptions:\\n(A) The green book is the second from the right\\n(B) The orange book is the second from the right\\n(C) The gray book is the second from the right\\n(D) The yellow book is the second from the right\\n(E) The purple book is the second from the right</td>\n",
       "      <td>(D)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            input  \\\n",
       "0                                                                                                                                                                           The following paragraphs each describe a set of five objects arranged in a fixed order. The statements are logically consistent within each paragraph. On a branch, there are five birds: a quail, an owl, a raven, a falcon, and a robin. The owl is the leftmost. The robin is to the left of the raven. The quail is the rightmost. The raven is the third from the left.\\nOptions:\\n(A) The quail is the rightmost\\n(B) The owl is the rightmost\\n(C) The raven is the rightmost\\n(D) The falcon is the rightmost\\n(E) The robin is the rightmost   \n",
       "1                                                                                             The following paragraphs each describe a set of five objects arranged in a fixed order. The statements are logically consistent within each paragraph. In an antique car show, there are five vehicles: a hatchback, a bus, a convertible, a tractor, and a minivan. The tractor is older than the bus. The minivan is newer than the bus. The hatchback is the second-newest. The minivan is older than the convertible.\\nOptions:\\n(A) The hatchback is the second-oldest\\n(B) The bus is the second-oldest\\n(C) The convertible is the second-oldest\\n(D) The tractor is the second-oldest\\n(E) The minivan is the second-oldest   \n",
       "2                                                                    The following paragraphs each describe a set of five objects arranged in a fixed order. The statements are logically consistent within each paragraph. On a shelf, there are five books: a yellow book, a green book, a gray book, a blue book, and an orange book. The gray book is to the left of the green book. The gray book is the second from the right. The yellow book is to the right of the orange book. The blue book is the second from the left.\\nOptions:\\n(A) The yellow book is the leftmost\\n(B) The green book is the leftmost\\n(C) The gray book is the leftmost\\n(D) The blue book is the leftmost\\n(E) The orange book is the leftmost   \n",
       "3                                                                        The following paragraphs each describe a set of five objects arranged in a fixed order. The statements are logically consistent within each paragraph. On a branch, there are five birds: a raven, an owl, a cardinal, a hummingbird, and a robin. The cardinal is the rightmost. The raven is to the left of the owl. The robin is to the right of the hummingbird. The hummingbird is the third from the left.\\nOptions:\\n(A) The raven is the second from the left\\n(B) The owl is the second from the left\\n(C) The cardinal is the second from the left\\n(D) The hummingbird is the second from the left\\n(E) The robin is the second from the left   \n",
       "4  The following paragraphs each describe a set of five objects arranged in a fixed order. The statements are logically consistent within each paragraph. On a shelf, there are five books: a green book, an orange book, a gray book, a yellow book, and a purple book. The green book is the rightmost. The gray book is to the right of the orange book. The purple book is to the left of the yellow book. The purple book is to the right of the gray book.\\nOptions:\\n(A) The green book is the second from the right\\n(B) The orange book is the second from the right\\n(C) The gray book is the second from the right\\n(D) The yellow book is the second from the right\\n(E) The purple book is the second from the right   \n",
       "\n",
       "  target  \n",
       "0    (A)  \n",
       "1    (B)  \n",
       "2    (E)  \n",
       "3    (B)  \n",
       "4    (D)  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logical_deduction_five.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['(A)', '(B)', '(E)', '(D)', '(C)'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logical_deduction_five['target'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GEMINI Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_logical_deduction_five = gemini_generator(logical_deduction_five, \"You only answer A, B, C, D, E to the following questions.\")\n",
    "df_to_csv(\"Big Bench Hard\", gemini_logical_deduction_five, file_name = \"gemini_logical_deduction_five\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GROQ - llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_logical_five = logical_deduction_five.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 16\n",
      "Successful requests: 10\n",
      "Total requests made: 12\n",
      "Successful requests: 10\n",
      "Total requests made: 19\n",
      "Successful requests: 9\n",
      "Total requests made: 26\n",
      "Successful requests: 10\n",
      "Total requests made: 16\n",
      "Successful requests: 10\n",
      "Total requests made: 19\n",
      "Successful requests: 9\n",
      "Total requests made: 20\n",
      "Successful requests: 10\n",
      "Total requests made: 36\n",
      "Successful requests: 6\n",
      "Total requests made: 45\n",
      "Successful requests: 5\n",
      "Total requests made: 36\n",
      "Successful requests: 8\n",
      "Total requests made: 42\n",
      "Successful requests: 4\n",
      "Total requests made: 45\n",
      "Successful requests: 5\n",
      "Total requests made: 50\n",
      "Successful requests: 2\n",
      "Total requests made: 37\n",
      "Successful requests: 7\n",
      "Total requests made: 14\n",
      "Successful requests: 10\n",
      "Total requests made: 16\n",
      "Successful requests: 10\n",
      "Total requests made: 31\n",
      "Successful requests: 7\n",
      "Total requests made: 44\n",
      "Successful requests: 6\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 45\u001b[0m\n\u001b[1;32m     41\u001b[0m groq_logical_five \u001b[38;5;241m=\u001b[39m groq_line_generate(raw_dataset \u001b[38;5;241m=\u001b[39m logical_deduction_five, output_dataset \u001b[38;5;241m=\u001b[39m groq_logical_five, start_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, end_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m209\u001b[39m, system_message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou only answer A, B to the following questions.\u001b[39m\u001b[38;5;124m\"\u001b[39m, model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama-3.3-70b-versatile\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     43\u001b[0m groq_logical_five \u001b[38;5;241m=\u001b[39m groq_line_generate(raw_dataset \u001b[38;5;241m=\u001b[39m logical_deduction_five, output_dataset \u001b[38;5;241m=\u001b[39m groq_logical_five, start_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m210\u001b[39m, end_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m219\u001b[39m, system_message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou only answer A, B to the following questions.\u001b[39m\u001b[38;5;124m\"\u001b[39m, model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama-3.3-70b-versatile\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 45\u001b[0m groq_logical_five \u001b[38;5;241m=\u001b[39m \u001b[43mgroq_line_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_dataset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlogical_deduction_five\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dataset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgroq_logical_five\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m220\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m229\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_message\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou only answer A, B to the following questions.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mllama-3.3-70b-versatile\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m groq_logical_five \u001b[38;5;241m=\u001b[39m groq_line_generate(raw_dataset \u001b[38;5;241m=\u001b[39m logical_deduction_five, output_dataset \u001b[38;5;241m=\u001b[39m groq_logical_five, start_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m230\u001b[39m, end_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m239\u001b[39m, system_message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou only answer A, B to the following questions.\u001b[39m\u001b[38;5;124m\"\u001b[39m, model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama-3.3-70b-versatile\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m groq_logical_five \u001b[38;5;241m=\u001b[39m groq_line_generate(raw_dataset \u001b[38;5;241m=\u001b[39m logical_deduction_five, output_dataset \u001b[38;5;241m=\u001b[39m groq_logical_five, start_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m240\u001b[39m, end_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m249\u001b[39m, system_message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou only answer A, B to the following questions.\u001b[39m\u001b[38;5;124m\"\u001b[39m, model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama-3.3-70b-versatile\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 11\u001b[0m, in \u001b[0;36mgroq_line_generate\u001b[0;34m(raw_dataset, output_dataset, start_idx, end_idx, system_message, model_name)\u001b[0m\n\u001b[1;32m      9\u001b[0m sample \u001b[38;5;241m=\u001b[39m raw_dataset\u001b[38;5;241m.\u001b[39mloc[start_idx:end_idx, ]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     10\u001b[0m sample\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 11\u001b[0m groq_sample \u001b[38;5;241m=\u001b[39m \u001b[43mgroq\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_message\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m output_dataset\u001b[38;5;241m.\u001b[39mloc[start_idx:end_idx, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama_output\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m groq_sample[model_name]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output_dataset\n",
      "Cell \u001b[0;32mIn[4], line 30\u001b[0m, in \u001b[0;36mgroq\u001b[0;34m(data, system_message, model_name)\u001b[0m\n\u001b[1;32m     27\u001b[0m total_requests \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Make a request to the GROQ API\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m chat_completion \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_message\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m response \u001b[38;5;241m=\u001b[39m chat_completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     46\u001b[0m sample\u001b[38;5;241m.\u001b[39mloc[i, model_name] \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[0;32m~/anaconda3/envs/python_env/lib/python3.12/site-packages/groq/resources/chat/completions.py:298\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    186\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    187\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    188\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/openai/v1/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python_env/lib/python3.12/site-packages/groq/_base_client.py:1263\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1251\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1258\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1259\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1260\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1261\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1262\u001b[0m     )\n\u001b[0;32m-> 1263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/python_env/lib/python3.12/site-packages/groq/_base_client.py:955\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    953\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 955\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python_env/lib/python3.12/site-packages/groq/_base_client.py:991\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    988\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m    990\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 991\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    993\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    995\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    997\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/python_env/lib/python3.12/site-packages/httpx/_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/anaconda3/envs/python_env/lib/python3.12/site-packages/httpx/_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    951\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/python_env/lib/python3.12/site-packages/httpx/_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    989\u001b[0m     hook(request)\n\u001b[0;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    993\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/anaconda3/envs/python_env/lib/python3.12/site-packages/httpx/_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1024\u001b[0m     )\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1031\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/anaconda3/envs/python_env/lib/python3.12/site-packages/httpx/_transports/default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    234\u001b[0m )\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    241\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    242\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    243\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    244\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    245\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/python_env/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[0;32m~/anaconda3/envs/python_env/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/anaconda3/envs/python_env/lib/python3.12/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python_env/lib/python3.12/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/anaconda3/envs/python_env/lib/python3.12/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/anaconda3/envs/python_env/lib/python3.12/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python_env/lib/python3.12/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/anaconda3/envs/python_env/lib/python3.12/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python_env/lib/python3.12/ssl.py:1232\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1228\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1229\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1230\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1231\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1233\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m~/anaconda3/envs/python_env/lib/python3.12/ssl.py:1105\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "groq_logical_five = groq_line_generate(raw_dataset = logical_deduction_five, output_dataset = groq_logical_five, start_idx=0, end_idx=9, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_five = groq_line_generate(raw_dataset = logical_deduction_five, output_dataset = groq_logical_five, start_idx=10, end_idx=19, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_five = groq_line_generate(raw_dataset = logical_deduction_five, output_dataset = groq_logical_five, start_idx=20, end_idx=29, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_five = groq_line_generate(raw_dataset = logical_deduction_five, output_dataset = groq_logical_five, start_idx=30, end_idx=39, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_five = groq_line_generate(raw_dataset = logical_deduction_five, output_dataset = groq_logical_five, start_idx=40, end_idx=49, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_five = groq_line_generate(raw_dataset = logical_deduction_five, output_dataset = groq_logical_five, start_idx=50, end_idx=59, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_five = groq_line_generate(raw_dataset = logical_deduction_five, output_dataset = groq_logical_five, start_idx=60, end_idx=69, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_five = groq_line_generate(raw_dataset = logical_deduction_five, output_dataset = groq_logical_five, start_idx=70, end_idx=79, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_five = groq_line_generate(raw_dataset = logical_deduction_five, output_dataset = groq_logical_five, start_idx=80, end_idx=89, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_five = groq_line_generate(raw_dataset = logical_deduction_five, output_dataset = groq_logical_five, start_idx=90, end_idx=99, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_five = groq_line_generate(raw_dataset = logical_deduction_five, output_dataset = groq_logical_five, start_idx=100, end_idx=109, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_five = groq_line_generate(raw_dataset = logical_deduction_five, output_dataset = groq_logical_five, start_idx=110, end_idx=119, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_five = groq_line_generate(raw_dataset = logical_deduction_five, output_dataset = groq_logical_five, start_idx=120, end_idx=129, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_five = groq_line_generate(raw_dataset = logical_deduction_five, output_dataset = groq_logical_five, start_idx=130, end_idx=139, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_five = groq_line_generate(raw_dataset = logical_deduction_five, output_dataset = groq_logical_five, start_idx=140, end_idx=149, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_five = groq_line_generate(raw_dataset = logical_deduction_five, output_dataset = groq_logical_five, start_idx=150, end_idx=159, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_five = groq_line_generate(raw_dataset = logical_deduction_five, output_dataset = groq_logical_five, start_idx=160, end_idx=169, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_five = groq_line_generate(raw_dataset = logical_deduction_five, output_dataset = groq_logical_five, start_idx=170, end_idx=179, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_five = groq_line_generate(raw_dataset = logical_deduction_five, output_dataset = groq_logical_five, start_idx=180, end_idx=189, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_five = groq_line_generate(raw_dataset = logical_deduction_five, output_dataset = groq_logical_five, start_idx=190, end_idx=199, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_five = groq_line_generate(raw_dataset = logical_deduction_five, output_dataset = groq_logical_five, start_idx=200, end_idx=209, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_five = groq_line_generate(raw_dataset = logical_deduction_five, output_dataset = groq_logical_five, start_idx=210, end_idx=219, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_five = groq_line_generate(raw_dataset = logical_deduction_five, output_dataset = groq_logical_five, start_idx=220, end_idx=229, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_five = groq_line_generate(raw_dataset = logical_deduction_five, output_dataset = groq_logical_five, start_idx=230, end_idx=239, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_five = groq_line_generate(raw_dataset = logical_deduction_five, output_dataset = groq_logical_five, start_idx=240, end_idx=249, system_message=\"You only answer A, B to the following questions.\", model_name=\"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   input         250 non-null    object\n",
      " 1   target        250 non-null    object\n",
      " 2   llama_output  178 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "groq_logical_five.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export failed: DataFrame contains null values in 'gemini_output'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_csv(\"Big Bench Hard\", groq_logical_five, file_name = \"groq_logical_five\", output_col = \"llama_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'B', 'A.', 'C', None, 'D',\n",
       "       'B is incorrect, E is the correct statement according to the text, but since I can only answer A or B, I will say: \\n\\nB',\n",
       "       'B.', nan], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_logical_five['llama_output'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_logical_five.loc[groq_logical_five['llama_output']== 'B.',\"llama_output\"] = \"B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'B', 'A.', 'C', None, 'D', nan], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_logical_five['llama_output'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "      <th>llama_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>The following paragraphs each describe a set of five objects arranged in a fixed order. The statements are logically consistent within each paragraph. In an antique car show, there are five vehicles: a sedan, a convertible, a station wagon, a bus, and a motorcyle. The sedan is the second-newest. The station wagon is newer than the convertible. The sedan is older than the motorcyle. The bus is the oldest.\\nOptions:\\n(A) The sedan is the oldest\\n(B) The convertible is the oldest\\n(C) The station wagon is the oldest\\n(D) The bus is the oldest\\n(E) The motorcyle is the oldest</td>\n",
       "      <td>(D)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>The following paragraphs each describe a set of five objects arranged in a fixed order. The statements are logically consistent within each paragraph. On a branch, there are five birds: a falcon, a raven, a cardinal, a hawk, and a crow. The cardinal is the second from the right. The hawk is to the right of the falcon. The raven is the second from the left. The crow is the rightmost.\\nOptions:\\n(A) The falcon is the leftmost\\n(B) The raven is the leftmost\\n(C) The cardinal is the leftmost\\n(D) The hawk is the leftmost\\n(E) The crow is the leftmost</td>\n",
       "      <td>(A)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>The following paragraphs each describe a set of five objects arranged in a fixed order. The statements are logically consistent within each paragraph. On a shelf, there are five books: a black book, a purple book, a yellow book, an orange book, and a red book. The yellow book is the rightmost. The black book is to the left of the orange book. The orange book is to the left of the purple book. The black book is the second from the left.\\nOptions:\\n(A) The black book is the rightmost\\n(B) The purple book is the rightmost\\n(C) The yellow book is the rightmost\\n(D) The orange book is the rightmost\\n(E) The red book is the rightmost</td>\n",
       "      <td>(C)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>The following paragraphs each describe a set of five objects arranged in a fixed order. The statements are logically consistent within each paragraph. On a branch, there are five birds: a crow, a robin, a quail, a blue jay, and a falcon. The robin is to the left of the quail. The falcon is the third from the left. The crow is to the left of the falcon. The blue jay is the leftmost.\\nOptions:\\n(A) The crow is the second from the left\\n(B) The robin is the second from the left\\n(C) The quail is the second from the left\\n(D) The blue jay is the second from the left\\n(E) The falcon is the second from the left</td>\n",
       "      <td>(A)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>The following paragraphs each describe a set of five objects arranged in a fixed order. The statements are logically consistent within each paragraph. A fruit stand sells five fruits: loquats, peaches, pears, plums, and watermelons. The watermelons are the most expensive. The peaches are more expensive than the loquats. The plums are the second-cheapest. The pears are the third-most expensive.\\nOptions:\\n(A) The loquats are the cheapest\\n(B) The peaches are the cheapest\\n(C) The pears are the cheapest\\n(D) The plums are the cheapest\\n(E) The watermelons are the cheapest</td>\n",
       "      <td>(A)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>The following paragraphs each describe a set of five objects arranged in a fixed order. The statements are logically consistent within each paragraph. In a golf tournament, there were five golfers: Ana, Amy, Dan, Mya, and Eve. Ana finished below Mya. Dan finished above Amy. Mya finished second-to-last. Eve finished below Amy.\\nOptions:\\n(A) Ana finished first\\n(B) Amy finished first\\n(C) Dan finished first\\n(D) Mya finished first\\n(E) Eve finished first</td>\n",
       "      <td>(C)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>The following paragraphs each describe a set of five objects arranged in a fixed order. The statements are logically consistent within each paragraph. On a shelf, there are five books: a white book, an orange book, a yellow book, a blue book, and a red book. The yellow book is to the left of the white book. The red book is to the right of the blue book. The yellow book is to the right of the orange book. The blue book is to the right of the white book.\\nOptions:\\n(A) The white book is the third from the left\\n(B) The orange book is the third from the left\\n(C) The yellow book is the third from the left\\n(D) The blue book is the third from the left\\n(E) The red book is the third from the left</td>\n",
       "      <td>(A)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>The following paragraphs each describe a set of five objects arranged in a fixed order. The statements are logically consistent within each paragraph. A fruit stand sells five fruits: watermelons, oranges, loquats, plums, and kiwis. The plums are less expensive than the kiwis. The plums are more expensive than the watermelons. The loquats are more expensive than the kiwis. The oranges are the most expensive.\\nOptions:\\n(A) The watermelons are the third-most expensive\\n(B) The oranges are the third-most expensive\\n(C) The loquats are the third-most expensive\\n(D) The plums are the third-most expensive\\n(E) The kiwis are the third-most expensive</td>\n",
       "      <td>(E)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>The following paragraphs each describe a set of five objects arranged in a fixed order. The statements are logically consistent within each paragraph. On a branch, there are five birds: a hawk, a raven, a robin, a hummingbird, and a crow. The robin is the leftmost. The raven is the second from the left. The hawk is the second from the right. The crow is the third from the left.\\nOptions:\\n(A) The hawk is the third from the left\\n(B) The raven is the third from the left\\n(C) The robin is the third from the left\\n(D) The hummingbird is the third from the left\\n(E) The crow is the third from the left</td>\n",
       "      <td>(E)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>The following paragraphs each describe a set of five objects arranged in a fixed order. The statements are logically consistent within each paragraph. On a branch, there are five birds: a hawk, a raven, a robin, a hummingbird, and a crow. The robin is the leftmost. The raven is the second from the left. The hawk is the second from the right. The crow is the third from the left.\\nOptions:\\n(A) The hawk is the second from the left\\n(B) The raven is the second from the left\\n(C) The robin is the second from the left\\n(D) The hummingbird is the second from the left\\n(E) The crow is the second from the left</td>\n",
       "      <td>(B)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            input  \\\n",
       "68                                                                                                                             The following paragraphs each describe a set of five objects arranged in a fixed order. The statements are logically consistent within each paragraph. In an antique car show, there are five vehicles: a sedan, a convertible, a station wagon, a bus, and a motorcyle. The sedan is the second-newest. The station wagon is newer than the convertible. The sedan is older than the motorcyle. The bus is the oldest.\\nOptions:\\n(A) The sedan is the oldest\\n(B) The convertible is the oldest\\n(C) The station wagon is the oldest\\n(D) The bus is the oldest\\n(E) The motorcyle is the oldest   \n",
       "96                                                                                                                                                       The following paragraphs each describe a set of five objects arranged in a fixed order. The statements are logically consistent within each paragraph. On a branch, there are five birds: a falcon, a raven, a cardinal, a hawk, and a crow. The cardinal is the second from the right. The hawk is to the right of the falcon. The raven is the second from the left. The crow is the rightmost.\\nOptions:\\n(A) The falcon is the leftmost\\n(B) The raven is the leftmost\\n(C) The cardinal is the leftmost\\n(D) The hawk is the leftmost\\n(E) The crow is the leftmost   \n",
       "112                                                                   The following paragraphs each describe a set of five objects arranged in a fixed order. The statements are logically consistent within each paragraph. On a shelf, there are five books: a black book, a purple book, a yellow book, an orange book, and a red book. The yellow book is the rightmost. The black book is to the left of the orange book. The orange book is to the left of the purple book. The black book is the second from the left.\\nOptions:\\n(A) The black book is the rightmost\\n(B) The purple book is the rightmost\\n(C) The yellow book is the rightmost\\n(D) The orange book is the rightmost\\n(E) The red book is the rightmost   \n",
       "113                                                                                          The following paragraphs each describe a set of five objects arranged in a fixed order. The statements are logically consistent within each paragraph. On a branch, there are five birds: a crow, a robin, a quail, a blue jay, and a falcon. The robin is to the left of the quail. The falcon is the third from the left. The crow is to the left of the falcon. The blue jay is the leftmost.\\nOptions:\\n(A) The crow is the second from the left\\n(B) The robin is the second from the left\\n(C) The quail is the second from the left\\n(D) The blue jay is the second from the left\\n(E) The falcon is the second from the left   \n",
       "115                                                                                                                              The following paragraphs each describe a set of five objects arranged in a fixed order. The statements are logically consistent within each paragraph. A fruit stand sells five fruits: loquats, peaches, pears, plums, and watermelons. The watermelons are the most expensive. The peaches are more expensive than the loquats. The plums are the second-cheapest. The pears are the third-most expensive.\\nOptions:\\n(A) The loquats are the cheapest\\n(B) The peaches are the cheapest\\n(C) The pears are the cheapest\\n(D) The plums are the cheapest\\n(E) The watermelons are the cheapest   \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ...   \n",
       "245                                                                                                                                                                                                                                                     The following paragraphs each describe a set of five objects arranged in a fixed order. The statements are logically consistent within each paragraph. In a golf tournament, there were five golfers: Ana, Amy, Dan, Mya, and Eve. Ana finished below Mya. Dan finished above Amy. Mya finished second-to-last. Eve finished below Amy.\\nOptions:\\n(A) Ana finished first\\n(B) Amy finished first\\n(C) Dan finished first\\n(D) Mya finished first\\n(E) Eve finished first   \n",
       "246  The following paragraphs each describe a set of five objects arranged in a fixed order. The statements are logically consistent within each paragraph. On a shelf, there are five books: a white book, an orange book, a yellow book, a blue book, and a red book. The yellow book is to the left of the white book. The red book is to the right of the blue book. The yellow book is to the right of the orange book. The blue book is to the right of the white book.\\nOptions:\\n(A) The white book is the third from the left\\n(B) The orange book is the third from the left\\n(C) The yellow book is the third from the left\\n(D) The blue book is the third from the left\\n(E) The red book is the third from the left   \n",
       "247                                                   The following paragraphs each describe a set of five objects arranged in a fixed order. The statements are logically consistent within each paragraph. A fruit stand sells five fruits: watermelons, oranges, loquats, plums, and kiwis. The plums are less expensive than the kiwis. The plums are more expensive than the watermelons. The loquats are more expensive than the kiwis. The oranges are the most expensive.\\nOptions:\\n(A) The watermelons are the third-most expensive\\n(B) The oranges are the third-most expensive\\n(C) The loquats are the third-most expensive\\n(D) The plums are the third-most expensive\\n(E) The kiwis are the third-most expensive   \n",
       "248                                                                                                  The following paragraphs each describe a set of five objects arranged in a fixed order. The statements are logically consistent within each paragraph. On a branch, there are five birds: a hawk, a raven, a robin, a hummingbird, and a crow. The robin is the leftmost. The raven is the second from the left. The hawk is the second from the right. The crow is the third from the left.\\nOptions:\\n(A) The hawk is the third from the left\\n(B) The raven is the third from the left\\n(C) The robin is the third from the left\\n(D) The hummingbird is the third from the left\\n(E) The crow is the third from the left   \n",
       "249                                                                                             The following paragraphs each describe a set of five objects arranged in a fixed order. The statements are logically consistent within each paragraph. On a branch, there are five birds: a hawk, a raven, a robin, a hummingbird, and a crow. The robin is the leftmost. The raven is the second from the left. The hawk is the second from the right. The crow is the third from the left.\\nOptions:\\n(A) The hawk is the second from the left\\n(B) The raven is the second from the left\\n(C) The robin is the second from the left\\n(D) The hummingbird is the second from the left\\n(E) The crow is the second from the left   \n",
       "\n",
       "    target llama_output  \n",
       "68     (D)         None  \n",
       "96     (A)         None  \n",
       "112    (C)         None  \n",
       "113    (A)         None  \n",
       "115    (A)         None  \n",
       "..     ...          ...  \n",
       "245    (C)          NaN  \n",
       "246    (A)          NaN  \n",
       "247    (E)          NaN  \n",
       "248    (E)          NaN  \n",
       "249    (B)          NaN  \n",
       "\n",
       "[72 rows x 3 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_logical_five[groq_logical_five['llama_output'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame exported successfully to /Users/ezishr/Library/CloudStorage/OneDrive-UniversityofCincinnati/Undergraduate Research/Check points/Big Bench Hard/groq_logical_five_not_done.csv!\n"
     ]
    }
   ],
   "source": [
    "# Export temporary GROQ generation DataFrame to CSV\n",
    "\n",
    "base_path = r'/Users/ezishr/Library/CloudStorage/OneDrive-UniversityofCincinnati/Undergraduate Research/Check points'\n",
    "file_path = os.path.join(base_path, \"Big Bench Hard\", \"groq_logical_five_not_done.csv\")\n",
    "os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "groq_logical_five.to_csv(file_path, index=False)\n",
    "print(f\"DataFrame exported successfully to {file_path}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logical_deduction_five['input'].is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"groq_logical_five_not_done.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249]\n"
     ]
    }
   ],
   "source": [
    "indices = sample.index.tolist()\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in indices:\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\":\"user\",\n",
    "                \"content\": sample.loc[idx, 'input']\n",
    "            },\n",
    "            {\n",
    "                'role': 'system',\n",
    "                'content': \"You only answer A, B to the following questions.\"\n",
    "            }\n",
    "        ],\n",
    "        model = \"llama-3.3-70b-versatile\"\n",
    "    )\n",
    "\n",
    "    response = chat_completion.choices[0].message.content\n",
    "    sample.loc[idx, 'llama_output'] = response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['llama_output'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame exported successfully to /Users/ezishr/Library/CloudStorage/OneDrive-UniversityofCincinnati/Undergraduate Research/Check points/Big Bench Hard/groq_logical_five.csv!\n"
     ]
    }
   ],
   "source": [
    "df_to_csv(\"Big Bench Hard\", sample, file_name = \"groq_logical_five\", output_col = \"llama_output\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Testing - logical_deduction_seven"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "logical_deduction_seven = Big_Bench_Json_Processor_my('Big Bench Hard', 'logical_deduction_seven_objects.json').convert_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logical_deduction_seven.head()\n",
    "logical_deduction_seven['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logical_deduction_seven.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GEMINI Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_logical_deduction_seven = gemini_generator(logical_deduction_seven, \"You only answer A, B, C, D, E to the following questions.\")\n",
    "df_to_csv(\"Big Bench Hard\", gemini_logical_deduction_seven, file_name = \"gemini_logical_deduction_seven\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GROQ - llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   250 non-null    object\n",
      " 1   target  250 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 4.0+ KB\n"
     ]
    }
   ],
   "source": [
    "groq_logical_seven = logical_deduction_seven.copy()\n",
    "groq_logical_seven.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The following paragraphs each describe a set of seven objects arranged in a fixed order. The statements are logically consistent within each paragraph. In a golf tournament, there were seven golfers: Ana, Eve, Ada, Dan, Rob, Amy, and Joe. Dan finished third. Ana finished above Ada. Amy finished last. Dan finished below Rob. Eve finished below Ada. Rob finished below Joe.\\nOptions:\\n(A) Ana finished third\\n(B) Eve finished third\\n(C) Ada finished third\\n(D) Dan finished third\\n(E) Rob finished third\\n(F) Amy finished third\\n(G) Joe finished third</td>\n",
       "      <td>(D)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The following paragraphs each describe a set of seven objects arranged in a fixed order. The statements are logically consistent within each paragraph. In an antique car show, there are seven vehicles: a bus, a motorcyle, a hatchback, a station wagon, a minivan, a truck, and a limousine. The station wagon is the fourth-newest. The motorcyle is newer than the truck. The station wagon is older than the hatchback. The minivan is newer than the hatchback. The bus is newer than the minivan. The truck is newer than the limousine.\\nOptions:\\n(A) The bus is the third-oldest\\n(B) The motorcyle is the third-oldest\\n(C) The hatchback is the third-oldest\\n(D) The station wagon is the third-oldest\\n(E) The minivan is the third-oldest\\n(F) The truck is the third-oldest\\n(G) The limousine is the third-oldest</td>\n",
       "      <td>(B)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The following paragraphs each describe a set of seven objects arranged in a fixed order. The statements are logically consistent within each paragraph. On a branch, there are seven birds: a hummingbird, a cardinal, a blue jay, an owl, a raven, a quail, and a robin. The hummingbird is to the left of the quail. The robin is to the left of the cardinal. The blue jay is the leftmost. The cardinal is the fourth from the left. The raven is the third from the right. The owl is the third from the left.\\nOptions:\\n(A) The hummingbird is the second from the right\\n(B) The cardinal is the second from the right\\n(C) The blue jay is the second from the right\\n(D) The owl is the second from the right\\n(E) The raven is the second from the right\\n(F) The quail is the second from the right\\n(G) The robin is the second from the right</td>\n",
       "      <td>(A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The following paragraphs each describe a set of seven objects arranged in a fixed order. The statements are logically consistent within each paragraph. On a branch, there are seven birds: a robin, an owl, a quail, a falcon, a hummingbird, a cardinal, and a crow. The hummingbird is to the left of the falcon. The crow is to the right of the cardinal. The cardinal is the second from the right. The quail is the third from the right. The falcon is to the left of the robin. The owl is the second from the left.\\nOptions:\\n(A) The robin is the fourth from the left\\n(B) The owl is the fourth from the left\\n(C) The quail is the fourth from the left\\n(D) The falcon is the fourth from the left\\n(E) The hummingbird is the fourth from the left\\n(F) The cardinal is the fourth from the left\\n(G) The crow is the fourth from the left</td>\n",
       "      <td>(A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The following paragraphs each describe a set of seven objects arranged in a fixed order. The statements are logically consistent within each paragraph. A fruit stand sells seven fruits: kiwis, plums, mangoes, watermelons, pears, peaches, and oranges. The pears are the third-cheapest. The kiwis are the second-most expensive. The pears are more expensive than the plums. The oranges are less expensive than the kiwis. The mangoes are the third-most expensive. The peaches are the second-cheapest.\\nOptions:\\n(A) The kiwis are the second-cheapest\\n(B) The plums are the second-cheapest\\n(C) The mangoes are the second-cheapest\\n(D) The watermelons are the second-cheapest\\n(E) The pears are the second-cheapest\\n(F) The peaches are the second-cheapest\\n(G) The oranges are the second-cheapest</td>\n",
       "      <td>(F)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         input  \\\n",
       "0                                                                                                                                                                                                                                                                                      The following paragraphs each describe a set of seven objects arranged in a fixed order. The statements are logically consistent within each paragraph. In a golf tournament, there were seven golfers: Ana, Eve, Ada, Dan, Rob, Amy, and Joe. Dan finished third. Ana finished above Ada. Amy finished last. Dan finished below Rob. Eve finished below Ada. Rob finished below Joe.\\nOptions:\\n(A) Ana finished third\\n(B) Eve finished third\\n(C) Ada finished third\\n(D) Dan finished third\\n(E) Rob finished third\\n(F) Amy finished third\\n(G) Joe finished third   \n",
       "1                         The following paragraphs each describe a set of seven objects arranged in a fixed order. The statements are logically consistent within each paragraph. In an antique car show, there are seven vehicles: a bus, a motorcyle, a hatchback, a station wagon, a minivan, a truck, and a limousine. The station wagon is the fourth-newest. The motorcyle is newer than the truck. The station wagon is older than the hatchback. The minivan is newer than the hatchback. The bus is newer than the minivan. The truck is newer than the limousine.\\nOptions:\\n(A) The bus is the third-oldest\\n(B) The motorcyle is the third-oldest\\n(C) The hatchback is the third-oldest\\n(D) The station wagon is the third-oldest\\n(E) The minivan is the third-oldest\\n(F) The truck is the third-oldest\\n(G) The limousine is the third-oldest   \n",
       "2  The following paragraphs each describe a set of seven objects arranged in a fixed order. The statements are logically consistent within each paragraph. On a branch, there are seven birds: a hummingbird, a cardinal, a blue jay, an owl, a raven, a quail, and a robin. The hummingbird is to the left of the quail. The robin is to the left of the cardinal. The blue jay is the leftmost. The cardinal is the fourth from the left. The raven is the third from the right. The owl is the third from the left.\\nOptions:\\n(A) The hummingbird is the second from the right\\n(B) The cardinal is the second from the right\\n(C) The blue jay is the second from the right\\n(D) The owl is the second from the right\\n(E) The raven is the second from the right\\n(F) The quail is the second from the right\\n(G) The robin is the second from the right   \n",
       "3  The following paragraphs each describe a set of seven objects arranged in a fixed order. The statements are logically consistent within each paragraph. On a branch, there are seven birds: a robin, an owl, a quail, a falcon, a hummingbird, a cardinal, and a crow. The hummingbird is to the left of the falcon. The crow is to the right of the cardinal. The cardinal is the second from the right. The quail is the third from the right. The falcon is to the left of the robin. The owl is the second from the left.\\nOptions:\\n(A) The robin is the fourth from the left\\n(B) The owl is the fourth from the left\\n(C) The quail is the fourth from the left\\n(D) The falcon is the fourth from the left\\n(E) The hummingbird is the fourth from the left\\n(F) The cardinal is the fourth from the left\\n(G) The crow is the fourth from the left   \n",
       "4                                      The following paragraphs each describe a set of seven objects arranged in a fixed order. The statements are logically consistent within each paragraph. A fruit stand sells seven fruits: kiwis, plums, mangoes, watermelons, pears, peaches, and oranges. The pears are the third-cheapest. The kiwis are the second-most expensive. The pears are more expensive than the plums. The oranges are less expensive than the kiwis. The mangoes are the third-most expensive. The peaches are the second-cheapest.\\nOptions:\\n(A) The kiwis are the second-cheapest\\n(B) The plums are the second-cheapest\\n(C) The mangoes are the second-cheapest\\n(D) The watermelons are the second-cheapest\\n(E) The pears are the second-cheapest\\n(F) The peaches are the second-cheapest\\n(G) The oranges are the second-cheapest   \n",
       "\n",
       "  target  \n",
       "0    (D)  \n",
       "1    (B)  \n",
       "2    (A)  \n",
       "3    (A)  \n",
       "4    (F)  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_logical_seven.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 23\n",
      "Successful requests: 9\n",
      "Total requests made: 47\n",
      "Successful requests: 5\n",
      "Total requests made: 53\n",
      "Successful requests: 3\n",
      "Total requests made: 22\n",
      "Successful requests: 8\n",
      "Total requests made: 17\n",
      "Successful requests: 9\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 42\n",
      "Successful requests: 6\n",
      "Total requests made: 52\n",
      "Successful requests: 4\n",
      "Total requests made: 51\n",
      "Successful requests: 3\n",
      "Total requests made: 44\n",
      "Successful requests: 4\n",
      "Total requests made: 34\n",
      "Successful requests: 6\n"
     ]
    }
   ],
   "source": [
    "groq_logical_seven = groq_line_generate(raw_dataset = logical_deduction_seven, output_dataset = groq_logical_seven, start_idx=0, end_idx=9, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_seven = groq_line_generate(raw_dataset = logical_deduction_seven, output_dataset = groq_logical_seven, start_idx=10, end_idx=19, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_seven = groq_line_generate(raw_dataset = logical_deduction_seven, output_dataset = groq_logical_seven, start_idx=20, end_idx=29, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_seven = groq_line_generate(raw_dataset = logical_deduction_seven, output_dataset = groq_logical_seven, start_idx=30, end_idx=39, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_seven = groq_line_generate(raw_dataset = logical_deduction_seven, output_dataset = groq_logical_seven, start_idx=40, end_idx=49, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_seven = groq_line_generate(raw_dataset = logical_deduction_seven, output_dataset = groq_logical_seven, start_idx=50, end_idx=59, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_seven = groq_line_generate(raw_dataset = logical_deduction_seven, output_dataset = groq_logical_seven, start_idx=60, end_idx=69, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_seven = groq_line_generate(raw_dataset = logical_deduction_seven, output_dataset = groq_logical_seven, start_idx=70, end_idx=79, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_seven = groq_line_generate(raw_dataset = logical_deduction_seven, output_dataset = groq_logical_seven, start_idx=80, end_idx=89, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_seven = groq_line_generate(raw_dataset = logical_deduction_seven, output_dataset = groq_logical_seven, start_idx=90, end_idx=99, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_seven = groq_line_generate(raw_dataset = logical_deduction_seven, output_dataset = groq_logical_seven, start_idx=100, end_idx=109, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_seven = groq_line_generate(raw_dataset = logical_deduction_seven, output_dataset = groq_logical_seven, start_idx=110, end_idx=119, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_seven = groq_line_generate(raw_dataset = logical_deduction_seven, output_dataset = groq_logical_seven, start_idx=120, end_idx=129, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_seven = groq_line_generate(raw_dataset = logical_deduction_seven, output_dataset = groq_logical_seven, start_idx=130, end_idx=139, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_seven = groq_line_generate(raw_dataset = logical_deduction_seven, output_dataset = groq_logical_seven, start_idx=140, end_idx=149, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_seven = groq_line_generate(raw_dataset = logical_deduction_seven, output_dataset = groq_logical_seven, start_idx=150, end_idx=159, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_seven = groq_line_generate(raw_dataset = logical_deduction_seven, output_dataset = groq_logical_seven, start_idx=160, end_idx=169, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_seven = groq_line_generate(raw_dataset = logical_deduction_seven, output_dataset = groq_logical_seven, start_idx=170, end_idx=179, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_seven = groq_line_generate(raw_dataset = logical_deduction_seven, output_dataset = groq_logical_seven, start_idx=180, end_idx=189, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_seven = groq_line_generate(raw_dataset = logical_deduction_seven, output_dataset = groq_logical_seven, start_idx=190, end_idx=199, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_seven = groq_line_generate(raw_dataset = logical_deduction_seven, output_dataset = groq_logical_seven, start_idx=200, end_idx=209, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_seven = groq_line_generate(raw_dataset = logical_deduction_seven, output_dataset = groq_logical_seven, start_idx=210, end_idx=219, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_seven = groq_line_generate(raw_dataset = logical_deduction_seven, output_dataset = groq_logical_seven, start_idx=220, end_idx=229, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_seven = groq_line_generate(raw_dataset = logical_deduction_seven, output_dataset = groq_logical_seven, start_idx=230, end_idx=239, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "\n",
    "groq_logical_seven = groq_line_generate(raw_dataset = logical_deduction_seven, output_dataset = groq_logical_seven, start_idx=240, end_idx=249, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   input         250 non-null    object\n",
      " 1   target        250 non-null    object\n",
      " 2   llama_output  207 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "groq_logical_seven.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame exported successfully to /Users/ezishr/Library/CloudStorage/OneDrive-UniversityofCincinnati/Undergraduate Research/Check points/Big Bench Hard/groq_logical_seven_not_done.csv!\n"
     ]
    }
   ],
   "source": [
    "base_path = r'/Users/ezishr/Library/CloudStorage/OneDrive-UniversityofCincinnati/Undergraduate Research/Check points'\n",
    "file_path = os.path.join(base_path, \"Big Bench Hard\", \"groq_logical_seven_not_done.csv\")\n",
    "os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "groq_logical_seven.to_csv(file_path, index=False)\n",
    "print(f\"DataFrame exported successfully to {file_path}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"groq_logical_seven_not_done.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_null = sample[sample['llama_output'].isnull()]\n",
    "indices = sample_null.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in indices:\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\":\"user\",\n",
    "                \"content\": sample.loc[i, 'input']\n",
    "            },\n",
    "            {\n",
    "                'role': 'system',\n",
    "                'content': \"You only answer the provided options (A, B, C, eg.) to the following questions.\"\n",
    "            }\n",
    "        ],\n",
    "        model = \"llama-3.3-70b-versatile\"\n",
    "    )\n",
    "\n",
    "    sample.loc[i, \"llama_output\"] = chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   input         250 non-null    object\n",
      " 1   target        250 non-null    object\n",
      " 2   llama_output  250 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv(\"groq_logical_seven.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Testing - logical_deduction_three"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The following paragraphs each describe a set of three objects arranged in a fixed order. The statements are logically consistent within each paragraph. On a branch, there are three birds: a blue jay, a quail, and a falcon. The falcon is to the right of the blue jay. The blue jay is to the right of the quail.\\nOptions:\\n(A) The blue jay is the second from the left\\n(B) The quail is the second from the left\\n(C) The falcon is the second from the left</td>\n",
       "      <td>(A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The following paragraphs each describe a set of three objects arranged in a fixed order. The statements are logically consistent within each paragraph. In an antique car show, there are three vehicles: a motorcyle, a limousine, and a convertible. The motorcyle is newer than the limousine. The convertible is newer than the motorcyle.\\nOptions:\\n(A) The motorcyle is the oldest\\n(B) The limousine is the oldest\\n(C) The convertible is the oldest</td>\n",
       "      <td>(B)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The following paragraphs each describe a set of three objects arranged in a fixed order. The statements are logically consistent within each paragraph. On a shelf, there are three books: a blue book, an orange book, and a red book. The blue book is the rightmost. The orange book is the leftmost.\\nOptions:\\n(A) The blue book is the second from the left\\n(B) The orange book is the second from the left\\n(C) The red book is the second from the left</td>\n",
       "      <td>(C)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The following paragraphs each describe a set of three objects arranged in a fixed order. The statements are logically consistent within each paragraph. On a branch, there are three birds: a robin, a blue jay, and a crow. The robin is to the right of the crow. The robin is to the left of the blue jay.\\nOptions:\\n(A) The robin is the rightmost\\n(B) The blue jay is the rightmost\\n(C) The crow is the rightmost</td>\n",
       "      <td>(B)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The following paragraphs each describe a set of three objects arranged in a fixed order. The statements are logically consistent within each paragraph. On a shelf, there are three books: a green book, a red book, and a blue book. The red book is the rightmost. The blue book is to the right of the green book.\\nOptions:\\n(A) The green book is the rightmost\\n(B) The red book is the rightmost\\n(C) The blue book is the rightmost</td>\n",
       "      <td>(B)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                  input  \\\n",
       "0  The following paragraphs each describe a set of three objects arranged in a fixed order. The statements are logically consistent within each paragraph. On a branch, there are three birds: a blue jay, a quail, and a falcon. The falcon is to the right of the blue jay. The blue jay is to the right of the quail.\\nOptions:\\n(A) The blue jay is the second from the left\\n(B) The quail is the second from the left\\n(C) The falcon is the second from the left   \n",
       "1         The following paragraphs each describe a set of three objects arranged in a fixed order. The statements are logically consistent within each paragraph. In an antique car show, there are three vehicles: a motorcyle, a limousine, and a convertible. The motorcyle is newer than the limousine. The convertible is newer than the motorcyle.\\nOptions:\\n(A) The motorcyle is the oldest\\n(B) The limousine is the oldest\\n(C) The convertible is the oldest   \n",
       "2      The following paragraphs each describe a set of three objects arranged in a fixed order. The statements are logically consistent within each paragraph. On a shelf, there are three books: a blue book, an orange book, and a red book. The blue book is the rightmost. The orange book is the leftmost.\\nOptions:\\n(A) The blue book is the second from the left\\n(B) The orange book is the second from the left\\n(C) The red book is the second from the left   \n",
       "3                                             The following paragraphs each describe a set of three objects arranged in a fixed order. The statements are logically consistent within each paragraph. On a branch, there are three birds: a robin, a blue jay, and a crow. The robin is to the right of the crow. The robin is to the left of the blue jay.\\nOptions:\\n(A) The robin is the rightmost\\n(B) The blue jay is the rightmost\\n(C) The crow is the rightmost   \n",
       "4                           The following paragraphs each describe a set of three objects arranged in a fixed order. The statements are logically consistent within each paragraph. On a shelf, there are three books: a green book, a red book, and a blue book. The red book is the rightmost. The blue book is to the right of the green book.\\nOptions:\\n(A) The green book is the rightmost\\n(B) The red book is the rightmost\\n(C) The blue book is the rightmost   \n",
       "\n",
       "  target  \n",
       "0    (A)  \n",
       "1    (B)  \n",
       "2    (C)  \n",
       "3    (B)  \n",
       "4    (B)  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logical_deduction_three = Big_Bench_Json_Processor_my('Big Bench Hard', 'logical_deduction_three_objects.json').convert_df()\n",
    "logical_deduction_three.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logical_deduction_three.info()\n",
    "print(logical_deduction_three['target'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GEMINI Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_logical_deduction_three = gemini_generator(logical_deduction_three, \"You only answer A, B, C  to the following questions.\")\n",
    "\n",
    "df_to_csv(\"Big Bench Hard\", gemini_logical_deduction_three, file_name = \"gemini_logi cal_deduction_three\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GROQ - llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   250 non-null    object\n",
      " 1   target  250 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 4.0+ KB\n"
     ]
    }
   ],
   "source": [
    "groq_logical_three = logical_deduction_three.copy()\n",
    "groq_logical_three.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 12\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 14\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 12\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 14\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 12\n",
      "Successful requests: 10\n",
      "Total requests made: 12\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n"
     ]
    }
   ],
   "source": [
    "groq_logical_three = groq_line_generate(raw_dataset = logical_deduction_three, output_dataset = groq_logical_three, start_idx=0, end_idx=9, system_message=\"You only answer the provided options (A, B, C, eg.) to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_three = groq_line_generate(raw_dataset = logical_deduction_three, output_dataset = groq_logical_three, start_idx=10, end_idx=19, system_message=\"You only answer the provided options (A, B, C, eg.) to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_three = groq_line_generate(raw_dataset = logical_deduction_three, output_dataset = groq_logical_three, start_idx=20, end_idx=29, system_message=\"You only answer the provided options (A, B, C, eg.) to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_three = groq_line_generate(raw_dataset = logical_deduction_three, output_dataset = groq_logical_three, start_idx=30, end_idx=39, system_message=\"You only answer the provided options (A, B, C, eg.) to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_three = groq_line_generate(raw_dataset = logical_deduction_three, output_dataset = groq_logical_three, start_idx=40, end_idx=49, system_message=\"You only answer the provided options (A, B, C, eg.) to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_three = groq_line_generate(raw_dataset = logical_deduction_three, output_dataset = groq_logical_three, start_idx=50, end_idx=59, system_message=\"You only answer the provided options (A, B, C, eg.) to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_three = groq_line_generate(raw_dataset = logical_deduction_three, output_dataset = groq_logical_three, start_idx=60, end_idx=69, system_message=\"You only answer the provided options (A, B, C, eg.) to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_three = groq_line_generate(raw_dataset = logical_deduction_three, output_dataset = groq_logical_three, start_idx=70, end_idx=79, system_message=\"You only answer the provided options (A, B, C, eg.) to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_three = groq_line_generate(raw_dataset = logical_deduction_three, output_dataset = groq_logical_three, start_idx=80, end_idx=89, system_message=\"You only answer the provided options (A, B, C, eg.) to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_three = groq_line_generate(raw_dataset = logical_deduction_three, output_dataset = groq_logical_three, start_idx=90, end_idx=99, system_message=\"You only answer the provided options (A, B, C, eg.) to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_three = groq_line_generate(raw_dataset = logical_deduction_three, output_dataset = groq_logical_three, start_idx=100, end_idx=109, system_message=\"You only answer the provided options (A, B, C, eg.) to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_three = groq_line_generate(raw_dataset = logical_deduction_three, output_dataset = groq_logical_three, start_idx=110, end_idx=119, system_message=\"You only answer the provided options (A, B, C, eg.) to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_three = groq_line_generate(raw_dataset = logical_deduction_three, output_dataset = groq_logical_three, start_idx=120, end_idx=129, system_message=\"You only answer the provided options (A, B, C, eg.) to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_three = groq_line_generate(raw_dataset = logical_deduction_three, output_dataset = groq_logical_three, start_idx=130, end_idx=139, system_message=\"You only answer the provided options (A, B, C, eg.) to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_three = groq_line_generate(raw_dataset = logical_deduction_three, output_dataset = groq_logical_three, start_idx=140, end_idx=149, system_message=\"You only answer the provided options (A, B, C, eg.) to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_three = groq_line_generate(raw_dataset = logical_deduction_three, output_dataset = groq_logical_three, start_idx=150, end_idx=159, system_message=\"You only answer the provided options (A, B, C, eg.) to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_three = groq_line_generate(raw_dataset = logical_deduction_three, output_dataset = groq_logical_three, start_idx=160, end_idx=169, system_message=\"You only answer the provided options (A, B, C, eg.) to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_three = groq_line_generate(raw_dataset = logical_deduction_three, output_dataset = groq_logical_three, start_idx=170, end_idx=179, system_message=\"You only answer the provided options (A, B, C, eg.) to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "groq_logical_three = groq_line_generate(raw_dataset = logical_deduction_three, output_dataset = groq_logical_three, start_idx=180, end_idx=189, system_message=\"You only answer the provided options (A, B, C, eg.) to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_three = groq_line_generate(raw_dataset = logical_deduction_three, output_dataset = groq_logical_three, start_idx=190, end_idx=199, system_message=\"You only answer the provided options (A, B, C, eg.) to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_three = groq_line_generate(raw_dataset = logical_deduction_three, output_dataset = groq_logical_three, start_idx=200, end_idx=209, system_message=\"You only answer the provided options (A, B, C, eg.) to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_three = groq_line_generate(raw_dataset = logical_deduction_three, output_dataset = groq_logical_three, start_idx=210, end_idx=219, system_message=\"You only answer the provided options (A, B, C, eg.) to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_three = groq_line_generate(raw_dataset = logical_deduction_three, output_dataset = groq_logical_three, start_idx=220, end_idx=229, system_message=\"You only answer the provided options (A, B, C, eg.) to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_three = groq_line_generate(raw_dataset = logical_deduction_three, output_dataset = groq_logical_three, start_idx=230, end_idx=239, system_message=\"You only answer the provided options (A, B, C, eg.) to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_logical_three = groq_line_generate(raw_dataset = logical_deduction_three, output_dataset = groq_logical_three, start_idx=240, end_idx=249, system_message=\"You only answer the provided options (A, B, C, eg.) to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame exported successfully to /Users/ezishr/Library/CloudStorage/OneDrive-UniversityofCincinnati/Undergraduate Research/Check points/Big Bench Hard/groq_logical_three.csv!\n"
     ]
    }
   ],
   "source": [
    "df_to_csv(\"Big Bench Hard\", groq_logical_three, file_name = \"groq_logical_three\", output_col = \"llama_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Testing - movie_recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Find a movie similar to Batman, The Mask, The Fugitive, Pretty Woman:\\nOptions:\\n(A) The Front Page\\n(B) Maelstrom\\n(C) The Lion King\\n(D) Lamerica</td>\n",
       "      <td>(C)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Find a movie similar to The Sixth Sense, The Matrix, Forrest Gump, The Shawshank Redemption:\\nOptions:\\n(A) Street Fighter II The Animated Movie\\n(B) The Sheltering Sky\\n(C) The Boy Who Could Fly\\n(D) Terminator 2 Judgment Day</td>\n",
       "      <td>(D)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Find a movie similar to Schindler's List, Braveheart, The Silence of the Lambs, Tombstone:\\nOptions:\\n(A) Orlando\\n(B) Guilty of Romance\\n(C) Forrest Gump\\n(D) All the Real Girls</td>\n",
       "      <td>(C)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Find a movie similar to Terminator 2 Judgment Day, The Fugitive, The Shawshank Redemption, Dead Man Walking:\\nOptions:\\n(A) Walk\\n(B) Don't Run\\n(C) Shaun the Sheep Movie\\n(D) Rocky IV\\n(E) Braveheart</td>\n",
       "      <td>(E)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Find a movie similar to Braveheart, The Mask, The Fugitive, Batman:\\nOptions:\\n(A) Club Dread\\n(B) George Washington\\n(C) Schindler's List\\n(D) Once Upon a Time in America</td>\n",
       "      <td>(C)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                input  \\\n",
       "0                                                                                 Find a movie similar to Batman, The Mask, The Fugitive, Pretty Woman:\\nOptions:\\n(A) The Front Page\\n(B) Maelstrom\\n(C) The Lion King\\n(D) Lamerica   \n",
       "1  Find a movie similar to The Sixth Sense, The Matrix, Forrest Gump, The Shawshank Redemption:\\nOptions:\\n(A) Street Fighter II The Animated Movie\\n(B) The Sheltering Sky\\n(C) The Boy Who Could Fly\\n(D) Terminator 2 Judgment Day   \n",
       "2                                                  Find a movie similar to Schindler's List, Braveheart, The Silence of the Lambs, Tombstone:\\nOptions:\\n(A) Orlando\\n(B) Guilty of Romance\\n(C) Forrest Gump\\n(D) All the Real Girls   \n",
       "3                            Find a movie similar to Terminator 2 Judgment Day, The Fugitive, The Shawshank Redemption, Dead Man Walking:\\nOptions:\\n(A) Walk\\n(B) Don't Run\\n(C) Shaun the Sheep Movie\\n(D) Rocky IV\\n(E) Braveheart   \n",
       "4                                                         Find a movie similar to Braveheart, The Mask, The Fugitive, Batman:\\nOptions:\\n(A) Club Dread\\n(B) George Washington\\n(C) Schindler's List\\n(D) Once Upon a Time in America   \n",
       "\n",
       "  target  \n",
       "0    (C)  \n",
       "1    (D)  \n",
       "2    (C)  \n",
       "3    (E)  \n",
       "4    (C)  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_recommendation = Big_Bench_Json_Processor_my('Big Bench Hard', 'movie_recommendation.json').convert_df()\n",
    "\n",
    "movie_recommendation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['(C)', '(D)', '(E)', '(B)', '(A)', 'Monsters, Inc'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_recommendation['target'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_recommendation[movie_recommendation['target']=='Monsters, Inc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GEMINI Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_movie_recommendation = gemini_generator(movie_recommendation, \"Your answers to the following question should be in the provided options.\")\n",
    "\n",
    "df_to_csv(\"Big Bench Hard\", gemini_movie_recommendation, file_name = \"gemini_movie_recommendation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GROQ - llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_movie_recommendation = movie_recommendation.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 14\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 12\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n"
     ]
    }
   ],
   "source": [
    "groq_movie_recommendation = groq_line_generate(raw_dataset = movie_recommendation, output_dataset = groq_movie_recommendation, start_idx=0, end_idx=9, system_message=\"Your answers to the following question should be in the provided options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_movie_recommendation = groq_line_generate(raw_dataset = movie_recommendation, output_dataset = groq_movie_recommendation, start_idx=10, end_idx=19, system_message=\"Your answers to the following question should be in the provided options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_movie_recommendation = groq_line_generate(raw_dataset = movie_recommendation, output_dataset = groq_movie_recommendation, start_idx=20, end_idx=29, system_message=\"Your answers to the following question should be in the provided options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_movie_recommendation = groq_line_generate(raw_dataset = movie_recommendation, output_dataset = groq_movie_recommendation, start_idx=30, end_idx=39, system_message=\"Your answers to the following question should be in the provided options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_movie_recommendation = groq_line_generate(raw_dataset = movie_recommendation, output_dataset = groq_movie_recommendation, start_idx=40, end_idx=49, system_message=\"Your answers to the following question should be in the provided options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_movie_recommendation = groq_line_generate(raw_dataset = movie_recommendation, output_dataset = groq_movie_recommendation, start_idx=50, end_idx=59, system_message=\"Your answers to the following question should be in the provided options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_movie_recommendation = groq_line_generate(raw_dataset = movie_recommendation, output_dataset = groq_movie_recommendation, start_idx=60, end_idx=69, system_message=\"Your answers to the following question should be in the provided options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_movie_recommendation = groq_line_generate(raw_dataset = movie_recommendation, output_dataset = groq_movie_recommendation, start_idx=70, end_idx=79, system_message=\"Your answers to the following question should be in the provided options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_movie_recommendation = groq_line_generate(raw_dataset = movie_recommendation, output_dataset = groq_movie_recommendation, start_idx=80, end_idx=89, system_message=\"Your answers to the following question should be in the provided options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_movie_recommendation = groq_line_generate(raw_dataset = movie_recommendation, output_dataset = groq_movie_recommendation, start_idx=90, end_idx=99, system_message=\"Your answers to the following question should be in the provided options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_movie_recommendation = groq_line_generate(raw_dataset = movie_recommendation, output_dataset = groq_movie_recommendation, start_idx=100, end_idx=109, system_message=\"Your answers to the following question should be in the provided options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_movie_recommendation = groq_line_generate(raw_dataset = movie_recommendation, output_dataset = groq_movie_recommendation, start_idx=110, end_idx=119, system_message=\"Your answers to the following question should be in the provided options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_movie_recommendation = groq_line_generate(raw_dataset = movie_recommendation, output_dataset = groq_movie_recommendation, start_idx=120, end_idx=129, system_message=\"Your answers to the following question should be in the provided options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_movie_recommendation = groq_line_generate(raw_dataset = movie_recommendation, output_dataset = groq_movie_recommendation, start_idx=130, end_idx=139, system_message=\"Your answers to the following question should be in the provided options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_movie_recommendation = groq_line_generate(raw_dataset = movie_recommendation, output_dataset = groq_movie_recommendation, start_idx=140, end_idx=149, system_message=\"Your answers to the following question should be in the provided options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_movie_recommendation = groq_line_generate(raw_dataset = movie_recommendation, output_dataset = groq_movie_recommendation, start_idx=150, end_idx=159, system_message=\"Your answers to the following question should be in the provided options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_movie_recommendation = groq_line_generate(raw_dataset = movie_recommendation, output_dataset = groq_movie_recommendation, start_idx=160, end_idx=169, system_message=\"Your answers to the following question should be in the provided options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_movie_recommendation = groq_line_generate(raw_dataset = movie_recommendation, output_dataset = groq_movie_recommendation, start_idx=170, end_idx=179, system_message=\"Your answers to the following question should be in the provided options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_movie_recommendation = groq_line_generate(raw_dataset = movie_recommendation, output_dataset = groq_movie_recommendation, start_idx=180, end_idx=189, system_message=\"Your answers to the following question should be in the provided options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_movie_recommendation = groq_line_generate(raw_dataset = movie_recommendation, output_dataset = groq_movie_recommendation, start_idx=190, end_idx=199, system_message=\"Your answers to the following question should be in the provided options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_movie_recommendation = groq_line_generate(raw_dataset = movie_recommendation, output_dataset = groq_movie_recommendation, start_idx=200, end_idx=209, system_message=\"Your answers to the following question should be in the provided options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_movie_recommendation = groq_line_generate(raw_dataset = movie_recommendation, output_dataset = groq_movie_recommendation, start_idx=210, end_idx=219, system_message=\"Your answers to the following question should be in the provided options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_movie_recommendation = groq_line_generate(raw_dataset = movie_recommendation, output_dataset = groq_movie_recommendation, start_idx=220, end_idx=229, system_message=\"Your answers to the following question should be in the provided options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_movie_recommendation = groq_line_generate(raw_dataset = movie_recommendation, output_dataset = groq_movie_recommendation, start_idx=230, end_idx=239, system_message=\"Your answers to the following question should be in the provided options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_movie_recommendation = groq_line_generate(raw_dataset = movie_recommendation, output_dataset = groq_movie_recommendation, start_idx=240, end_idx=249, system_message=\"Your answers to the following question should be in the provided options.\", model_name=\"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame exported successfully to /Users/ezishr/Library/CloudStorage/OneDrive-UniversityofCincinnati/Undergraduate Research/Check points/Big Bench Hard/groq_movie_recommendation.csv!\n"
     ]
    }
   ],
   "source": [
    "df_to_csv(\"Big Bench Hard\", groq_movie_recommendation, file_name = \"groq_movie_recommendation\", output_col = \"llama_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Testing - multistep_arithmetic_two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>((-1 + 2 + 9 * 5) - (-2 + -4 + -4 * -7)) =</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>((-9 * -5 - 6 + -2) - (-8 - -6 * -3 * 1)) =</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>((3 * -3 * 6 + -5) - (-2 + -7 - 7 - -7)) =</td>\n",
       "      <td>-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>((6 * -6 * 8 * 1) * (-1 * 7 * -6 + -2)) =</td>\n",
       "      <td>-11520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>((-6 - -4 + 9 + 0) + (1 + -4 - -9 * 6)) =</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         input  target\n",
       "0   ((-1 + 2 + 9 * 5) - (-2 + -4 + -4 * -7)) =      24\n",
       "1  ((-9 * -5 - 6 + -2) - (-8 - -6 * -3 * 1)) =      63\n",
       "2   ((3 * -3 * 6 + -5) - (-2 + -7 - 7 - -7)) =     -50\n",
       "3    ((6 * -6 * 8 * 1) * (-1 * 7 * -6 + -2)) =  -11520\n",
       "4    ((-6 - -4 + 9 + 0) + (1 + -4 - -9 * 6)) =      58"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multistep_arithmetic_two = Big_Bench_Json_Processor_my('Big Bench Hard', 'multistep_arithmetic_two.json').convert_df()\n",
    "multistep_arithmetic_two.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['24', '63', '-50', '-11520', '58', '-33', '49', '-80', '702', '20',\n",
       "       '54', '-8840', '42', '26', '-1960', '1608', '31', '2', '-92', '5',\n",
       "       '-1', '-35', '-22', '-5', '-3400', '71', '-3', '25', '416', '40',\n",
       "       '-19', '44', '72', '-170', '-20', '-9', '65', '70', '976', '2240',\n",
       "       '57', '150', '37', '84', '-76', '-1343', '-37', '59', '36',\n",
       "       '38556', '89', '-48', '211', '83', '-51', '60', '77', '4', '-46',\n",
       "       '15', '365', '-99', '88', '-55', '48', '38', '41', '-320', '-144',\n",
       "       '-26', '30', '-10', '443', '14', '33', '-217', '-262', '-1300',\n",
       "       '-15', '16', '-39960', '76', '-8304', '-17', '-13', '94', '-21',\n",
       "       '-3850', '-8', '-3136', '12', '34', '140', '-168', '-6', '-57',\n",
       "       '8', '-330', '1980', '78', '11', '-264', '0', '-83', '-391', '10',\n",
       "       '45', '-196', '35', '3420', '-90', '-81', '-89', '343', '-24',\n",
       "       '-39', '-60', '-284', '-4', '360', '32', '220', '18', '-18', '3',\n",
       "       '-84', '-71', '-343', '-5453', '101', '-43', '-61', '-25', '21',\n",
       "       '27', '-224', '-151', '-110', '198', '-32', '-554', '-11', '-240',\n",
       "       '2652', '312', '522', '-52', '237', '-340', '107', '1168', '181',\n",
       "       '-23', '7056', '-7', '52', '330', '17', '-2146', '-113', '-658',\n",
       "       '-192', '123', '-169', '630', '120', '128', '3255', '346', '-38',\n",
       "       '-30', '-160', '474', '-36', '-97', '867', '-147', '11050', '55',\n",
       "       '-114', '336', '216', '250992', '464', '-1968'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multistep_arithmetic_two['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   250 non-null    object\n",
      " 1   target  250 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 4.0+ KB\n"
     ]
    }
   ],
   "source": [
    "multistep_arithmetic_two.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GEMINI Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_multistep_arithmetic_two = gemini_generator(multistep_arithmetic_two, \"Your answers should only be numbers to the following questions.\")\n",
    "\n",
    "df_to_csv(\"Big Bench Hard\", gemini_multistep_arithmetic_two, file_name = \"gemini_multistep_arithmetic_two\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GROQ - llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   250 non-null    object\n",
      " 1   target  250 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 4.0+ KB\n"
     ]
    }
   ],
   "source": [
    "groq_multistep_arithmetic_two = multistep_arithmetic_two.copy()\n",
    "groq_multistep_arithmetic_two.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 12\n",
      "Successful requests: 10\n",
      "Total requests made: 34\n",
      "Successful requests: 6\n",
      "Total requests made: 42\n",
      "Successful requests: 4\n",
      "Total requests made: 50\n",
      "Successful requests: 2\n",
      "Total requests made: 43\n",
      "Successful requests: 5\n",
      "Total requests made: 39\n",
      "Successful requests: 5\n",
      "Total requests made: 46\n",
      "Successful requests: 4\n",
      "Total requests made: 55\n",
      "Successful requests: 3\n",
      "Total requests made: 54\n",
      "Successful requests: 2\n",
      "Total requests made: 55\n",
      "Successful requests: 3\n",
      "Total requests made: 47\n",
      "Successful requests: 3\n",
      "Total requests made: 34\n",
      "Successful requests: 6\n",
      "Total requests made: 47\n",
      "Successful requests: 3\n",
      "Total requests made: 44\n",
      "Successful requests: 4\n",
      "Total requests made: 50\n",
      "Successful requests: 4\n",
      "Total requests made: 47\n",
      "Successful requests: 3\n",
      "Total requests made: 47\n",
      "Successful requests: 3\n",
      "Total requests made: 40\n",
      "Successful requests: 4\n",
      "Total requests made: 43\n",
      "Successful requests: 5\n",
      "Total requests made: 14\n",
      "Successful requests: 10\n",
      "Total requests made: 44\n",
      "Successful requests: 4\n",
      "Total requests made: 16\n",
      "Successful requests: 10\n",
      "Total requests made: 12\n",
      "Successful requests: 10\n",
      "Total requests made: 12\n",
      "Successful requests: 10\n"
     ]
    }
   ],
   "source": [
    "groq_multistep_arithmetic_two = groq_line_generate(raw_dataset = multistep_arithmetic_two, output_dataset = groq_multistep_arithmetic_two, start_idx=0, end_idx=9, system_message=\"Your answers should only be numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_multistep_arithmetic_two = groq_line_generate(raw_dataset = multistep_arithmetic_two, output_dataset = groq_multistep_arithmetic_two, start_idx=10, end_idx=19, system_message=\"Your answers should only be numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_multistep_arithmetic_two = groq_line_generate(raw_dataset = multistep_arithmetic_two, output_dataset = groq_multistep_arithmetic_two, start_idx=20, end_idx=29, system_message=\"Your answers should only be numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_multistep_arithmetic_two = groq_line_generate(raw_dataset = multistep_arithmetic_two, output_dataset = groq_multistep_arithmetic_two, start_idx=30, end_idx=39, system_message=\"Your answers should only be numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_multistep_arithmetic_two = groq_line_generate(raw_dataset = multistep_arithmetic_two, output_dataset = groq_multistep_arithmetic_two, start_idx=40, end_idx=49, system_message=\"Your answers should only be numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_multistep_arithmetic_two = groq_line_generate(raw_dataset = multistep_arithmetic_two, output_dataset = groq_multistep_arithmetic_two, start_idx=50, end_idx=59, system_message=\"Your answers should only be numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_multistep_arithmetic_two = groq_line_generate(raw_dataset = multistep_arithmetic_two, output_dataset = groq_multistep_arithmetic_two, start_idx=60, end_idx=69, system_message=\"Your answers should only be numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_multistep_arithmetic_two = groq_line_generate(raw_dataset = multistep_arithmetic_two, output_dataset = groq_multistep_arithmetic_two, start_idx=70, end_idx=79, system_message=\"Your answers should only be numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_multistep_arithmetic_two = groq_line_generate(raw_dataset = multistep_arithmetic_two, output_dataset = groq_multistep_arithmetic_two, start_idx=80, end_idx=89, system_message=\"Your answers should only be numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_multistep_arithmetic_two = groq_line_generate(raw_dataset = multistep_arithmetic_two, output_dataset = groq_multistep_arithmetic_two, start_idx=90, end_idx=99, system_message=\"Your answers should only be numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_multistep_arithmetic_two = groq_line_generate(raw_dataset = multistep_arithmetic_two, output_dataset = groq_multistep_arithmetic_two, start_idx=100, end_idx=109, system_message=\"Your answers should only be numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_multistep_arithmetic_two = groq_line_generate(raw_dataset = multistep_arithmetic_two, output_dataset = groq_multistep_arithmetic_two, start_idx=110, end_idx=119, system_message=\"Your answers should only be numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_multistep_arithmetic_two = groq_line_generate(raw_dataset = multistep_arithmetic_two, output_dataset = groq_multistep_arithmetic_two, start_idx=120, end_idx=129, system_message=\"Your answers should only be numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_multistep_arithmetic_two = groq_line_generate(raw_dataset = multistep_arithmetic_two, output_dataset = groq_multistep_arithmetic_two, start_idx=130, end_idx=139, system_message=\"Your answers should only be numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_multistep_arithmetic_two = groq_line_generate(raw_dataset = multistep_arithmetic_two, output_dataset = groq_multistep_arithmetic_two, start_idx=140, end_idx=149, system_message=\"Your answers should only be numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_multistep_arithmetic_two = groq_line_generate(raw_dataset = multistep_arithmetic_two, output_dataset = groq_multistep_arithmetic_two, start_idx=150, end_idx=159, system_message=\"Your answers should only be numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_multistep_arithmetic_two = groq_line_generate(raw_dataset = multistep_arithmetic_two, output_dataset = groq_multistep_arithmetic_two, start_idx=160, end_idx=169, system_message=\"Your answers should only be numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_multistep_arithmetic_two = groq_line_generate(raw_dataset = multistep_arithmetic_two, output_dataset = groq_multistep_arithmetic_two, start_idx=170, end_idx=179, system_message=\"Your answers should only be numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_multistep_arithmetic_two = groq_line_generate(raw_dataset = multistep_arithmetic_two, output_dataset = groq_multistep_arithmetic_two, start_idx=180, end_idx=189, system_message=\"Your answers should only be numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_multistep_arithmetic_two = groq_line_generate(raw_dataset = multistep_arithmetic_two, output_dataset = groq_multistep_arithmetic_two, start_idx=190, end_idx=199, system_message=\"Your answers should only be numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_multistep_arithmetic_two = groq_line_generate(raw_dataset = multistep_arithmetic_two, output_dataset = groq_multistep_arithmetic_two, start_idx=200, end_idx=209, system_message=\"Your answers should only be numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_multistep_arithmetic_two = groq_line_generate(raw_dataset = multistep_arithmetic_two, output_dataset = groq_multistep_arithmetic_two, start_idx=210, end_idx=219, system_message=\"Your answers should only be numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_multistep_arithmetic_two = groq_line_generate(raw_dataset = multistep_arithmetic_two, output_dataset = groq_multistep_arithmetic_two, start_idx=220, end_idx=229, system_message=\"Your answers should only be numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_multistep_arithmetic_two = groq_line_generate(raw_dataset = multistep_arithmetic_two, output_dataset = groq_multistep_arithmetic_two, start_idx=230, end_idx=239, system_message=\"Your answers should only be numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_multistep_arithmetic_two = groq_line_generate(raw_dataset = multistep_arithmetic_two, output_dataset = groq_multistep_arithmetic_two, start_idx=240, end_idx=249, system_message=\"Your answers should only be numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   input         250 non-null    object\n",
      " 1   target        250 non-null    object\n",
      " 2   llama_output  133 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "groq_multistep_arithmetic_two.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export failed: DataFrame contains null values in 'gemini_output'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_csv(\"Big Bench Hard\", groq_multistep_arithmetic_two, file_name = \"groq_multistep_arithmetic_two\", output_col = \"llama_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_multistep_arithmetic_two.to_csv(\"groq_multistep_arithmetic_two_not_done.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Testing - navigate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   250 non-null    object\n",
      " 1   target  250 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 4.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If you follow these instructions, do you return to the starting point? Always face forward. Take 1 step backward. Take 9 steps left. Take 2 steps backward. Take 6 steps forward. Take 4 steps forward. Take 4 steps backward. Take 3 steps right.\\nOptions:\\n- Yes\\n- No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If you follow these instructions, do you return to the starting point? Always face forward. Take 10 steps left. Take 10 steps forward. Take 7 steps forward. Take 2 steps forward.\\nOptions:\\n- Yes\\n- No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you follow these instructions, do you return to the starting point? Take 1 step. Take 10 steps. Take 4 steps. Take 1 step. Take 10 steps. Turn right. Turn around.\\nOptions:\\n- Yes\\n- No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you follow these instructions, do you return to the starting point? Always face forward. Take 1 step right. Take 3 steps left. Take 2 steps right.\\nOptions:\\n- Yes\\n- No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If you follow these instructions, do you return to the starting point? Always face forward. Take 10 steps backward. Take 7 steps backward. Take 8 steps right. Take 6 steps right. Take 3 steps left.\\nOptions:\\n- Yes\\n- No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                       input  \\\n",
       "0  If you follow these instructions, do you return to the starting point? Always face forward. Take 1 step backward. Take 9 steps left. Take 2 steps backward. Take 6 steps forward. Take 4 steps forward. Take 4 steps backward. Take 3 steps right.\\nOptions:\\n- Yes\\n- No   \n",
       "1                                                                  If you follow these instructions, do you return to the starting point? Always face forward. Take 10 steps left. Take 10 steps forward. Take 7 steps forward. Take 2 steps forward.\\nOptions:\\n- Yes\\n- No   \n",
       "2                                                                               If you follow these instructions, do you return to the starting point? Take 1 step. Take 10 steps. Take 4 steps. Take 1 step. Take 10 steps. Turn right. Turn around.\\nOptions:\\n- Yes\\n- No   \n",
       "3                                                                                               If you follow these instructions, do you return to the starting point? Always face forward. Take 1 step right. Take 3 steps left. Take 2 steps right.\\nOptions:\\n- Yes\\n- No   \n",
       "4                                               If you follow these instructions, do you return to the starting point? Always face forward. Take 10 steps backward. Take 7 steps backward. Take 8 steps right. Take 6 steps right. Take 3 steps left.\\nOptions:\\n- Yes\\n- No   \n",
       "\n",
       "  target  \n",
       "0     No  \n",
       "1     No  \n",
       "2     No  \n",
       "3    Yes  \n",
       "4     No  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "navigate = Big_Bench_Json_Processor_my('Big Bench Hard', 'navigate.json').convert_df()\n",
    "navigate.info()\n",
    "navigate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "navigate['target'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GEMINI Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_navigate = gemini_generator(navigate, \"You only answer Yes of No to the following questions.\")\n",
    "\n",
    "df_to_csv(\"Big Bench Hard\", gemini_navigate, file_name = \"gemini_navigate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GROQ - llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   250 non-null    object\n",
      " 1   target  250 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 4.0+ KB\n"
     ]
    }
   ],
   "source": [
    "groq_navigate = navigate.copy()\n",
    "groq_navigate.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n"
     ]
    }
   ],
   "source": [
    "groq_navigate = groq_line_generate(raw_dataset = navigate, output_dataset = groq_navigate, start_idx=0, end_idx=9, system_message=\"You only answer Yes of No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_navigate = groq_line_generate(raw_dataset = navigate, output_dataset = groq_navigate, start_idx=10, end_idx=19, system_message=\"You only answer Yes of No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_navigate = groq_line_generate(raw_dataset = navigate, output_dataset = groq_navigate, start_idx=20, end_idx=29, system_message=\"You only answer Yes of No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_navigate = groq_line_generate(raw_dataset = navigate, output_dataset = groq_navigate, start_idx=30, end_idx=39, system_message=\"You only answer Yes of No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_navigate = groq_line_generate(raw_dataset = navigate, output_dataset = groq_navigate, start_idx=40, end_idx=49, system_message=\"You only answer Yes of No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_navigate = groq_line_generate(raw_dataset = navigate, output_dataset = groq_navigate, start_idx=50, end_idx=59, system_message=\"You only answer Yes of No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_navigate = groq_line_generate(raw_dataset = navigate, output_dataset = groq_navigate, start_idx=60, end_idx=69, system_message=\"You only answer Yes of No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_navigate = groq_line_generate(raw_dataset = navigate, output_dataset = groq_navigate, start_idx=70, end_idx=79, system_message=\"You only answer Yes of No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_navigate = groq_line_generate(raw_dataset = navigate, output_dataset = groq_navigate, start_idx=80, end_idx=89, system_message=\"You only answer Yes of No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_navigate = groq_line_generate(raw_dataset = navigate, output_dataset = groq_navigate, start_idx=90, end_idx=99, system_message=\"You only answer Yes of No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_navigate = groq_line_generate(raw_dataset = navigate, output_dataset = groq_navigate, start_idx=100, end_idx=109, system_message=\"You only answer Yes of No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_navigate = groq_line_generate(raw_dataset = navigate, output_dataset = groq_navigate, start_idx=110, end_idx=119, system_message=\"You only answer Yes of No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_navigate = groq_line_generate(raw_dataset = navigate, output_dataset = groq_navigate, start_idx=120, end_idx=129, system_message=\"You only answer Yes of No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_navigate = groq_line_generate(raw_dataset = navigate, output_dataset = groq_navigate, start_idx=130, end_idx=139, system_message=\"You only answer Yes of No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_navigate = groq_line_generate(raw_dataset = navigate, output_dataset = groq_navigate, start_idx=140, end_idx=149, system_message=\"You only answer Yes of No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_navigate = groq_line_generate(raw_dataset = navigate, output_dataset = groq_navigate, start_idx=150, end_idx=159, system_message=\"You only answer Yes of No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_navigate = groq_line_generate(raw_dataset = navigate, output_dataset = groq_navigate, start_idx=160, end_idx=169, system_message=\"You only answer Yes of No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_navigate = groq_line_generate(raw_dataset = navigate, output_dataset = groq_navigate, start_idx=170, end_idx=179, system_message=\"You only answer Yes of No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_navigate = groq_line_generate(raw_dataset = navigate, output_dataset = groq_navigate, start_idx=180, end_idx=189, system_message=\"You only answer Yes of No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_navigate = groq_line_generate(raw_dataset = navigate, output_dataset = groq_navigate, start_idx=190, end_idx=199, system_message=\"You only answer Yes of No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_navigate = groq_line_generate(raw_dataset = navigate, output_dataset = groq_navigate, start_idx=200, end_idx=209, system_message=\"You only answer Yes of No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_navigate = groq_line_generate(raw_dataset = navigate, output_dataset = groq_navigate, start_idx=210, end_idx=219, system_message=\"You only answer Yes of No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_navigate = groq_line_generate(raw_dataset = navigate, output_dataset = groq_navigate, start_idx=220, end_idx=229, system_message=\"You only answer Yes of No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_navigate = groq_line_generate(raw_dataset = navigate, output_dataset = groq_navigate, start_idx=230, end_idx=239, system_message=\"You only answer Yes of No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_navigate = groq_line_generate(raw_dataset = navigate, output_dataset = groq_navigate, start_idx=240, end_idx=249, system_message=\"You only answer Yes of No to the following questions.\", model_name=\"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame exported successfully to /Users/ezishr/Library/CloudStorage/OneDrive-UniversityofCincinnati/Undergraduate Research/Check points/Big Bench Hard/groq_navigate.csv!\n"
     ]
    }
   ],
   "source": [
    "df_to_csv(\"Big Bench Hard\", groq_navigate, file_name = \"groq_navigate\", output_col = \"llama_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My testing - object_counting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   250 non-null    object\n",
      " 1   target  250 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 4.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have a flute, a piano, a trombone, four stoves, a violin, an accordion, a clarinet, a drum, two lamps, and a trumpet. How many musical instruments do I have?</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have an apple, three bananas, a strawberry, a peach, three oranges, a plum, a raspberry, two grapes, a nectarine, and a blackberry. How many fruits do I have?</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have a fridge, a chair, and a microwave. How many objects do I have?</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I have three blackberries, two strawberries, an apple, three oranges, a nectarine, a grape, a peach, a banana, and a plum. How many fruits do I have?</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have a couch, an oven, two microwaves, and a fridge. How many objects do I have?</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                              input  \\\n",
       "0   I have a flute, a piano, a trombone, four stoves, a violin, an accordion, a clarinet, a drum, two lamps, and a trumpet. How many musical instruments do I have?   \n",
       "1  I have an apple, three bananas, a strawberry, a peach, three oranges, a plum, a raspberry, two grapes, a nectarine, and a blackberry. How many fruits do I have?   \n",
       "2                                                                                            I have a fridge, a chair, and a microwave. How many objects do I have?   \n",
       "3             I have three blackberries, two strawberries, an apple, three oranges, a nectarine, a grape, a peach, a banana, and a plum. How many fruits do I have?   \n",
       "4                                                                                I have a couch, an oven, two microwaves, and a fridge. How many objects do I have?   \n",
       "\n",
       "  target  \n",
       "0      8  \n",
       "1     15  \n",
       "2      3  \n",
       "3     14  \n",
       "4      5  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_counting = Big_Bench_Json_Processor_my('Big Bench Hard', 'object_counting.json').convert_df()\n",
    "object_counting.info()\n",
    "object_counting['target'].unique()\n",
    "object_counting.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GEMINI Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_object_counting = gemini_generator(object_counting, \"You only answer the number of objects to the following questions.\")\n",
    "\n",
    "df_to_csv(\"Big Bench Hard\", gemini_object_counting, file_name = \"gemini_object_counting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_counting.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-flash\",\n",
    "  system_instruction=\"You only answer True or False to the following questions.\",)\n",
    "\n",
    "model.generate_content(object_counting['input'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GROQ - llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_object_counting = object_counting.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n"
     ]
    }
   ],
   "source": [
    "groq_object_counting = groq_line_generate(raw_dataset = object_counting, output_dataset = groq_object_counting, start_idx=0, end_idx=9, system_message=\"You only answer numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_object_counting = groq_line_generate(raw_dataset = object_counting, output_dataset = groq_object_counting, start_idx=10, end_idx=19, system_message=\"You only answer numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_object_counting = groq_line_generate(raw_dataset = object_counting, output_dataset = groq_object_counting, start_idx=20, end_idx=29, system_message=\"You only answer numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_object_counting = groq_line_generate(raw_dataset = object_counting, output_dataset = groq_object_counting, start_idx=30, end_idx=39, system_message=\"You only answer numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_object_counting = groq_line_generate(raw_dataset = object_counting, output_dataset = groq_object_counting, start_idx=40, end_idx=49, system_message=\"You only answer numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_object_counting = groq_line_generate(raw_dataset = object_counting, output_dataset = groq_object_counting, start_idx=50, end_idx=59, system_message=\"You only answer numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_object_counting = groq_line_generate(raw_dataset = object_counting, output_dataset = groq_object_counting, start_idx=60, end_idx=69, system_message=\"You only answer numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_object_counting = groq_line_generate(raw_dataset = object_counting, output_dataset = groq_object_counting, start_idx=70, end_idx=79, system_message=\"You only answer numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_object_counting = groq_line_generate(raw_dataset = object_counting, output_dataset = groq_object_counting, start_idx=80, end_idx=89, system_message=\"You only answer numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_object_counting = groq_line_generate(raw_dataset = object_counting, output_dataset = groq_object_counting, start_idx=90, end_idx=99, system_message=\"You only answer numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_object_counting = groq_line_generate(raw_dataset = object_counting, output_dataset = groq_object_counting, start_idx=100, end_idx=109, system_message=\"You only answer numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_object_counting = groq_line_generate(raw_dataset = object_counting, output_dataset = groq_object_counting, start_idx=110, end_idx=119, system_message=\"You only answer numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_object_counting = groq_line_generate(raw_dataset = object_counting, output_dataset = groq_object_counting, start_idx=120, end_idx=129, system_message=\"You only answer numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_object_counting = groq_line_generate(raw_dataset = object_counting, output_dataset = groq_object_counting, start_idx=130, end_idx=139, system_message=\"You only answer numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_object_counting = groq_line_generate(raw_dataset = object_counting, output_dataset = groq_object_counting, start_idx=140, end_idx=149, system_message=\"You only answer numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_object_counting = groq_line_generate(raw_dataset = object_counting, output_dataset = groq_object_counting, start_idx=150, end_idx=159, system_message=\"You only answer numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_object_counting = groq_line_generate(raw_dataset = object_counting, output_dataset = groq_object_counting, start_idx=160, end_idx=169, system_message=\"You only answer numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_object_counting = groq_line_generate(raw_dataset = object_counting, output_dataset = groq_object_counting, start_idx=170, end_idx=179, system_message=\"You only answer numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_object_counting = groq_line_generate(raw_dataset = object_counting, output_dataset = groq_object_counting, start_idx=180, end_idx=189, system_message=\"You only answer numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_object_counting = groq_line_generate(raw_dataset = object_counting, output_dataset = groq_object_counting, start_idx=190, end_idx=199, system_message=\"You only answer numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_object_counting = groq_line_generate(raw_dataset = object_counting, output_dataset = groq_object_counting, start_idx=200, end_idx=209, system_message=\"You only answer numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_object_counting = groq_line_generate(raw_dataset = object_counting, output_dataset = groq_object_counting, start_idx=210, end_idx=219, system_message=\"You only answer numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_object_counting = groq_line_generate(raw_dataset = object_counting, output_dataset = groq_object_counting, start_idx=220, end_idx=229, system_message=\"You only answer numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_object_counting = groq_line_generate(raw_dataset = object_counting, output_dataset = groq_object_counting, start_idx=230, end_idx=239, system_message=\"You only answer numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_object_counting = groq_line_generate(raw_dataset = object_counting, output_dataset = groq_object_counting, start_idx=240, end_idx=249, system_message=\"You only answer numbers to the following questions.\", model_name=\"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame exported successfully to /Users/ezishr/Library/CloudStorage/OneDrive-UniversityofCincinnati/Undergraduate Research/Check points/Big Bench Hard/groq_object_counting.csv!\n"
     ]
    }
   ],
   "source": [
    "df_to_csv(\"Big Bench Hard\", groq_object_counting, file_name = \"groq_object_counting\", output_col = \"llama_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Testing - penguins_in_a_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins_in_a_table = Big_Bench_Json_Processor_my('Big Bench Hard', 'penguins_in_a_table.json').convert_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 146 entries, 0 to 145\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   146 non-null    object\n",
      " 1   target  146 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.4+ KB\n",
      "['(E)' '(C)' '(A)' '(D)' '(B)']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  We now add a penguin to the table:\\nJames, 12, 90, 12\\nAnd here is a similar table, but listing giraffes:\\nname, age, height (cm), weight (kg)\\nJody, 5, 430, 620\\nGladys, 10, 420, 590\\nMarian, 2, 310, 410\\nDonna, 9, 440, 650\\nWhich is the oldest penguin?\\nOptions:\\n(A) Louis\\n(B) Bernard\\n(C) Vincent\\n(D) Gwen\\n(E) James</td>\n",
       "      <td>(E)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  What is the name of the last penguin sorted by alphabetic order?\\nOptions:\\n(A) Louis\\n(B) Bernard\\n(C) Vincent\\n(D) Gwen\\n(E) James</td>\n",
       "      <td>(C)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  How many penguins are more than 5 years old?\\nOptions:\\n(A) 1\\n(B) 2\\n(C) 3\\n(D) 4\\n(E) 5</td>\n",
       "      <td>(C)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  And here is a similar table, but listing giraffes:\\nname, age, height (cm), weight (kg)\\nJody, 5, 430, 620\\nGladys, 10, 420, 590\\nMarian, 2, 310, 410\\nDonna, 9, 440, 650\\nHow many animals are more than 5 years old?\\nOptions:\\n(A) 5\\n(B) 6\\n(C) 7\\n(D) 8\\n(E) 9</td>\n",
       "      <td>(A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  Which penguin is older than Gwen?\\nOptions:\\n(A) Louis\\n(B) Bernard\\n(C) Vincent\\n(D) Gwen\\n(E) James</td>\n",
       "      <td>(C)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       input  \\\n",
       "0  Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  We now add a penguin to the table:\\nJames, 12, 90, 12\\nAnd here is a similar table, but listing giraffes:\\nname, age, height (cm), weight (kg)\\nJody, 5, 430, 620\\nGladys, 10, 420, 590\\nMarian, 2, 310, 410\\nDonna, 9, 440, 650\\nWhich is the oldest penguin?\\nOptions:\\n(A) Louis\\n(B) Bernard\\n(C) Vincent\\n(D) Gwen\\n(E) James   \n",
       "1                                                                                                                                                                                                Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  What is the name of the last penguin sorted by alphabetic order?\\nOptions:\\n(A) Louis\\n(B) Bernard\\n(C) Vincent\\n(D) Gwen\\n(E) James   \n",
       "2                                                                                                                                                                                                                                           Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  How many penguins are more than 5 years old?\\nOptions:\\n(A) 1\\n(B) 2\\n(C) 3\\n(D) 4\\n(E) 5   \n",
       "3                                                                 Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  And here is a similar table, but listing giraffes:\\nname, age, height (cm), weight (kg)\\nJody, 5, 430, 620\\nGladys, 10, 420, 590\\nMarian, 2, 310, 410\\nDonna, 9, 440, 650\\nHow many animals are more than 5 years old?\\nOptions:\\n(A) 5\\n(B) 6\\n(C) 7\\n(D) 8\\n(E) 9   \n",
       "4                                                                                                                                                                                                                               Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  Which penguin is older than Gwen?\\nOptions:\\n(A) Louis\\n(B) Bernard\\n(C) Vincent\\n(D) Gwen\\n(E) James   \n",
       "\n",
       "  target  \n",
       "0    (E)  \n",
       "1    (C)  \n",
       "2    (C)  \n",
       "3    (A)  \n",
       "4    (C)  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penguins_in_a_table.info()\n",
    "print(penguins_in_a_table['target'].unique())\n",
    "penguins_in_a_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GEMINI Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "GEMINI\n",
    "\n",
    "The function is to generate Gemini answers for the given data.\n",
    "\n",
    "@params: data(initial dataframe), system_message(message for Gemini system)\n",
    "@return: sample(dataframe with gemini_output column)\n",
    "\"\"\"\n",
    "\n",
    "def gemini_generator(data, system_message):\n",
    "\n",
    "    import time\n",
    "    total_requests = 0\n",
    "    successful_requests = 0\n",
    "\n",
    "\n",
    "    model=genai.GenerativeModel(\n",
    "    model_name=\"gemini-2.0-flash-exp\",\n",
    "    system_instruction=system_message,\n",
    "    )\n",
    "\n",
    "    sample = data.copy()\n",
    "    sample['gemini_output'] = None\n",
    "\n",
    "    for i in range(len(sample)):\n",
    "        success = False\n",
    "        retries = 3\n",
    "\n",
    "        while not success and retries > 0:\n",
    "            try:\n",
    "                total_requests += 1\n",
    "\n",
    "                # Make API request\n",
    "                response = model.generate_content(sample['input'][i])\n",
    "                # print(response.text)\n",
    "                sample.loc[i, 'gemini_output'] = response.text.strip()\n",
    "                success = True\n",
    "                successful_requests += 1\n",
    "                time.sleep(5)\n",
    "\n",
    "            except Exception as e:\n",
    "                # print(f\"Error: {e}\")\n",
    "                retries -= 1\n",
    "                time.sleep(5)\n",
    "                total_requests += 1\n",
    "\n",
    "    print(f\"Total requests made: {total_requests}\")\n",
    "    print(f\"Successful requests: {successful_requests}\")\n",
    "\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total requests made: 152\n",
      "Successful requests: 146\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "df_to_csv() missing 1 required positional argument: 'output_col'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m gemini_penguins_in_a_table \u001b[38;5;241m=\u001b[39m gemini_generator(penguins_in_a_table, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou only answer the provided options to the following questions.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mdf_to_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBig Bench Hard\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgemini_penguins_in_a_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgemini_penguins_in_a_table\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: df_to_csv() missing 1 required positional argument: 'output_col'"
     ]
    }
   ],
   "source": [
    "gemini_penguins_in_a_table = gemini_generator(penguins_in_a_table, \"You only answer the provided options to the following questions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame exported successfully to /Users/ezishr/Library/CloudStorage/OneDrive-UniversityofCincinnati/Undergraduate Research/Check points/Big Bench Hard/gemini_penguins_in_a_table.csv!\n"
     ]
    }
   ],
   "source": [
    "df_to_csv(\"Big Bench Hard\", gemini_penguins_in_a_table, file_name = \"gemini_penguins_in_a_table\", output_col=\"gemini_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "      <th>gemini_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  We now add a penguin to the table:\\nJames, 12, 90, 12\\nAnd here is a similar table, but listing giraffes:\\nname, age, height (cm), weight (kg)\\nJody, 5, 430, 620\\nGladys, 10, 420, 590\\nMarian, 2, 310, 410\\nDonna, 9, 440, 650\\nWhich is the oldest penguin?\\nOptions:\\n(A) Louis\\n(B) Bernard\\n(C) Vincent\\n(D) Gwen\\n(E) James</td>\n",
       "      <td>(E)</td>\n",
       "      <td>(E) James</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  What is the name of the last penguin sorted by alphabetic order?\\nOptions:\\n(A) Louis\\n(B) Bernard\\n(C) Vincent\\n(D) Gwen\\n(E) James</td>\n",
       "      <td>(C)</td>\n",
       "      <td>(C) Vincent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  How many penguins are more than 5 years old?\\nOptions:\\n(A) 1\\n(B) 2\\n(C) 3\\n(D) 4\\n(E) 5</td>\n",
       "      <td>(C)</td>\n",
       "      <td>(D) 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  And here is a similar table, but listing giraffes:\\nname, age, height (cm), weight (kg)\\nJody, 5, 430, 620\\nGladys, 10, 420, 590\\nMarian, 2, 310, 410\\nDonna, 9, 440, 650\\nHow many animals are more than 5 years old?\\nOptions:\\n(A) 5\\n(B) 6\\n(C) 7\\n(D) 8\\n(E) 9</td>\n",
       "      <td>(A)</td>\n",
       "      <td>(B) 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  Which penguin is older than Gwen?\\nOptions:\\n(A) Louis\\n(B) Bernard\\n(C) Vincent\\n(D) Gwen\\n(E) James</td>\n",
       "      <td>(C)</td>\n",
       "      <td>(C) Vincent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  We now add a penguin to the table:\\nJames, 12, 90, 12\\nAnd here is a similar table, but listing giraffes:\\nname, age, height (cm), weight (kg)\\nJody, 5, 430, 620\\nGladys, 10, 420, 590\\nMarian, 2, 310, 410\\nDonna, 9, 440, 650\\nHow many penguins are there in the tables?\\nOptions:\\n(A) 1\\n(B) 2\\n(C) 3\\n(D) 4\\n(E) 5</td>\n",
       "      <td>(E)</td>\n",
       "      <td>(E)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  What is the name of the first penguin sorted by alphabetic order?\\nOptions:\\n(A) Louis\\n(B) Bernard\\n(C) Vincent\\n(D) Gwen\\n(E) James</td>\n",
       "      <td>(B)</td>\n",
       "      <td>(B) Bernard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  Which penguin is a female?\\nOptions:\\n(A) Louis\\n(B) Bernard\\n(C) Vincent\\n(D) Gwen\\n(E) James</td>\n",
       "      <td>(D)</td>\n",
       "      <td>(D) Gwen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  We now add a penguin to the table:\\nJames, 12, 90, 12\\nWhich penguin is taller than the other ones?\\nOptions:\\n(A) Louis\\n(B) Bernard\\n(C) Vincent\\n(D) Gwen\\n(E) James</td>\n",
       "      <td>(E)</td>\n",
       "      <td>(E) James</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  We now add a penguin to the table:\\nJames, 12, 90, 12\\nWhat is the name of the last penguin sorted by alphabetic order?\\nOptions:\\n(A) Louis\\n(B) Bernard\\n(C) Vincent\\n(D) Gwen\\n(E) James</td>\n",
       "      <td>(C)</td>\n",
       "      <td>(C) Vincent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         input  \\\n",
       "0    Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  We now add a penguin to the table:\\nJames, 12, 90, 12\\nAnd here is a similar table, but listing giraffes:\\nname, age, height (cm), weight (kg)\\nJody, 5, 430, 620\\nGladys, 10, 420, 590\\nMarian, 2, 310, 410\\nDonna, 9, 440, 650\\nWhich is the oldest penguin?\\nOptions:\\n(A) Louis\\n(B) Bernard\\n(C) Vincent\\n(D) Gwen\\n(E) James   \n",
       "1                                                                                                                                                                                                  Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  What is the name of the last penguin sorted by alphabetic order?\\nOptions:\\n(A) Louis\\n(B) Bernard\\n(C) Vincent\\n(D) Gwen\\n(E) James   \n",
       "2                                                                                                                                                                                                                                             Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  How many penguins are more than 5 years old?\\nOptions:\\n(A) 1\\n(B) 2\\n(C) 3\\n(D) 4\\n(E) 5   \n",
       "3                                                                   Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  And here is a similar table, but listing giraffes:\\nname, age, height (cm), weight (kg)\\nJody, 5, 430, 620\\nGladys, 10, 420, 590\\nMarian, 2, 310, 410\\nDonna, 9, 440, 650\\nHow many animals are more than 5 years old?\\nOptions:\\n(A) 5\\n(B) 6\\n(C) 7\\n(D) 8\\n(E) 9   \n",
       "4                                                                                                                                                                                                                                 Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  Which penguin is older than Gwen?\\nOptions:\\n(A) Louis\\n(B) Bernard\\n(C) Vincent\\n(D) Gwen\\n(E) James   \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ...   \n",
       "141           Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  We now add a penguin to the table:\\nJames, 12, 90, 12\\nAnd here is a similar table, but listing giraffes:\\nname, age, height (cm), weight (kg)\\nJody, 5, 430, 620\\nGladys, 10, 420, 590\\nMarian, 2, 310, 410\\nDonna, 9, 440, 650\\nHow many penguins are there in the tables?\\nOptions:\\n(A) 1\\n(B) 2\\n(C) 3\\n(D) 4\\n(E) 5   \n",
       "142                                                                                                                                                                                               Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  What is the name of the first penguin sorted by alphabetic order?\\nOptions:\\n(A) Louis\\n(B) Bernard\\n(C) Vincent\\n(D) Gwen\\n(E) James   \n",
       "143                                                                                                                                                                                                                                      Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  Which penguin is a female?\\nOptions:\\n(A) Louis\\n(B) Bernard\\n(C) Vincent\\n(D) Gwen\\n(E) James   \n",
       "144                                                                                                                                                             Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  We now add a penguin to the table:\\nJames, 12, 90, 12\\nWhich penguin is taller than the other ones?\\nOptions:\\n(A) Louis\\n(B) Bernard\\n(C) Vincent\\n(D) Gwen\\n(E) James   \n",
       "145                                                                                                                                         Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  We now add a penguin to the table:\\nJames, 12, 90, 12\\nWhat is the name of the last penguin sorted by alphabetic order?\\nOptions:\\n(A) Louis\\n(B) Bernard\\n(C) Vincent\\n(D) Gwen\\n(E) James   \n",
       "\n",
       "    target gemini_output  \n",
       "0      (E)     (E) James  \n",
       "1      (C)   (C) Vincent  \n",
       "2      (C)         (D) 4  \n",
       "3      (A)         (B) 6  \n",
       "4      (C)   (C) Vincent  \n",
       "..     ...           ...  \n",
       "141    (E)           (E)  \n",
       "142    (B)   (B) Bernard  \n",
       "143    (D)      (D) Gwen  \n",
       "144    (E)     (E) James  \n",
       "145    (C)   (C) Vincent  \n",
       "\n",
       "[146 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemini_penguins_in_a_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GROQ - llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 146 entries, 0 to 145\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   146 non-null    object\n",
      " 1   target  146 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.4+ KB\n"
     ]
    }
   ],
   "source": [
    "groq_penguins = penguins_in_a_table.copy()\n",
    "groq_penguins.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 45\n",
      "Successful requests: 3\n",
      "Total requests made: 59\n",
      "Successful requests: 1\n",
      "Total requests made: 52\n",
      "Successful requests: 2\n",
      "Total requests made: 36\n",
      "Successful requests: 0\n",
      "Total requests made: 0\n",
      "Successful requests: 0\n",
      "Total requests made: 0\n",
      "Successful requests: 0\n",
      "Total requests made: 0\n",
      "Successful requests: 0\n",
      "Total requests made: 0\n",
      "Successful requests: 0\n",
      "Total requests made: 0\n",
      "Successful requests: 0\n",
      "Total requests made: 0\n",
      "Successful requests: 0\n",
      "Total requests made: 0\n",
      "Successful requests: 0\n",
      "Total requests made: 0\n",
      "Successful requests: 0\n",
      "Total requests made: 0\n",
      "Successful requests: 0\n",
      "Total requests made: 0\n",
      "Successful requests: 0\n"
     ]
    }
   ],
   "source": [
    "groq_penguins = groq_line_generate(raw_dataset = penguins_in_a_table, output_dataset = groq_penguins, start_idx=0, end_idx=9, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_penguins = groq_line_generate(raw_dataset = penguins_in_a_table, output_dataset = groq_penguins, start_idx=10, end_idx=19, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_penguins = groq_line_generate(raw_dataset = penguins_in_a_table, output_dataset = groq_penguins, start_idx=20, end_idx=29, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_penguins = groq_line_generate(raw_dataset = penguins_in_a_table, output_dataset = groq_penguins, start_idx=30, end_idx=39, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_penguins = groq_line_generate(raw_dataset = penguins_in_a_table, output_dataset = groq_penguins, start_idx=40, end_idx=49, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_penguins = groq_line_generate(raw_dataset = penguins_in_a_table, output_dataset = groq_penguins, start_idx=50, end_idx=59, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_penguins = groq_line_generate(raw_dataset = penguins_in_a_table, output_dataset = groq_penguins, start_idx=60, end_idx=69, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_penguins = groq_line_generate(raw_dataset = penguins_in_a_table, output_dataset = groq_penguins, start_idx=70, end_idx=79, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_penguins = groq_line_generate(raw_dataset = penguins_in_a_table, output_dataset = groq_penguins, start_idx=80, end_idx=89, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_penguins = groq_line_generate(raw_dataset = penguins_in_a_table, output_dataset = groq_penguins, start_idx=90, end_idx=99, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_penguins = groq_line_generate(raw_dataset = penguins_in_a_table, output_dataset = groq_penguins, start_idx=100, end_idx=109, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_penguins = groq_line_generate(raw_dataset = penguins_in_a_table, output_dataset = groq_penguins, start_idx=110, end_idx=119, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_penguins = groq_line_generate(raw_dataset = penguins_in_a_table, output_dataset = groq_penguins, start_idx=120, end_idx=129, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_penguins = groq_line_generate(raw_dataset = penguins_in_a_table, output_dataset = groq_penguins, start_idx=130, end_idx=139, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_penguins = groq_line_generate(raw_dataset = penguins_in_a_table, output_dataset = groq_penguins, start_idx=140, end_idx=149, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_penguins = groq_line_generate(raw_dataset = penguins_in_a_table, output_dataset = groq_penguins, start_idx=150, end_idx=159, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_penguins = groq_line_generate(raw_dataset = penguins_in_a_table, output_dataset = groq_penguins, start_idx=160, end_idx=169, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_penguins = groq_line_generate(raw_dataset = penguins_in_a_table, output_dataset = groq_penguins, start_idx=170, end_idx=179, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_penguins = groq_line_generate(raw_dataset = penguins_in_a_table, output_dataset = groq_penguins, start_idx=180, end_idx=189, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_penguins = groq_line_generate(raw_dataset = penguins_in_a_table, output_dataset = groq_penguins, start_idx=190, end_idx=199, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_penguins = groq_line_generate(raw_dataset = penguins_in_a_table, output_dataset = groq_penguins, start_idx=200, end_idx=209, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_penguins = groq_line_generate(raw_dataset = penguins_in_a_table, output_dataset = groq_penguins, start_idx=210, end_idx=219, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_penguins = groq_line_generate(raw_dataset = penguins_in_a_table, output_dataset = groq_penguins, start_idx=220, end_idx=229, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_penguins = groq_line_generate(raw_dataset = penguins_in_a_table, output_dataset = groq_penguins, start_idx=230, end_idx=239, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_penguins = groq_line_generate(raw_dataset = penguins_in_a_table, output_dataset = groq_penguins, start_idx=240, end_idx=249, system_message=\"You only answer the provided options to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export failed: DataFrame contains null values in 'gemini_output'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_csv(\"Big Bench Hard\", groq_penguins, file_name = \"groq_penguins\", output_col = \"llama_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_penguins['llama_output'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = groq_penguins[groq_penguins['llama_output'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "      <th>llama_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  And here is a similar table, but listing giraffes:\\nname, age, height (cm), weight (kg)\\nJody, 5, 430, 620\\nGladys, 10, 420, 590\\nMarian, 2, 310, 410\\nDonna, 9, 440, 650\\nWhat is the name of the last animal sorted by alphabetic order?\\nOptions:\\n(A) Jody\\n(B) Louis\\n(C) Louise\\n(D) Marian\\n(E) Vincent</td>\n",
       "      <td>(E)</td>\n",
       "      <td>The first step is to sort both tables by alphabetic order and then find the last animal.\\n\\nPenguins in order: Bernard, Gwen, Louis, Vincent\\nGiraffes in order: Donna, Gladys, Jody, Marian\\n\\nCombined list: Bernard, Donna, Gladys, Gwen, Jody, Louis, Marian, Vincent\\n\\nThe last animal in the combined list is Vincent. \\n\\n(E)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  And here is a similar table, but listing giraffes:\\nname, age, height (cm), weight (kg)\\nJody, 5, 430, 620\\nGladys, 10, 420, 590\\nMarian, 2, 310, 410\\nDonna, 9, 440, 650\\nHow many penguins are more than 5 years old?\\nOptions:\\n(A) 1\\n(B) 2\\n(C) 3\\n(D) 4\\n(E) 5</td>\n",
       "      <td>(C)</td>\n",
       "      <td>(C) 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  What is the name of the second penguin?\\nOptions:\\n(A) Louis\\n(B) Bernard\\n(C) Vincent\\n(D) Gwen\\n(E) James</td>\n",
       "      <td>(B)</td>\n",
       "      <td>(B) Bernard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  Which penguin is younger than Louis?\\nOptions:\\n(A) Louis\\n(B) Bernard\\n(C) Vincent\\n(D) Gwen\\n(E) James</td>\n",
       "      <td>(B)</td>\n",
       "      <td>(B) Bernard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  We now add a penguin to the table:\\nJames, 12, 90, 12\\nAnd here is a similar table, but listing giraffes:\\nname, age, height (cm), weight (kg)\\nJody, 5, 430, 620\\nGladys, 10, 420, 590\\nMarian, 2, 310, 410\\nDonna, 9, 440, 650\\nHow many penguins are more than 5 years old?\\nOptions:\\n(A) 1\\n(B) 2\\n(C) 3\\n(D) 4\\n(E) 5</td>\n",
       "      <td>(D)</td>\n",
       "      <td>(C) 3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  input  \\\n",
       "113               Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  And here is a similar table, but listing giraffes:\\nname, age, height (cm), weight (kg)\\nJody, 5, 430, 620\\nGladys, 10, 420, 590\\nMarian, 2, 310, 410\\nDonna, 9, 440, 650\\nWhat is the name of the last animal sorted by alphabetic order?\\nOptions:\\n(A) Jody\\n(B) Louis\\n(C) Louise\\n(D) Marian\\n(E) Vincent   \n",
       "114                                                         Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  And here is a similar table, but listing giraffes:\\nname, age, height (cm), weight (kg)\\nJody, 5, 430, 620\\nGladys, 10, 420, 590\\nMarian, 2, 310, 410\\nDonna, 9, 440, 650\\nHow many penguins are more than 5 years old?\\nOptions:\\n(A) 1\\n(B) 2\\n(C) 3\\n(D) 4\\n(E) 5   \n",
       "115                                                                                                                                                                                                                  Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  What is the name of the second penguin?\\nOptions:\\n(A) Louis\\n(B) Bernard\\n(C) Vincent\\n(D) Gwen\\n(E) James   \n",
       "116                                                                                                                                                                                                                     Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  Which penguin is younger than Louis?\\nOptions:\\n(A) Louis\\n(B) Bernard\\n(C) Vincent\\n(D) Gwen\\n(E) James   \n",
       "117  Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  We now add a penguin to the table:\\nJames, 12, 90, 12\\nAnd here is a similar table, but listing giraffes:\\nname, age, height (cm), weight (kg)\\nJody, 5, 430, 620\\nGladys, 10, 420, 590\\nMarian, 2, 310, 410\\nDonna, 9, 440, 650\\nHow many penguins are more than 5 years old?\\nOptions:\\n(A) 1\\n(B) 2\\n(C) 3\\n(D) 4\\n(E) 5   \n",
       "\n",
       "    target  \\\n",
       "113    (E)   \n",
       "114    (C)   \n",
       "115    (B)   \n",
       "116    (B)   \n",
       "117    (D)   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                              llama_output  \n",
       "113  The first step is to sort both tables by alphabetic order and then find the last animal.\\n\\nPenguins in order: Bernard, Gwen, Louis, Vincent\\nGiraffes in order: Donna, Gladys, Jody, Marian\\n\\nCombined list: Bernard, Donna, Gladys, Gwen, Jody, Louis, Marian, Vincent\\n\\nThe last animal in the combined list is Vincent. \\n\\n(E)  \n",
       "114                                                                                                                                                                                                                                                                                                                                  (C) 3  \n",
       "115                                                                                                                                                                                                                                                                                                                            (B) Bernard  \n",
       "116                                                                                                                                                                                                                                                                                                                            (B) Bernard  \n",
       "117                                                                                                                                                                                                                                                                                                                                  (C) 3  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['E', '(C) 3', '(B) Bernard', '(B) 2', '(E) James', '(A) Louis',\n",
       "       '(B) 29', '(B) Gladys', '(A) 1', '(B)', '(D) Gwen', '(B) 50',\n",
       "       '(C) 26', '(C) 41', '(E) 90', '(C) Vincent', '(C) 36', '(E) 5',\n",
       "       '(A)'], dtype=object)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['llama_output'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['llama_output'].str.len().idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "input           Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  What animals are listed in the table?\\nOptions:\\n(A) bears\\n(B) crocodiles\\n(C) elephants\\n(D) giraffes\\n(E) penguins\n",
       "target                                                                                                                                                                                                                                                                                                                                                                                                                                   (E)\n",
       "llama_output                                                                                                                                                                                                                                                                                                                                                                                                                       (E) James\n",
       "Name: 124, dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.loc[124,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(E) James\n"
     ]
    }
   ],
   "source": [
    "    # os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
    "client = Groq(api_key = os.environ['GROQ_API_KEY'],)\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\":\"user\",\n",
    "            \"content\": sample.loc[123, 'input']\n",
    "        },\n",
    "        {\n",
    "            \"role\":\"system\",\n",
    "            \"content\": \"Your answer should be one of the provided options, no explanation needed.\"\n",
    "        }\n",
    "    ],\n",
    "    model = \"llama-3.3-70b-specdec\",\n",
    ")\n",
    "\n",
    "response = chat_completion.choices[0].message.content\n",
    "print(response)\n",
    "sample.loc[123, 'llama_output'] = response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 134,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 140,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 145]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in sample.index.to_list():\n",
    "    groq_penguins.loc[idx, 'llama_output'] = sample.loc[idx, 'llama_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame exported successfully to /Users/ezishr/Library/CloudStorage/OneDrive-UniversityofCincinnati/Undergraduate Research/Check points/Big Bench Hard/groq_penguins.csv!\n"
     ]
    }
   ],
   "source": [
    "df_to_csv(\"Big Bench Hard\", groq_penguins, file_name = \"groq_penguins\", output_col = \"llama_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Testing - reasoning_about_colored_objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_colored_objects = Big_Bench_Json_Processor_my('Big Bench Hard', 'reasoning_about_colored_objects.json').convert_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   250 non-null    object\n",
      " 1   target  250 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 4.0+ KB\n",
      "None\n",
      "['(D)' '(Q)' '(I)' '(B)' '(F)' '(L)' '(K)' '(E)' '(C)' '(M)' '(J)' '(A)'\n",
      " '(H)' '(R)' '(O)' '(N)' '(G)' '(P)']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>On the floor, there is one mauve cat toy, two purple cat toys, three grey cat toys, two mauve notebooks, three grey notebooks, three burgundy cat toys, and one purple notebook. If I remove all the notebooks from the floor, how many grey objects remain on it?\\nOptions:\\n(A) zero\\n(B) one\\n(C) two\\n(D) three\\n(E) four\\n(F) five\\n(G) six\\n(H) seven\\n(I) eight\\n(J) nine\\n(K) ten\\n(L) eleven\\n(M) twelve\\n(N) thirteen\\n(O) fourteen\\n(P) fifteen\\n(Q) sixteen</td>\n",
       "      <td>(D)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>On the desk, you see a set of things arranged in a row: a grey cup, a purple mug, and a blue teddy bear. What is the color of the thing directly to the right of the cup?\\nOptions:\\n(A) red\\n(B) orange\\n(C) yellow\\n(D) green\\n(E) blue\\n(F) brown\\n(G) magenta\\n(H) fuchsia\\n(I) mauve\\n(J) teal\\n(K) turquoise\\n(L) burgundy\\n(M) silver\\n(N) gold\\n(O) black\\n(P) grey\\n(Q) purple\\n(R) pink</td>\n",
       "      <td>(Q)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>On the nightstand, you see a set of items arranged in a row: a gold plate, a silver stress ball, a fuchsia notebook, a mauve bracelet, a green jug, and a yellow fidget spinner. What is the color of the item directly to the left of the jug?\\nOptions:\\n(A) red\\n(B) orange\\n(C) yellow\\n(D) green\\n(E) blue\\n(F) brown\\n(G) magenta\\n(H) fuchsia\\n(I) mauve\\n(J) teal\\n(K) turquoise\\n(L) burgundy\\n(M) silver\\n(N) gold\\n(O) black\\n(P) grey\\n(Q) purple\\n(R) pink</td>\n",
       "      <td>(I)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On the table, you see several items arranged in a row: a fuchsia teddy bear, a red jug, a gold puzzle, a burgundy bracelet, and a green notebook. How many non-magenta items do you see to the right of the red item?\\nOptions:\\n(A) zero\\n(B) one\\n(C) two\\n(D) three\\n(E) four\\n(F) five\\n(G) six</td>\n",
       "      <td>(D)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On the desk, you see a bunch of things arranged in a row: a mauve plate, an orange jug, a burgundy pair of sunglasses, a green pen, and a purple stress ball. What is the color of the thing directly to the left of the burgundy thing?\\nOptions:\\n(A) red\\n(B) orange\\n(C) yellow\\n(D) green\\n(E) blue\\n(F) brown\\n(G) magenta\\n(H) fuchsia\\n(I) mauve\\n(J) teal\\n(K) turquoise\\n(L) burgundy\\n(M) silver\\n(N) gold\\n(O) black\\n(P) grey\\n(Q) purple\\n(R) pink</td>\n",
       "      <td>(B)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                     input  \\\n",
       "0  On the floor, there is one mauve cat toy, two purple cat toys, three grey cat toys, two mauve notebooks, three grey notebooks, three burgundy cat toys, and one purple notebook. If I remove all the notebooks from the floor, how many grey objects remain on it?\\nOptions:\\n(A) zero\\n(B) one\\n(C) two\\n(D) three\\n(E) four\\n(F) five\\n(G) six\\n(H) seven\\n(I) eight\\n(J) nine\\n(K) ten\\n(L) eleven\\n(M) twelve\\n(N) thirteen\\n(O) fourteen\\n(P) fifteen\\n(Q) sixteen   \n",
       "1                                                                        On the desk, you see a set of things arranged in a row: a grey cup, a purple mug, and a blue teddy bear. What is the color of the thing directly to the right of the cup?\\nOptions:\\n(A) red\\n(B) orange\\n(C) yellow\\n(D) green\\n(E) blue\\n(F) brown\\n(G) magenta\\n(H) fuchsia\\n(I) mauve\\n(J) teal\\n(K) turquoise\\n(L) burgundy\\n(M) silver\\n(N) gold\\n(O) black\\n(P) grey\\n(Q) purple\\n(R) pink   \n",
       "2  On the nightstand, you see a set of items arranged in a row: a gold plate, a silver stress ball, a fuchsia notebook, a mauve bracelet, a green jug, and a yellow fidget spinner. What is the color of the item directly to the left of the jug?\\nOptions:\\n(A) red\\n(B) orange\\n(C) yellow\\n(D) green\\n(E) blue\\n(F) brown\\n(G) magenta\\n(H) fuchsia\\n(I) mauve\\n(J) teal\\n(K) turquoise\\n(L) burgundy\\n(M) silver\\n(N) gold\\n(O) black\\n(P) grey\\n(Q) purple\\n(R) pink   \n",
       "3                                                                                                                                                                      On the table, you see several items arranged in a row: a fuchsia teddy bear, a red jug, a gold puzzle, a burgundy bracelet, and a green notebook. How many non-magenta items do you see to the right of the red item?\\nOptions:\\n(A) zero\\n(B) one\\n(C) two\\n(D) three\\n(E) four\\n(F) five\\n(G) six   \n",
       "4         On the desk, you see a bunch of things arranged in a row: a mauve plate, an orange jug, a burgundy pair of sunglasses, a green pen, and a purple stress ball. What is the color of the thing directly to the left of the burgundy thing?\\nOptions:\\n(A) red\\n(B) orange\\n(C) yellow\\n(D) green\\n(E) blue\\n(F) brown\\n(G) magenta\\n(H) fuchsia\\n(I) mauve\\n(J) teal\\n(K) turquoise\\n(L) burgundy\\n(M) silver\\n(N) gold\\n(O) black\\n(P) grey\\n(Q) purple\\n(R) pink   \n",
       "\n",
       "  target  \n",
       "0    (D)  \n",
       "1    (Q)  \n",
       "2    (I)  \n",
       "3    (D)  \n",
       "4    (B)  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(reasoning_colored_objects.info())\n",
    "print(reasoning_colored_objects['target'].unique())\n",
    "reasoning_colored_objects.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GEMINI Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_reasoning_colored_objects = gemini_generator(reasoning_colored_objects, \"You only choose the options provided to answer the following questions.\")\n",
    "df_to_csv(\"Big Bench Hard\", gemini_reasoning_colored_objects, file_name = \"gemini_reasoning_colored_objects\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GROQ - llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>On the floor, there is one mauve cat toy, two purple cat toys, three grey cat toys, two mauve notebooks, three grey notebooks, three burgundy cat toys, and one purple notebook. If I remove all the notebooks from the floor, how many grey objects remain on it?\\nOptions:\\n(A) zero\\n(B) one\\n(C) two\\n(D) three\\n(E) four\\n(F) five\\n(G) six\\n(H) seven\\n(I) eight\\n(J) nine\\n(K) ten\\n(L) eleven\\n(M) twelve\\n(N) thirteen\\n(O) fourteen\\n(P) fifteen\\n(Q) sixteen</td>\n",
       "      <td>(D)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>On the desk, you see a set of things arranged in a row: a grey cup, a purple mug, and a blue teddy bear. What is the color of the thing directly to the right of the cup?\\nOptions:\\n(A) red\\n(B) orange\\n(C) yellow\\n(D) green\\n(E) blue\\n(F) brown\\n(G) magenta\\n(H) fuchsia\\n(I) mauve\\n(J) teal\\n(K) turquoise\\n(L) burgundy\\n(M) silver\\n(N) gold\\n(O) black\\n(P) grey\\n(Q) purple\\n(R) pink</td>\n",
       "      <td>(Q)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>On the nightstand, you see a set of items arranged in a row: a gold plate, a silver stress ball, a fuchsia notebook, a mauve bracelet, a green jug, and a yellow fidget spinner. What is the color of the item directly to the left of the jug?\\nOptions:\\n(A) red\\n(B) orange\\n(C) yellow\\n(D) green\\n(E) blue\\n(F) brown\\n(G) magenta\\n(H) fuchsia\\n(I) mauve\\n(J) teal\\n(K) turquoise\\n(L) burgundy\\n(M) silver\\n(N) gold\\n(O) black\\n(P) grey\\n(Q) purple\\n(R) pink</td>\n",
       "      <td>(I)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On the table, you see several items arranged in a row: a fuchsia teddy bear, a red jug, a gold puzzle, a burgundy bracelet, and a green notebook. How many non-magenta items do you see to the right of the red item?\\nOptions:\\n(A) zero\\n(B) one\\n(C) two\\n(D) three\\n(E) four\\n(F) five\\n(G) six</td>\n",
       "      <td>(D)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On the desk, you see a bunch of things arranged in a row: a mauve plate, an orange jug, a burgundy pair of sunglasses, a green pen, and a purple stress ball. What is the color of the thing directly to the left of the burgundy thing?\\nOptions:\\n(A) red\\n(B) orange\\n(C) yellow\\n(D) green\\n(E) blue\\n(F) brown\\n(G) magenta\\n(H) fuchsia\\n(I) mauve\\n(J) teal\\n(K) turquoise\\n(L) burgundy\\n(M) silver\\n(N) gold\\n(O) black\\n(P) grey\\n(Q) purple\\n(R) pink</td>\n",
       "      <td>(B)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                     input  \\\n",
       "0  On the floor, there is one mauve cat toy, two purple cat toys, three grey cat toys, two mauve notebooks, three grey notebooks, three burgundy cat toys, and one purple notebook. If I remove all the notebooks from the floor, how many grey objects remain on it?\\nOptions:\\n(A) zero\\n(B) one\\n(C) two\\n(D) three\\n(E) four\\n(F) five\\n(G) six\\n(H) seven\\n(I) eight\\n(J) nine\\n(K) ten\\n(L) eleven\\n(M) twelve\\n(N) thirteen\\n(O) fourteen\\n(P) fifteen\\n(Q) sixteen   \n",
       "1                                                                        On the desk, you see a set of things arranged in a row: a grey cup, a purple mug, and a blue teddy bear. What is the color of the thing directly to the right of the cup?\\nOptions:\\n(A) red\\n(B) orange\\n(C) yellow\\n(D) green\\n(E) blue\\n(F) brown\\n(G) magenta\\n(H) fuchsia\\n(I) mauve\\n(J) teal\\n(K) turquoise\\n(L) burgundy\\n(M) silver\\n(N) gold\\n(O) black\\n(P) grey\\n(Q) purple\\n(R) pink   \n",
       "2  On the nightstand, you see a set of items arranged in a row: a gold plate, a silver stress ball, a fuchsia notebook, a mauve bracelet, a green jug, and a yellow fidget spinner. What is the color of the item directly to the left of the jug?\\nOptions:\\n(A) red\\n(B) orange\\n(C) yellow\\n(D) green\\n(E) blue\\n(F) brown\\n(G) magenta\\n(H) fuchsia\\n(I) mauve\\n(J) teal\\n(K) turquoise\\n(L) burgundy\\n(M) silver\\n(N) gold\\n(O) black\\n(P) grey\\n(Q) purple\\n(R) pink   \n",
       "3                                                                                                                                                                      On the table, you see several items arranged in a row: a fuchsia teddy bear, a red jug, a gold puzzle, a burgundy bracelet, and a green notebook. How many non-magenta items do you see to the right of the red item?\\nOptions:\\n(A) zero\\n(B) one\\n(C) two\\n(D) three\\n(E) four\\n(F) five\\n(G) six   \n",
       "4         On the desk, you see a bunch of things arranged in a row: a mauve plate, an orange jug, a burgundy pair of sunglasses, a green pen, and a purple stress ball. What is the color of the thing directly to the left of the burgundy thing?\\nOptions:\\n(A) red\\n(B) orange\\n(C) yellow\\n(D) green\\n(E) blue\\n(F) brown\\n(G) magenta\\n(H) fuchsia\\n(I) mauve\\n(J) teal\\n(K) turquoise\\n(L) burgundy\\n(M) silver\\n(N) gold\\n(O) black\\n(P) grey\\n(Q) purple\\n(R) pink   \n",
       "\n",
       "  target  \n",
       "0    (D)  \n",
       "1    (Q)  \n",
       "2    (I)  \n",
       "3    (D)  \n",
       "4    (B)  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_reasoning_colored_objects = reasoning_colored_objects.copy()\n",
    "groq_reasoning_colored_objects.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total requests made: 10\n",
      "Successful requests: 10\n"
     ]
    }
   ],
   "source": [
    "groq_reasoning_colored_objects = groq_line_generate(raw_dataset = reasoning_colored_objects, output_dataset = groq_reasoning_colored_objects, start_idx=0, end_idx=9, system_message=\"You only choose the options provided to answer the following questions.\", model_name=\"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total requests made: 10\n",
      "Successful requests: 10\n"
     ]
    }
   ],
   "source": [
    "groq_reasoning_colored_objects = groq_line_generate(raw_dataset = reasoning_colored_objects, output_dataset = groq_reasoning_colored_objects, start_idx=10, end_idx=19, system_message=\"You only choose the options provided to answer the following questions.\", model_name=\"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n"
     ]
    }
   ],
   "source": [
    "groq_reasoning_colored_objects = groq_line_generate(raw_dataset = reasoning_colored_objects, output_dataset = groq_reasoning_colored_objects, start_idx=20, end_idx=29, system_message=\"You only choose the options provided to answer the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_reasoning_colored_objects = groq_line_generate(raw_dataset = reasoning_colored_objects, output_dataset = groq_reasoning_colored_objects, start_idx=30, end_idx=39, system_message=\"You only choose the options provided to answer the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_reasoning_colored_objects = groq_line_generate(raw_dataset = reasoning_colored_objects, output_dataset = groq_reasoning_colored_objects, start_idx=40, end_idx=49, system_message=\"You only choose the options provided to answer the following questions.\", model_name=\"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n"
     ]
    }
   ],
   "source": [
    "groq_reasoning_colored_objects = groq_line_generate(raw_dataset = reasoning_colored_objects, output_dataset = groq_reasoning_colored_objects, start_idx=50, end_idx=59, system_message=\"You only choose the options provided to answer the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_reasoning_colored_objects = groq_line_generate(raw_dataset = reasoning_colored_objects, output_dataset = groq_reasoning_colored_objects, start_idx=60, end_idx=69, system_message=\"You only choose the options provided to answer the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_reasoning_colored_objects = groq_line_generate(raw_dataset = reasoning_colored_objects, output_dataset = groq_reasoning_colored_objects, start_idx=70, end_idx=79, system_message=\"You only choose the options provided to answer the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_reasoning_colored_objects = groq_line_generate(raw_dataset = reasoning_colored_objects, output_dataset = groq_reasoning_colored_objects, start_idx=80, end_idx=89, system_message=\"You only choose the options provided to answer the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_reasoning_colored_objects = groq_line_generate(raw_dataset = reasoning_colored_objects, output_dataset = groq_reasoning_colored_objects, start_idx=90, end_idx=99, system_message=\"You only choose the options provided to answer the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_reasoning_colored_objects = groq_line_generate(raw_dataset = reasoning_colored_objects, output_dataset = groq_reasoning_colored_objects, start_idx=100, end_idx=109, system_message=\"You only choose the options provided to answer the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_reasoning_colored_objects = groq_line_generate(raw_dataset = reasoning_colored_objects, output_dataset = groq_reasoning_colored_objects, start_idx=110, end_idx=119, system_message=\"You only choose the options provided to answer the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_reasoning_colored_objects = groq_line_generate(raw_dataset = reasoning_colored_objects, output_dataset = groq_reasoning_colored_objects, start_idx=120, end_idx=129, system_message=\"You only choose the options provided to answer the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_reasoning_colored_objects = groq_line_generate(raw_dataset = reasoning_colored_objects, output_dataset = groq_reasoning_colored_objects, start_idx=130, end_idx=139, system_message=\"You only choose the options provided to answer the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_reasoning_colored_objects = groq_line_generate(raw_dataset = reasoning_colored_objects, output_dataset = groq_reasoning_colored_objects, start_idx=140, end_idx=149, system_message=\"You only choose the options provided to answer the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_reasoning_colored_objects = groq_line_generate(raw_dataset = reasoning_colored_objects, output_dataset = groq_reasoning_colored_objects, start_idx=150, end_idx=159, system_message=\"You only choose the options provided to answer the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_reasoning_colored_objects = groq_line_generate(raw_dataset = reasoning_colored_objects, output_dataset = groq_reasoning_colored_objects, start_idx=160, end_idx=169, system_message=\"You only choose the options provided to answer the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_reasoning_colored_objects = groq_line_generate(raw_dataset = reasoning_colored_objects, output_dataset = groq_reasoning_colored_objects, start_idx=170, end_idx=179, system_message=\"You only choose the options provided to answer the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_reasoning_colored_objects = groq_line_generate(raw_dataset = reasoning_colored_objects, output_dataset = groq_reasoning_colored_objects, start_idx=180, end_idx=189, system_message=\"You only choose the options provided to answer the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_reasoning_colored_objects = groq_line_generate(raw_dataset = reasoning_colored_objects, output_dataset = groq_reasoning_colored_objects, start_idx=190, end_idx=199, system_message=\"You only choose the options provided to answer the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_reasoning_colored_objects = groq_line_generate(raw_dataset = reasoning_colored_objects, output_dataset = groq_reasoning_colored_objects, start_idx=200, end_idx=209, system_message=\"You only choose the options provided to answer the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_reasoning_colored_objects = groq_line_generate(raw_dataset = reasoning_colored_objects, output_dataset = groq_reasoning_colored_objects, start_idx=210, end_idx=219, system_message=\"You only choose the options provided to answer the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_reasoning_colored_objects = groq_line_generate(raw_dataset = reasoning_colored_objects, output_dataset = groq_reasoning_colored_objects, start_idx=220, end_idx=229, system_message=\"You only choose the options provided to answer the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_reasoning_colored_objects = groq_line_generate(raw_dataset = reasoning_colored_objects, output_dataset = groq_reasoning_colored_objects, start_idx=230, end_idx=239, system_message=\"You only choose the options provided to answer the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_reasoning_colored_objects = groq_line_generate(raw_dataset = reasoning_colored_objects, output_dataset = groq_reasoning_colored_objects, start_idx=240, end_idx=249, system_message=\"You only choose the options provided to answer the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "      <th>llama_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>On the floor, there is one mauve cat toy, two purple cat toys, three grey cat toys, two mauve notebooks, three grey notebooks, three burgundy cat toys, and one purple notebook. If I remove all the notebooks from the floor, how many grey objects remain on it?\\nOptions:\\n(A) zero\\n(B) one\\n(C) two\\n(D) three\\n(E) four\\n(F) five\\n(G) six\\n(H) seven\\n(I) eight\\n(J) nine\\n(K) ten\\n(L) eleven\\n(M) twelve\\n(N) thirteen\\n(O) fourteen\\n(P) fifteen\\n(Q) sixteen</td>\n",
       "      <td>(D)</td>\n",
       "      <td>Since there are three grey cat toys and you are removing all the notebooks (including the three grey notebooks), the grey notebooks will be removed. The grey cat toys will remain. \\n\\nSo, the number of grey objects remaining on the floor will be the number of grey cat toys, which is three.\\n\\nThe correct answer is (D) three.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>On the desk, you see a set of things arranged in a row: a grey cup, a purple mug, and a blue teddy bear. What is the color of the thing directly to the right of the cup?\\nOptions:\\n(A) red\\n(B) orange\\n(C) yellow\\n(D) green\\n(E) blue\\n(F) brown\\n(G) magenta\\n(H) fuchsia\\n(I) mauve\\n(J) teal\\n(K) turquoise\\n(L) burgundy\\n(M) silver\\n(N) gold\\n(O) black\\n(P) grey\\n(Q) purple\\n(R) pink</td>\n",
       "      <td>(Q)</td>\n",
       "      <td>The color of the thing directly to the right of the cup is the color of the mug. Since the mug is purple, the correct answer is:\\n\\n(Q) purple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>On the nightstand, you see a set of items arranged in a row: a gold plate, a silver stress ball, a fuchsia notebook, a mauve bracelet, a green jug, and a yellow fidget spinner. What is the color of the item directly to the left of the jug?\\nOptions:\\n(A) red\\n(B) orange\\n(C) yellow\\n(D) green\\n(E) blue\\n(F) brown\\n(G) magenta\\n(H) fuchsia\\n(I) mauve\\n(J) teal\\n(K) turquoise\\n(L) burgundy\\n(M) silver\\n(N) gold\\n(O) black\\n(P) grey\\n(Q) purple\\n(R) pink</td>\n",
       "      <td>(I)</td>\n",
       "      <td>To determine the color of the item directly to the left of the jug, we need to look at the arrangement provided: a gold plate, a silver stress ball, a fuchsia notebook, a mauve bracelet, a green jug, and a yellow fidget spinner.\\n\\nStarting from the left, if we count the items to find the one directly before the green jug, we skip the gold plate, the silver stress ball, the fuchsia notebook, and land on the mauve bracelet as the item directly to the left of the green jug.\\n\\nThe answer is: (I) mauve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On the table, you see several items arranged in a row: a fuchsia teddy bear, a red jug, a gold puzzle, a burgundy bracelet, and a green notebook. How many non-magenta items do you see to the right of the red item?\\nOptions:\\n(A) zero\\n(B) one\\n(C) two\\n(D) three\\n(E) four\\n(F) five\\n(G) six</td>\n",
       "      <td>(D)</td>\n",
       "      <td>To solve this, let's first identify the items and their positions. \\n1. Fuchsia teddy bear (magenta)\\n2. Red jug (red, not magenta)\\n3. Gold puzzle (not magenta)\\n4. Burgundy bracelet (magenta)\\n5. Green notebook (not magenta)\\n\\nThe red item is the jug, which is in the second position. Now, let's look at the items to the right of the red jug:\\n- Gold puzzle (not magenta)\\n- Burgundy bracelet (magenta)\\n- Green notebook (not magenta)\\n\\nThere are two non-magenta items (gold puzzle and green notebook) to the right of the red jug. \\n\\nThe correct answer is:\\n(C) two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On the desk, you see a bunch of things arranged in a row: a mauve plate, an orange jug, a burgundy pair of sunglasses, a green pen, and a purple stress ball. What is the color of the thing directly to the left of the burgundy thing?\\nOptions:\\n(A) red\\n(B) orange\\n(C) yellow\\n(D) green\\n(E) blue\\n(F) brown\\n(G) magenta\\n(H) fuchsia\\n(I) mauve\\n(J) teal\\n(K) turquoise\\n(L) burgundy\\n(M) silver\\n(N) gold\\n(O) black\\n(P) grey\\n(Q) purple\\n(R) pink</td>\n",
       "      <td>(B)</td>\n",
       "      <td>The correct answer is (B) orange. \\n\\nThe items in order are: mauve plate, orange jug, burgundy sunglasses, green pen, and purple stress ball. So, the item to the left of the burgundy sunglasses is the orange jug.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                     input  \\\n",
       "0  On the floor, there is one mauve cat toy, two purple cat toys, three grey cat toys, two mauve notebooks, three grey notebooks, three burgundy cat toys, and one purple notebook. If I remove all the notebooks from the floor, how many grey objects remain on it?\\nOptions:\\n(A) zero\\n(B) one\\n(C) two\\n(D) three\\n(E) four\\n(F) five\\n(G) six\\n(H) seven\\n(I) eight\\n(J) nine\\n(K) ten\\n(L) eleven\\n(M) twelve\\n(N) thirteen\\n(O) fourteen\\n(P) fifteen\\n(Q) sixteen   \n",
       "1                                                                        On the desk, you see a set of things arranged in a row: a grey cup, a purple mug, and a blue teddy bear. What is the color of the thing directly to the right of the cup?\\nOptions:\\n(A) red\\n(B) orange\\n(C) yellow\\n(D) green\\n(E) blue\\n(F) brown\\n(G) magenta\\n(H) fuchsia\\n(I) mauve\\n(J) teal\\n(K) turquoise\\n(L) burgundy\\n(M) silver\\n(N) gold\\n(O) black\\n(P) grey\\n(Q) purple\\n(R) pink   \n",
       "2  On the nightstand, you see a set of items arranged in a row: a gold plate, a silver stress ball, a fuchsia notebook, a mauve bracelet, a green jug, and a yellow fidget spinner. What is the color of the item directly to the left of the jug?\\nOptions:\\n(A) red\\n(B) orange\\n(C) yellow\\n(D) green\\n(E) blue\\n(F) brown\\n(G) magenta\\n(H) fuchsia\\n(I) mauve\\n(J) teal\\n(K) turquoise\\n(L) burgundy\\n(M) silver\\n(N) gold\\n(O) black\\n(P) grey\\n(Q) purple\\n(R) pink   \n",
       "3                                                                                                                                                                      On the table, you see several items arranged in a row: a fuchsia teddy bear, a red jug, a gold puzzle, a burgundy bracelet, and a green notebook. How many non-magenta items do you see to the right of the red item?\\nOptions:\\n(A) zero\\n(B) one\\n(C) two\\n(D) three\\n(E) four\\n(F) five\\n(G) six   \n",
       "4         On the desk, you see a bunch of things arranged in a row: a mauve plate, an orange jug, a burgundy pair of sunglasses, a green pen, and a purple stress ball. What is the color of the thing directly to the left of the burgundy thing?\\nOptions:\\n(A) red\\n(B) orange\\n(C) yellow\\n(D) green\\n(E) blue\\n(F) brown\\n(G) magenta\\n(H) fuchsia\\n(I) mauve\\n(J) teal\\n(K) turquoise\\n(L) burgundy\\n(M) silver\\n(N) gold\\n(O) black\\n(P) grey\\n(Q) purple\\n(R) pink   \n",
       "\n",
       "  target  \\\n",
       "0    (D)   \n",
       "1    (Q)   \n",
       "2    (I)   \n",
       "3    (D)   \n",
       "4    (B)   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 llama_output  \n",
       "0                                                                                                                                                                                                                                                      Since there are three grey cat toys and you are removing all the notebooks (including the three grey notebooks), the grey notebooks will be removed. The grey cat toys will remain. \\n\\nSo, the number of grey objects remaining on the floor will be the number of grey cat toys, which is three.\\n\\nThe correct answer is (D) three.  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                              The color of the thing directly to the right of the cup is the color of the mug. Since the mug is purple, the correct answer is:\\n\\n(Q) purple  \n",
       "2                                                                    To determine the color of the item directly to the left of the jug, we need to look at the arrangement provided: a gold plate, a silver stress ball, a fuchsia notebook, a mauve bracelet, a green jug, and a yellow fidget spinner.\\n\\nStarting from the left, if we count the items to find the one directly before the green jug, we skip the gold plate, the silver stress ball, the fuchsia notebook, and land on the mauve bracelet as the item directly to the left of the green jug.\\n\\nThe answer is: (I) mauve  \n",
       "3  To solve this, let's first identify the items and their positions. \\n1. Fuchsia teddy bear (magenta)\\n2. Red jug (red, not magenta)\\n3. Gold puzzle (not magenta)\\n4. Burgundy bracelet (magenta)\\n5. Green notebook (not magenta)\\n\\nThe red item is the jug, which is in the second position. Now, let's look at the items to the right of the red jug:\\n- Gold puzzle (not magenta)\\n- Burgundy bracelet (magenta)\\n- Green notebook (not magenta)\\n\\nThere are two non-magenta items (gold puzzle and green notebook) to the right of the red jug. \\n\\nThe correct answer is:\\n(C) two  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                       The correct answer is (B) orange. \\n\\nThe items in order are: mauve plate, orange jug, burgundy sunglasses, green pen, and purple stress ball. So, the item to the left of the burgundy sunglasses is the orange jug.  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_reasoning_colored_objects.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   input         250 non-null    object\n",
      " 1   target        250 non-null    object\n",
      " 2   llama_output  250 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "groq_reasoning_colored_objects.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame exported successfully to /Users/ezishr/Library/CloudStorage/OneDrive-UniversityofCincinnati/Undergraduate Research/Check points/Big Bench Hard/groq_reasoning_colored_objects.csv!\n"
     ]
    }
   ],
   "source": [
    "df_to_csv(\"Big Bench Hard\", groq_reasoning_colored_objects, file_name = \"groq_reasoning_colored_objects\", output_col = \"llama_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Testing - ruin_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   250 non-null    object\n",
      " 1   target  250 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 4.0+ KB\n",
      "None\n",
      "['(A)' '(C)' '(D)' '(B)' 'dearth, wind, & fire' 'rita, sue and bob poo']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which of the following is a humorous edit of this artist or movie name: 'rain man'?\\nOptions:\\n(A) ruin man\\n(B) rains man\\n(C) rain men\\n(D) rainmman</td>\n",
       "      <td>(A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which of the following is a humorous edit of this artist or movie name: 'the dark knight rises'?\\nOptions:\\n(A) the bark knight rises\\n(B) thetdark knight rises\\n(C) the dork knight rises\\n(D) the dark kniggt rises</td>\n",
       "      <td>(C)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which of the following is a humorous edit of this artist or movie name: 'the shawshank redemption'?\\nOptions:\\n(A) the shapwshank redemption\\n(B) the shcawshank redemption\\n(C) the shawshanknredemption\\n(D) the shawshark redemption</td>\n",
       "      <td>(D)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Which of the following is a humorous edit of this artist or movie name: 'the third man'?\\nOptions:\\n(A) the third men\\n(B) the trird man\\n(C) thed third man\\n(D) the third pan</td>\n",
       "      <td>(D)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which of the following is a humorous edit of this artist or movie name: 'coldplay'?\\nOptions:\\n(A) coldpnay\\n(B) colldplay\\n(C) coldglay\\n(D) soldplay</td>\n",
       "      <td>(D)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                     input  \\\n",
       "0                                                                                   Which of the following is a humorous edit of this artist or movie name: 'rain man'?\\nOptions:\\n(A) ruin man\\n(B) rains man\\n(C) rain men\\n(D) rainmman   \n",
       "1                   Which of the following is a humorous edit of this artist or movie name: 'the dark knight rises'?\\nOptions:\\n(A) the bark knight rises\\n(B) thetdark knight rises\\n(C) the dork knight rises\\n(D) the dark kniggt rises   \n",
       "2  Which of the following is a humorous edit of this artist or movie name: 'the shawshank redemption'?\\nOptions:\\n(A) the shapwshank redemption\\n(B) the shcawshank redemption\\n(C) the shawshanknredemption\\n(D) the shawshark redemption   \n",
       "3                                                          Which of the following is a humorous edit of this artist or movie name: 'the third man'?\\nOptions:\\n(A) the third men\\n(B) the trird man\\n(C) thed third man\\n(D) the third pan   \n",
       "4                                                                                   Which of the following is a humorous edit of this artist or movie name: 'coldplay'?\\nOptions:\\n(A) coldpnay\\n(B) colldplay\\n(C) coldglay\\n(D) soldplay   \n",
       "\n",
       "  target  \n",
       "0    (A)  \n",
       "1    (C)  \n",
       "2    (D)  \n",
       "3    (D)  \n",
       "4    (D)  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ruin_names = Big_Bench_Json_Processor_my('Big Bench Hard', 'ruin_names.json').convert_df()\n",
    "print(ruin_names.info())\n",
    "print(ruin_names['target'].unique())\n",
    "ruin_names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruin_names[ruin_names['target'].isin(['dearth, wind, & fire', 'rita, sue and bob poo'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GEMINI Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_ruin_names = gemini_generator(ruin_names, \"You only answer the options provided to answer the following questions. You can choose multiple options.\")\n",
    "df_to_csv(\"Big Bench Hard\", gemini_ruin_names, file_name = \"gemini_ruin_names\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GROQ - llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['(A)', '(C)', '(D)', '(B)', 'dearth, wind, & fire',\n",
       "       'rita, sue and bob poo'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_ruins = ruin_names.copy()\n",
    "groq_ruins['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n"
     ]
    }
   ],
   "source": [
    "groq_ruins = groq_line_generate(raw_dataset = ruin_names, output_dataset = groq_ruins, start_idx=0, end_idx=9, system_message=\"You only choose the options provided to answer the following questions. You can choose multiple options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_ruins = groq_line_generate(raw_dataset = ruin_names, output_dataset = groq_ruins, start_idx=10, end_idx=19, system_message=\"You only choose the options provided to answer the following questions. You can choose multiple options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_ruins = groq_line_generate(raw_dataset = ruin_names, output_dataset = groq_ruins, start_idx=20, end_idx=29, system_message=\"You only choose the options provided to answer the following questions. You can choose multiple options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_ruins = groq_line_generate(raw_dataset = ruin_names, output_dataset = groq_ruins, start_idx=30, end_idx=39, system_message=\"You only choose the options provided to answer the following questions. You can choose multiple options.\", model_name=\"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n"
     ]
    }
   ],
   "source": [
    "groq_ruins = groq_line_generate(raw_dataset = ruin_names, output_dataset = groq_ruins, start_idx=50, end_idx=59, system_message=\"You only choose the options provided to answer the following questions. You can choose multiple options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_ruins = groq_line_generate(raw_dataset = ruin_names, output_dataset = groq_ruins, start_idx=60, end_idx=69, system_message=\"You only choose the options provided to answer the following questions. You can choose multiple options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_ruins = groq_line_generate(raw_dataset = ruin_names, output_dataset = groq_ruins, start_idx=70, end_idx=79, system_message=\"You only choose the options provided to answer the following questions. You can choose multiple options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_ruins = groq_line_generate(raw_dataset = ruin_names, output_dataset = groq_ruins, start_idx=80, end_idx=89, system_message=\"You only choose the options provided to answer the following questions. You can choose multiple options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_ruins = groq_line_generate(raw_dataset = ruin_names, output_dataset = groq_ruins, start_idx=90, end_idx=99, system_message=\"You only choose the options provided to answer the following questions. You can choose multiple options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_ruins = groq_line_generate(raw_dataset = ruin_names, output_dataset = groq_ruins, start_idx=100, end_idx=109, system_message=\"You only choose the options provided to answer the following questions. You can choose multiple options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_ruins = groq_line_generate(raw_dataset = ruin_names, output_dataset = groq_ruins, start_idx=110, end_idx=119, system_message=\"You only choose the options provided to answer the following questions. You can choose multiple options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_ruins = groq_line_generate(raw_dataset = ruin_names, output_dataset = groq_ruins, start_idx=120, end_idx=129, system_message=\"You only choose the options provided to answer the following questions. You can choose multiple options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_ruins = groq_line_generate(raw_dataset = ruin_names, output_dataset = groq_ruins, start_idx=130, end_idx=139, system_message=\"You only choose the options provided to answer the following questions. You can choose multiple options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_ruins = groq_line_generate(raw_dataset = ruin_names, output_dataset = groq_ruins, start_idx=140, end_idx=149, system_message=\"You only choose the options provided to answer the following questions. You can choose multiple options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_ruins = groq_line_generate(raw_dataset = ruin_names, output_dataset = groq_ruins, start_idx=150, end_idx=159, system_message=\"You only choose the options provided to answer the following questions. You can choose multiple options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_ruins = groq_line_generate(raw_dataset = ruin_names, output_dataset = groq_ruins, start_idx=160, end_idx=169, system_message=\"You only choose the options provided to answer the following questions. You can choose multiple options.\", model_name=\"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n"
     ]
    }
   ],
   "source": [
    "groq_ruins = groq_line_generate(raw_dataset = ruin_names, output_dataset = groq_ruins, start_idx=170, end_idx=179, system_message=\"You only choose the options provided to answer the following questions. You can choose multiple options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_ruins = groq_line_generate(raw_dataset = ruin_names, output_dataset = groq_ruins, start_idx=180, end_idx=189, system_message=\"You only choose the options provided to answer the following questions. You can choose multiple options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_ruins = groq_line_generate(raw_dataset = ruin_names, output_dataset = groq_ruins, start_idx=190, end_idx=199, system_message=\"You only choose the options provided to answer the following questions. You can choose multiple options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_ruins = groq_line_generate(raw_dataset = ruin_names, output_dataset = groq_ruins, start_idx=200, end_idx=209, system_message=\"You only choose the options provided to answer the following questions. You can choose multiple options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_ruins = groq_line_generate(raw_dataset = ruin_names, output_dataset = groq_ruins, start_idx=210, end_idx=219, system_message=\"You only choose the options provided to answer the following questions. You can choose multiple options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_ruins = groq_line_generate(raw_dataset = ruin_names, output_dataset = groq_ruins, start_idx=220, end_idx=229, system_message=\"You only choose the options provided to answer the following questions. You can choose multiple options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_ruins = groq_line_generate(raw_dataset = ruin_names, output_dataset = groq_ruins, start_idx=230, end_idx=239, system_message=\"You only choose the options provided to answer the following questions. You can choose multiple options.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_ruins = groq_line_generate(raw_dataset = ruin_names, output_dataset = groq_ruins, start_idx=240, end_idx=249, system_message=\"You only choose the options provided to answer the following questions. You can choose multiple options.\", model_name=\"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total requests made: 10\n",
      "Successful requests: 10\n"
     ]
    }
   ],
   "source": [
    "groq_ruins = groq_line_generate(raw_dataset = ruin_names, output_dataset = groq_ruins, start_idx=40, end_idx=49, system_message=\"You only choose the options provided to answer the following questions. You can choose multiple options.\", model_name=\"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame exported successfully to /Users/ezishr/Library/CloudStorage/OneDrive-UniversityofCincinnati/Undergraduate Research/Check points/Big Bench Hard/groq_ruins.csv!\n"
     ]
    }
   ],
   "source": [
    "df_to_csv(\"Big Bench Hard\", groq_ruins, file_name = \"groq_ruins\", output_col = \"llama_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Testing - salient_translation_error_detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salient_detection = Big_Bench_Json_Processor_my('Big Bench Hard', 'salient_translation_error_detection.json').convert_df()\n",
    "print(salient_detection.info())\n",
    "print(salient_detection['target'].unique())\n",
    "salient_detection.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(salient_detection['input'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GEMINI Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_salient_detection = gemini_generator(salient_detection, \"You only answer the options provided to answer the following questions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_csv(\"Big Bench Hard\", gemini_salient_detection, file_name = \"gemini_salient_detection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Testing - snarks.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snarks = Big_Bench_Json_Processor_my('Big Bench Hard', 'snarks.json').convert_df()\n",
    "print(snarks.info())\n",
    "print(snarks['target'].unique())\n",
    "snarks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GEMINI Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_snarks = gemini_generator(snarks, \"You only answer the options provided to answer the following questions.\")\n",
    "df_to_csv(\"Big Bench Hard\", gemini_snarks, file_name = \"gemini_snarks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Testing - sports_understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sports_understanding = Big_Bench_Json_Processor_my('Big Bench Hard', 'sports_understanding.json').convert_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sports_understanding.info())\n",
    "print(sports_understanding['target'].unique())\n",
    "sports_understanding.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GEMINI Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_sports_understanding = gemini_generator(sports_understanding, \"You only Yes or No to the following questions.\")\n",
    "df_to_csv(\"Big Bench Hard\", gemini_sports_understanding, file_name = \"gemini_sports_understanding\", output_col=\"gemini_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GROQ - llama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sports_understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample5_10 = sports_understanding.head(10)\n",
    "groq_sample = groq(sample5_10, \"You only Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_sports_understanding = sports_understanding.copy()\n",
    "groq_sports_understanding['llama_output'] = groq_sample[\"llama-3.3-70b-versatile\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_sports_understanding.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sports_understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_10_19 = sports_understanding.loc[10:20, ].copy()\n",
    "sample_10_19.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_sample = groq(sample_10_19, \"You only Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")\n",
    "groq_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_sports_understanding.loc[10:19, \"llama_output\"] = groq_sample[\"llama-3.3-70b-versatile\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_sports_understanding.loc[10:19, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_sports_understanding.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_20_29 = sports_understanding.loc[20:29, ].copy()\n",
    "sample_20_29.reset_index(drop=True, inplace=True)\n",
    "groq_sample = groq(sample_20_29, \"You only Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")\n",
    "groq_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_sports_understanding.loc[20:29, \"llama_output\"] = groq_sample[\"llama-3.3-70b-versatile\"].values\n",
    "groq_sports_understanding.loc[20:29, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_sports_understanding = groq_line_generate(sports_understanding, groq_sports_understanding, 30, 39, \"You only Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_sports_understanding = groq_line_generate(sports_understanding, groq_sports_understanding, 40, 49, \"You only Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_sports_understanding = groq_line_generate(sports_understanding, groq_sports_understanding, 50, 59, \"You only Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_sports_understanding = groq_line_generate(sports_understanding, groq_sports_understanding, 60, 69, \"You only Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_sports_understanding = groq_line_generate(sports_understanding, groq_sports_understanding, 70, 79, \"You only Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_sports_understanding = groq_line_generate(sports_understanding, groq_sports_understanding, 80, 89, \"You only Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_sports_understanding = groq_line_generate(sports_understanding, groq_sports_understanding, 90, 99, \"You only Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_sports_understanding = groq_line_generate(sports_understanding, groq_sports_understanding, 90, 109, \"You only Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_sports_understanding = groq_line_generate(sports_understanding, groq_sports_understanding, 110, 119, \"You only Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_sports_understanding = groq_line_generate(sports_understanding, groq_sports_understanding, 120, 129, \"You only Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_sports_understanding = groq_line_generate(sports_understanding, groq_sports_understanding, 130, 139, \"You only Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_sports_understanding = groq_line_generate(sports_understanding, groq_sports_understanding, 140, 149, \"You only Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_sports_understanding = groq_line_generate(sports_understanding, groq_sports_understanding, 150, 159, \"You only Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_sports_understanding = groq_line_generate(sports_understanding, groq_sports_understanding, 160, 169, \"You only Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_sports_understanding = groq_line_generate(sports_understanding, groq_sports_understanding, 170, 179, \"You only Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_sports_understanding = groq_line_generate(sports_understanding, groq_sports_understanding, 180, 189, \"You only Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_sports_understanding = groq_line_generate(sports_understanding, groq_sports_understanding, 190, 199, \"You only Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_sports_understanding = groq_line_generate(sports_understanding, groq_sports_understanding, 200, 209, \"You only Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_sports_understanding = groq_line_generate(sports_understanding, groq_sports_understanding, 210, 219, \"You only Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_sports_understanding = groq_line_generate(sports_understanding, groq_sports_understanding, 220, 229, \"You only Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_sports_understanding = groq_line_generate(sports_understanding, groq_sports_understanding, 230, 239, \"You only Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_sports_understanding = groq_line_generate(sports_understanding, groq_sports_understanding, 240, 250, \"You only Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_sports_understanding.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_csv(\"Big Bench Hard\", groq_sports_understanding, file_name = \"groq_sports_understanding\", output_col=\"llama_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Groq(api_key=os.environ['GROQ_API_KEY'],)\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\":\"user\",\n",
    "            \"content\": groq_causal_judgement.loc[188, 'input']\n",
    "        },\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': \"You only Yes or No to the following questions.\"\n",
    "        }\n",
    "    ],\n",
    "    model = \"llama-3.3-70b-versatile\"\n",
    ")\n",
    "\n",
    "response = chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_causal_judgement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Testing - temporal_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_sequences = Big_Bench_Json_Processor_my('Big Bench Hard', 'temporal_sequences.json').convert_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   250 non-null    object\n",
      " 1   target  250 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 4.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Today, Susan went to the coffee shop. Between what times could they have gone?\\nWe know that:\\nSusan woke up at 7am.\\nLinda saw Susan driving to the water park from 7am to 11am.\\nJohn saw Susan buying clothes at the mall from 11am to 12pm.\\nJessica saw Susan taking photos near the Eiffel Tower from 12pm to 1pm.\\nSteven saw Susan buying lunch at the deli from 1pm to 2pm.\\nThomas saw Susan reading at the library from 2pm to 6pm.\\nThe coffee shop was closed after 9pm.\\nBetween what times could Susan have gone to the coffee shop?\\nOptions:\\n(A) 6pm to 9pm\\n(B) 7am to 11am\\n(C) 1pm to 2pm\\n(D) 2pm to 6pm</td>\n",
       "      <td>(A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Today, Emily went to the soccer field. Between what times could they have gone?\\nWe know that:\\nEmily woke up at 10am.\\nLinda saw Emily waiting at the train station from 10am to 12pm.\\nAshley saw Emily fixing their computer at the electronic store from 12pm to 1pm.\\nJohn saw Emily walking towards the Statue of Liberty from 1pm to 2pm.\\nThe soccer field was closed after 8pm.\\nBetween what times could Emily have gone to the soccer field?\\nOptions:\\n(A) 12pm to 1pm\\n(B) 10am to 12pm\\n(C) 2pm to 8pm\\n(D) 1pm to 2pm</td>\n",
       "      <td>(C)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Today, Susan went to the restaurant. Between what times could they have gone?\\nWe know that:\\nSusan woke up at 11am.\\nLisa saw Susan taking photos near the Leaning Tower of Pisa from 11am to 1pm.\\nWilliam saw Susan buying cookies at a bakery from 1pm to 3pm.\\nJennifer saw Susan working at the office from 3pm to 6pm.\\nJason saw Susan walking towards the Statue of Liberty from 6pm to 7pm.\\nAshley saw Susan waiting at the airport from 7pm to 9pm.\\nThe restaurant was closed after 10pm.\\nBetween what times could Susan have gone to the restaurant?\\nOptions:\\n(A) 6pm to 7pm\\n(B) 9pm to 10pm\\n(C) 11am to 1pm\\n(D) 7pm to 9pm</td>\n",
       "      <td>(B)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Today, James went to the beach. Between what times could they have gone?\\nWe know that:\\nJames woke up at 5am.\\nSean saw James walking towards the Statue of Liberty from 5am to 6am.\\nMichael saw James driving to the water park from 6am to 7am.\\nAnthony saw James reading at the library from 7am to 3pm.\\nWilliam saw James getting a coffee at the cafe from 4pm to 9pm.\\nThe beach was closed after 9pm.\\nBetween what times could James have gone to the beach?\\nOptions:\\n(A) 7am to 3pm\\n(B) 5am to 6am\\n(C) 4pm to 9pm\\n(D) 3pm to 4pm</td>\n",
       "      <td>(D)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Today, Jason went to the movies. Between what times could they have gone?\\nWe know that:\\nJason woke up at 10am.\\nLinda saw Jason getting a coffee at the cafe from 10am to 3pm.\\nJennifer saw Jason walking towards the Statue of Liberty from 6pm to 7pm.\\nSean saw Jason buying a phone at the electronics store from 7pm to 10pm.\\nThe movies was closed after 10pm.\\nBetween what times could Jason have gone to the movies?\\nOptions:\\n(A) 3pm to 6pm\\n(B) 10am to 3pm\\n(C) 7pm to 10pm\\n(D) 6pm to 7pm</td>\n",
       "      <td>(A)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             input  \\\n",
       "0                   Today, Susan went to the coffee shop. Between what times could they have gone?\\nWe know that:\\nSusan woke up at 7am.\\nLinda saw Susan driving to the water park from 7am to 11am.\\nJohn saw Susan buying clothes at the mall from 11am to 12pm.\\nJessica saw Susan taking photos near the Eiffel Tower from 12pm to 1pm.\\nSteven saw Susan buying lunch at the deli from 1pm to 2pm.\\nThomas saw Susan reading at the library from 2pm to 6pm.\\nThe coffee shop was closed after 9pm.\\nBetween what times could Susan have gone to the coffee shop?\\nOptions:\\n(A) 6pm to 9pm\\n(B) 7am to 11am\\n(C) 1pm to 2pm\\n(D) 2pm to 6pm   \n",
       "1                                                                                                             Today, Emily went to the soccer field. Between what times could they have gone?\\nWe know that:\\nEmily woke up at 10am.\\nLinda saw Emily waiting at the train station from 10am to 12pm.\\nAshley saw Emily fixing their computer at the electronic store from 12pm to 1pm.\\nJohn saw Emily walking towards the Statue of Liberty from 1pm to 2pm.\\nThe soccer field was closed after 8pm.\\nBetween what times could Emily have gone to the soccer field?\\nOptions:\\n(A) 12pm to 1pm\\n(B) 10am to 12pm\\n(C) 2pm to 8pm\\n(D) 1pm to 2pm   \n",
       "2  Today, Susan went to the restaurant. Between what times could they have gone?\\nWe know that:\\nSusan woke up at 11am.\\nLisa saw Susan taking photos near the Leaning Tower of Pisa from 11am to 1pm.\\nWilliam saw Susan buying cookies at a bakery from 1pm to 3pm.\\nJennifer saw Susan working at the office from 3pm to 6pm.\\nJason saw Susan walking towards the Statue of Liberty from 6pm to 7pm.\\nAshley saw Susan waiting at the airport from 7pm to 9pm.\\nThe restaurant was closed after 10pm.\\nBetween what times could Susan have gone to the restaurant?\\nOptions:\\n(A) 6pm to 7pm\\n(B) 9pm to 10pm\\n(C) 11am to 1pm\\n(D) 7pm to 9pm   \n",
       "3                                                                                               Today, James went to the beach. Between what times could they have gone?\\nWe know that:\\nJames woke up at 5am.\\nSean saw James walking towards the Statue of Liberty from 5am to 6am.\\nMichael saw James driving to the water park from 6am to 7am.\\nAnthony saw James reading at the library from 7am to 3pm.\\nWilliam saw James getting a coffee at the cafe from 4pm to 9pm.\\nThe beach was closed after 9pm.\\nBetween what times could James have gone to the beach?\\nOptions:\\n(A) 7am to 3pm\\n(B) 5am to 6am\\n(C) 4pm to 9pm\\n(D) 3pm to 4pm   \n",
       "4                                                                                                                                    Today, Jason went to the movies. Between what times could they have gone?\\nWe know that:\\nJason woke up at 10am.\\nLinda saw Jason getting a coffee at the cafe from 10am to 3pm.\\nJennifer saw Jason walking towards the Statue of Liberty from 6pm to 7pm.\\nSean saw Jason buying a phone at the electronics store from 7pm to 10pm.\\nThe movies was closed after 10pm.\\nBetween what times could Jason have gone to the movies?\\nOptions:\\n(A) 3pm to 6pm\\n(B) 10am to 3pm\\n(C) 7pm to 10pm\\n(D) 6pm to 7pm   \n",
       "\n",
       "  target  \n",
       "0    (A)  \n",
       "1    (C)  \n",
       "2    (B)  \n",
       "3    (D)  \n",
       "4    (A)  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temporal_sequences.info()\n",
    "temporal_sequences.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GEMINI Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_temporal_sequences = gemini_generator(temporal_sequences, \"You only answer the options provided to the following questions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_csv(\"Big Bench Hard\", gemini_temporal_sequences, file_name = \"gemini_temporal_sequences\", output_col=\"gemini_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GROQ - llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Today, Susan went to the coffee shop. Between what times could they have gone?\\nWe know that:\\nSusan woke up at 7am.\\nLinda saw Susan driving to the water park from 7am to 11am.\\nJohn saw Susan buying clothes at the mall from 11am to 12pm.\\nJessica saw Susan taking photos near the Eiffel Tower from 12pm to 1pm.\\nSteven saw Susan buying lunch at the deli from 1pm to 2pm.\\nThomas saw Susan reading at the library from 2pm to 6pm.\\nThe coffee shop was closed after 9pm.\\nBetween what times could Susan have gone to the coffee shop?\\nOptions:\\n(A) 6pm to 9pm\\n(B) 7am to 11am\\n(C) 1pm to 2pm\\n(D) 2pm to 6pm</td>\n",
       "      <td>(A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Today, Emily went to the soccer field. Between what times could they have gone?\\nWe know that:\\nEmily woke up at 10am.\\nLinda saw Emily waiting at the train station from 10am to 12pm.\\nAshley saw Emily fixing their computer at the electronic store from 12pm to 1pm.\\nJohn saw Emily walking towards the Statue of Liberty from 1pm to 2pm.\\nThe soccer field was closed after 8pm.\\nBetween what times could Emily have gone to the soccer field?\\nOptions:\\n(A) 12pm to 1pm\\n(B) 10am to 12pm\\n(C) 2pm to 8pm\\n(D) 1pm to 2pm</td>\n",
       "      <td>(C)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Today, Susan went to the restaurant. Between what times could they have gone?\\nWe know that:\\nSusan woke up at 11am.\\nLisa saw Susan taking photos near the Leaning Tower of Pisa from 11am to 1pm.\\nWilliam saw Susan buying cookies at a bakery from 1pm to 3pm.\\nJennifer saw Susan working at the office from 3pm to 6pm.\\nJason saw Susan walking towards the Statue of Liberty from 6pm to 7pm.\\nAshley saw Susan waiting at the airport from 7pm to 9pm.\\nThe restaurant was closed after 10pm.\\nBetween what times could Susan have gone to the restaurant?\\nOptions:\\n(A) 6pm to 7pm\\n(B) 9pm to 10pm\\n(C) 11am to 1pm\\n(D) 7pm to 9pm</td>\n",
       "      <td>(B)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Today, James went to the beach. Between what times could they have gone?\\nWe know that:\\nJames woke up at 5am.\\nSean saw James walking towards the Statue of Liberty from 5am to 6am.\\nMichael saw James driving to the water park from 6am to 7am.\\nAnthony saw James reading at the library from 7am to 3pm.\\nWilliam saw James getting a coffee at the cafe from 4pm to 9pm.\\nThe beach was closed after 9pm.\\nBetween what times could James have gone to the beach?\\nOptions:\\n(A) 7am to 3pm\\n(B) 5am to 6am\\n(C) 4pm to 9pm\\n(D) 3pm to 4pm</td>\n",
       "      <td>(D)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Today, Jason went to the movies. Between what times could they have gone?\\nWe know that:\\nJason woke up at 10am.\\nLinda saw Jason getting a coffee at the cafe from 10am to 3pm.\\nJennifer saw Jason walking towards the Statue of Liberty from 6pm to 7pm.\\nSean saw Jason buying a phone at the electronics store from 7pm to 10pm.\\nThe movies was closed after 10pm.\\nBetween what times could Jason have gone to the movies?\\nOptions:\\n(A) 3pm to 6pm\\n(B) 10am to 3pm\\n(C) 7pm to 10pm\\n(D) 6pm to 7pm</td>\n",
       "      <td>(A)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             input  \\\n",
       "0                   Today, Susan went to the coffee shop. Between what times could they have gone?\\nWe know that:\\nSusan woke up at 7am.\\nLinda saw Susan driving to the water park from 7am to 11am.\\nJohn saw Susan buying clothes at the mall from 11am to 12pm.\\nJessica saw Susan taking photos near the Eiffel Tower from 12pm to 1pm.\\nSteven saw Susan buying lunch at the deli from 1pm to 2pm.\\nThomas saw Susan reading at the library from 2pm to 6pm.\\nThe coffee shop was closed after 9pm.\\nBetween what times could Susan have gone to the coffee shop?\\nOptions:\\n(A) 6pm to 9pm\\n(B) 7am to 11am\\n(C) 1pm to 2pm\\n(D) 2pm to 6pm   \n",
       "1                                                                                                             Today, Emily went to the soccer field. Between what times could they have gone?\\nWe know that:\\nEmily woke up at 10am.\\nLinda saw Emily waiting at the train station from 10am to 12pm.\\nAshley saw Emily fixing their computer at the electronic store from 12pm to 1pm.\\nJohn saw Emily walking towards the Statue of Liberty from 1pm to 2pm.\\nThe soccer field was closed after 8pm.\\nBetween what times could Emily have gone to the soccer field?\\nOptions:\\n(A) 12pm to 1pm\\n(B) 10am to 12pm\\n(C) 2pm to 8pm\\n(D) 1pm to 2pm   \n",
       "2  Today, Susan went to the restaurant. Between what times could they have gone?\\nWe know that:\\nSusan woke up at 11am.\\nLisa saw Susan taking photos near the Leaning Tower of Pisa from 11am to 1pm.\\nWilliam saw Susan buying cookies at a bakery from 1pm to 3pm.\\nJennifer saw Susan working at the office from 3pm to 6pm.\\nJason saw Susan walking towards the Statue of Liberty from 6pm to 7pm.\\nAshley saw Susan waiting at the airport from 7pm to 9pm.\\nThe restaurant was closed after 10pm.\\nBetween what times could Susan have gone to the restaurant?\\nOptions:\\n(A) 6pm to 7pm\\n(B) 9pm to 10pm\\n(C) 11am to 1pm\\n(D) 7pm to 9pm   \n",
       "3                                                                                               Today, James went to the beach. Between what times could they have gone?\\nWe know that:\\nJames woke up at 5am.\\nSean saw James walking towards the Statue of Liberty from 5am to 6am.\\nMichael saw James driving to the water park from 6am to 7am.\\nAnthony saw James reading at the library from 7am to 3pm.\\nWilliam saw James getting a coffee at the cafe from 4pm to 9pm.\\nThe beach was closed after 9pm.\\nBetween what times could James have gone to the beach?\\nOptions:\\n(A) 7am to 3pm\\n(B) 5am to 6am\\n(C) 4pm to 9pm\\n(D) 3pm to 4pm   \n",
       "4                                                                                                                                    Today, Jason went to the movies. Between what times could they have gone?\\nWe know that:\\nJason woke up at 10am.\\nLinda saw Jason getting a coffee at the cafe from 10am to 3pm.\\nJennifer saw Jason walking towards the Statue of Liberty from 6pm to 7pm.\\nSean saw Jason buying a phone at the electronics store from 7pm to 10pm.\\nThe movies was closed after 10pm.\\nBetween what times could Jason have gone to the movies?\\nOptions:\\n(A) 3pm to 6pm\\n(B) 10am to 3pm\\n(C) 7pm to 10pm\\n(D) 6pm to 7pm   \n",
       "\n",
       "  target  \n",
       "0    (A)  \n",
       "1    (C)  \n",
       "2    (B)  \n",
       "3    (D)  \n",
       "4    (A)  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_temporal = temporal_sequences.copy()\n",
    "groq_temporal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n"
     ]
    }
   ],
   "source": [
    "groq_temporal = groq_line_generate(raw_dataset = temporal_sequences, output_dataset = groq_temporal, start_idx=0, end_idx=9, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_temporal = groq_line_generate(raw_dataset = temporal_sequences, output_dataset = groq_temporal, start_idx=10, end_idx=19, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_temporal = groq_line_generate(raw_dataset = temporal_sequences, output_dataset = groq_temporal, start_idx=20, end_idx=29, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_temporal = groq_line_generate(raw_dataset = temporal_sequences, output_dataset = groq_temporal, start_idx=30, end_idx=39, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_temporal = groq_line_generate(raw_dataset = temporal_sequences, output_dataset = groq_temporal, start_idx=40, end_idx=49, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_temporal = groq_line_generate(raw_dataset = temporal_sequences, output_dataset = groq_temporal, start_idx=50, end_idx=59, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_temporal = groq_line_generate(raw_dataset = temporal_sequences, output_dataset = groq_temporal, start_idx=60, end_idx=69, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_temporal = groq_line_generate(raw_dataset = temporal_sequences, output_dataset = groq_temporal, start_idx=70, end_idx=79, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_temporal = groq_line_generate(raw_dataset = temporal_sequences, output_dataset = groq_temporal, start_idx=80, end_idx=89, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_temporal = groq_line_generate(raw_dataset = temporal_sequences, output_dataset = groq_temporal, start_idx=90, end_idx=99, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_temporal = groq_line_generate(raw_dataset = temporal_sequences, output_dataset = groq_temporal, start_idx=100, end_idx=109, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_temporal = groq_line_generate(raw_dataset = temporal_sequences, output_dataset = groq_temporal, start_idx=110, end_idx=119, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_temporal = groq_line_generate(raw_dataset = temporal_sequences, output_dataset = groq_temporal, start_idx=120, end_idx=129, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_temporal = groq_line_generate(raw_dataset = temporal_sequences, output_dataset = groq_temporal, start_idx=130, end_idx=139, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_temporal = groq_line_generate(raw_dataset = temporal_sequences, output_dataset = groq_temporal, start_idx=140, end_idx=149, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_temporal = groq_line_generate(raw_dataset = temporal_sequences, output_dataset = groq_temporal, start_idx=150, end_idx=159, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_temporal = groq_line_generate(raw_dataset = temporal_sequences, output_dataset = groq_temporal, start_idx=160, end_idx=169, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_temporal = groq_line_generate(raw_dataset = temporal_sequences, output_dataset = groq_temporal, start_idx=170, end_idx=179, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_temporal = groq_line_generate(raw_dataset = temporal_sequences, output_dataset = groq_temporal, start_idx=180, end_idx=189, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_temporal = groq_line_generate(raw_dataset = temporal_sequences, output_dataset = groq_temporal, start_idx=190, end_idx=199, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_temporal = groq_line_generate(raw_dataset = temporal_sequences, output_dataset = groq_temporal, start_idx=200, end_idx=209, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_temporal = groq_line_generate(raw_dataset = temporal_sequences, output_dataset = groq_temporal, start_idx=210, end_idx=219, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_temporal = groq_line_generate(raw_dataset = temporal_sequences, output_dataset = groq_temporal, start_idx=220, end_idx=229, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_temporal = groq_line_generate(raw_dataset = temporal_sequences, output_dataset = groq_temporal, start_idx=230, end_idx=239, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_temporal = groq_line_generate(raw_dataset = temporal_sequences, output_dataset = groq_temporal, start_idx=240, end_idx=249, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   input         250 non-null    object\n",
      " 1   target        250 non-null    object\n",
      " 2   llama_output  250 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "groq_temporal.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame exported successfully to /Users/ezishr/Library/CloudStorage/OneDrive-UniversityofCincinnati/Undergraduate Research/Check points/Big Bench Hard/groq_temporal.csv!\n"
     ]
    }
   ],
   "source": [
    "df_to_csv(\"Big Bench Hard\", groq_temporal, file_name = \"groq_temporal\", output_col=\"llama_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Testing - tracking_shuffled_objects_five"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_five = Big_Bench_Json_Processor_my('Big Bench Hard', 'tracking_shuffled_objects_five_objects.json').convert_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   250 non-null    object\n",
      " 1   target  250 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 4.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice, Bob, Claire, Dave, and Eve are dancers at a square dance. At the start of a song, they each have a partner: Alice is dancing with Patrick, Bob is dancing with Sam, Claire is dancing with Jamie, Dave is dancing with Lola, and Eve is dancing with Melissa.\\nThroughout the song, the dancers often trade partners. First, Dave and Eve switch partners. Then, Dave and Alice switch partners. Then, Eve and Alice switch partners. Then, Claire and Bob switch partners. Finally, Dave and Alice switch partners. At the end of the dance, Alice is dancing with\\nOptions:\\n(A) Patrick\\n(B) Sam\\n(C) Jamie\\n(D) Lola\\n(E) Melissa</td>\n",
       "      <td>(A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alice, Bob, Claire, Dave, and Eve are dancers at a square dance. At the start of a song, they each have a partner: Alice is dancing with Ophelia, Bob is dancing with Jamie, Claire is dancing with Melissa, Dave is dancing with Rodrigo, and Eve is dancing with Patrick.\\nThroughout the song, the dancers often trade partners. First, Claire and Bob switch partners. Then, Claire and Eve switch partners. Then, Claire and Bob switch partners. Then, Eve and Dave switch partners. Finally, Claire and Alice switch partners. At the end of the dance, Alice is dancing with\\nOptions:\\n(A) Ophelia\\n(B) Jamie\\n(C) Melissa\\n(D) Rodrigo\\n(E) Patrick</td>\n",
       "      <td>(C)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alice, Bob, Claire, Dave, and Eve are dancers at a square dance. At the start of a song, they each have a partner: Alice is dancing with Jamie, Bob is dancing with Lola, Claire is dancing with Izzi, Dave is dancing with Rodrigo, and Eve is dancing with Ophelia.\\nThroughout the song, the dancers often trade partners. First, Bob and Eve switch partners. Then, Alice and Bob switch partners. Then, Dave and Alice switch partners. Then, Dave and Claire switch partners. Finally, Bob and Claire switch partners. At the end of the dance, Claire is dancing with\\nOptions:\\n(A) Jamie\\n(B) Lola\\n(C) Izzi\\n(D) Rodrigo\\n(E) Ophelia</td>\n",
       "      <td>(A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alice, Bob, Claire, Dave, and Eve are friends and avid readers who occasionally trade books. At the start of the semester, they each buy one new book: Alice gets Catch-22, Bob gets Hound of the Baskervilles, Claire gets Frankenstein, Dave gets The Pearl, and Eve gets The Fellowship of the Ring.\\nAs the semester proceeds, they start trading around the new books. First, Eve and Alice swap books. Then, Alice and Claire swap books. Then, Alice and Bob swap books. Then, Dave and Alice swap books. Finally, Dave and Claire swap books. At the end of the semester, Dave has\\nOptions:\\n(A) Catch-22\\n(B) Hound of the Baskervilles\\n(C) Frankenstein\\n(D) The Pearl\\n(E) The Fellowship of the Ring</td>\n",
       "      <td>(E)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alice, Bob, Claire, Dave, and Eve are friends and avid readers who occasionally trade books. At the start of the semester, they each buy one new book: Alice gets Moby Dick, Bob gets Ulysses, Claire gets The Fellowship of the Ring, Dave gets Lolita, and Eve gets Catch-22.\\nAs the semester proceeds, they start trading around the new books. First, Claire and Bob swap books. Then, Claire and Dave swap books. Then, Dave and Alice swap books. Then, Dave and Bob swap books. Finally, Eve and Dave swap books. At the end of the semester, Claire has\\nOptions:\\n(A) Moby Dick\\n(B) Ulysses\\n(C) The Fellowship of the Ring\\n(D) Lolita\\n(E) Catch-22</td>\n",
       "      <td>(D)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                input  \\\n",
       "0                                                                        Alice, Bob, Claire, Dave, and Eve are dancers at a square dance. At the start of a song, they each have a partner: Alice is dancing with Patrick, Bob is dancing with Sam, Claire is dancing with Jamie, Dave is dancing with Lola, and Eve is dancing with Melissa.\\nThroughout the song, the dancers often trade partners. First, Dave and Eve switch partners. Then, Dave and Alice switch partners. Then, Eve and Alice switch partners. Then, Claire and Bob switch partners. Finally, Dave and Alice switch partners. At the end of the dance, Alice is dancing with\\nOptions:\\n(A) Patrick\\n(B) Sam\\n(C) Jamie\\n(D) Lola\\n(E) Melissa   \n",
       "1                                                       Alice, Bob, Claire, Dave, and Eve are dancers at a square dance. At the start of a song, they each have a partner: Alice is dancing with Ophelia, Bob is dancing with Jamie, Claire is dancing with Melissa, Dave is dancing with Rodrigo, and Eve is dancing with Patrick.\\nThroughout the song, the dancers often trade partners. First, Claire and Bob switch partners. Then, Claire and Eve switch partners. Then, Claire and Bob switch partners. Then, Eve and Dave switch partners. Finally, Claire and Alice switch partners. At the end of the dance, Alice is dancing with\\nOptions:\\n(A) Ophelia\\n(B) Jamie\\n(C) Melissa\\n(D) Rodrigo\\n(E) Patrick   \n",
       "2                                                                     Alice, Bob, Claire, Dave, and Eve are dancers at a square dance. At the start of a song, they each have a partner: Alice is dancing with Jamie, Bob is dancing with Lola, Claire is dancing with Izzi, Dave is dancing with Rodrigo, and Eve is dancing with Ophelia.\\nThroughout the song, the dancers often trade partners. First, Bob and Eve switch partners. Then, Alice and Bob switch partners. Then, Dave and Alice switch partners. Then, Dave and Claire switch partners. Finally, Bob and Claire switch partners. At the end of the dance, Claire is dancing with\\nOptions:\\n(A) Jamie\\n(B) Lola\\n(C) Izzi\\n(D) Rodrigo\\n(E) Ophelia   \n",
       "3  Alice, Bob, Claire, Dave, and Eve are friends and avid readers who occasionally trade books. At the start of the semester, they each buy one new book: Alice gets Catch-22, Bob gets Hound of the Baskervilles, Claire gets Frankenstein, Dave gets The Pearl, and Eve gets The Fellowship of the Ring.\\nAs the semester proceeds, they start trading around the new books. First, Eve and Alice swap books. Then, Alice and Claire swap books. Then, Alice and Bob swap books. Then, Dave and Alice swap books. Finally, Dave and Claire swap books. At the end of the semester, Dave has\\nOptions:\\n(A) Catch-22\\n(B) Hound of the Baskervilles\\n(C) Frankenstein\\n(D) The Pearl\\n(E) The Fellowship of the Ring   \n",
       "4                                                    Alice, Bob, Claire, Dave, and Eve are friends and avid readers who occasionally trade books. At the start of the semester, they each buy one new book: Alice gets Moby Dick, Bob gets Ulysses, Claire gets The Fellowship of the Ring, Dave gets Lolita, and Eve gets Catch-22.\\nAs the semester proceeds, they start trading around the new books. First, Claire and Bob swap books. Then, Claire and Dave swap books. Then, Dave and Alice swap books. Then, Dave and Bob swap books. Finally, Eve and Dave swap books. At the end of the semester, Claire has\\nOptions:\\n(A) Moby Dick\\n(B) Ulysses\\n(C) The Fellowship of the Ring\\n(D) Lolita\\n(E) Catch-22   \n",
       "\n",
       "  target  \n",
       "0    (A)  \n",
       "1    (C)  \n",
       "2    (A)  \n",
       "3    (E)  \n",
       "4    (D)  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracking_five.info()\n",
    "tracking_five.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracking_five['input'].is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GEMINI Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_tracking_five = gemini_generator(tracking_five, \"You only answer the options provided to the following questions.\")\n",
    "df_to_csv(\"Big Bench Hard\", gemini_tracking_five, file_name = \"gemini_tracking_five\", output_col=\"gemini_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GROQ - llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice, Bob, Claire, Dave, and Eve are dancers at a square dance. At the start of a song, they each have a partner: Alice is dancing with Patrick, Bob is dancing with Sam, Claire is dancing with Jamie, Dave is dancing with Lola, and Eve is dancing with Melissa.\\nThroughout the song, the dancers often trade partners. First, Dave and Eve switch partners. Then, Dave and Alice switch partners. Then, Eve and Alice switch partners. Then, Claire and Bob switch partners. Finally, Dave and Alice switch partners. At the end of the dance, Alice is dancing with\\nOptions:\\n(A) Patrick\\n(B) Sam\\n(C) Jamie\\n(D) Lola\\n(E) Melissa</td>\n",
       "      <td>(A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alice, Bob, Claire, Dave, and Eve are dancers at a square dance. At the start of a song, they each have a partner: Alice is dancing with Ophelia, Bob is dancing with Jamie, Claire is dancing with Melissa, Dave is dancing with Rodrigo, and Eve is dancing with Patrick.\\nThroughout the song, the dancers often trade partners. First, Claire and Bob switch partners. Then, Claire and Eve switch partners. Then, Claire and Bob switch partners. Then, Eve and Dave switch partners. Finally, Claire and Alice switch partners. At the end of the dance, Alice is dancing with\\nOptions:\\n(A) Ophelia\\n(B) Jamie\\n(C) Melissa\\n(D) Rodrigo\\n(E) Patrick</td>\n",
       "      <td>(C)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alice, Bob, Claire, Dave, and Eve are dancers at a square dance. At the start of a song, they each have a partner: Alice is dancing with Jamie, Bob is dancing with Lola, Claire is dancing with Izzi, Dave is dancing with Rodrigo, and Eve is dancing with Ophelia.\\nThroughout the song, the dancers often trade partners. First, Bob and Eve switch partners. Then, Alice and Bob switch partners. Then, Dave and Alice switch partners. Then, Dave and Claire switch partners. Finally, Bob and Claire switch partners. At the end of the dance, Claire is dancing with\\nOptions:\\n(A) Jamie\\n(B) Lola\\n(C) Izzi\\n(D) Rodrigo\\n(E) Ophelia</td>\n",
       "      <td>(A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alice, Bob, Claire, Dave, and Eve are friends and avid readers who occasionally trade books. At the start of the semester, they each buy one new book: Alice gets Catch-22, Bob gets Hound of the Baskervilles, Claire gets Frankenstein, Dave gets The Pearl, and Eve gets The Fellowship of the Ring.\\nAs the semester proceeds, they start trading around the new books. First, Eve and Alice swap books. Then, Alice and Claire swap books. Then, Alice and Bob swap books. Then, Dave and Alice swap books. Finally, Dave and Claire swap books. At the end of the semester, Dave has\\nOptions:\\n(A) Catch-22\\n(B) Hound of the Baskervilles\\n(C) Frankenstein\\n(D) The Pearl\\n(E) The Fellowship of the Ring</td>\n",
       "      <td>(E)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alice, Bob, Claire, Dave, and Eve are friends and avid readers who occasionally trade books. At the start of the semester, they each buy one new book: Alice gets Moby Dick, Bob gets Ulysses, Claire gets The Fellowship of the Ring, Dave gets Lolita, and Eve gets Catch-22.\\nAs the semester proceeds, they start trading around the new books. First, Claire and Bob swap books. Then, Claire and Dave swap books. Then, Dave and Alice swap books. Then, Dave and Bob swap books. Finally, Eve and Dave swap books. At the end of the semester, Claire has\\nOptions:\\n(A) Moby Dick\\n(B) Ulysses\\n(C) The Fellowship of the Ring\\n(D) Lolita\\n(E) Catch-22</td>\n",
       "      <td>(D)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                input  \\\n",
       "0                                                                        Alice, Bob, Claire, Dave, and Eve are dancers at a square dance. At the start of a song, they each have a partner: Alice is dancing with Patrick, Bob is dancing with Sam, Claire is dancing with Jamie, Dave is dancing with Lola, and Eve is dancing with Melissa.\\nThroughout the song, the dancers often trade partners. First, Dave and Eve switch partners. Then, Dave and Alice switch partners. Then, Eve and Alice switch partners. Then, Claire and Bob switch partners. Finally, Dave and Alice switch partners. At the end of the dance, Alice is dancing with\\nOptions:\\n(A) Patrick\\n(B) Sam\\n(C) Jamie\\n(D) Lola\\n(E) Melissa   \n",
       "1                                                       Alice, Bob, Claire, Dave, and Eve are dancers at a square dance. At the start of a song, they each have a partner: Alice is dancing with Ophelia, Bob is dancing with Jamie, Claire is dancing with Melissa, Dave is dancing with Rodrigo, and Eve is dancing with Patrick.\\nThroughout the song, the dancers often trade partners. First, Claire and Bob switch partners. Then, Claire and Eve switch partners. Then, Claire and Bob switch partners. Then, Eve and Dave switch partners. Finally, Claire and Alice switch partners. At the end of the dance, Alice is dancing with\\nOptions:\\n(A) Ophelia\\n(B) Jamie\\n(C) Melissa\\n(D) Rodrigo\\n(E) Patrick   \n",
       "2                                                                     Alice, Bob, Claire, Dave, and Eve are dancers at a square dance. At the start of a song, they each have a partner: Alice is dancing with Jamie, Bob is dancing with Lola, Claire is dancing with Izzi, Dave is dancing with Rodrigo, and Eve is dancing with Ophelia.\\nThroughout the song, the dancers often trade partners. First, Bob and Eve switch partners. Then, Alice and Bob switch partners. Then, Dave and Alice switch partners. Then, Dave and Claire switch partners. Finally, Bob and Claire switch partners. At the end of the dance, Claire is dancing with\\nOptions:\\n(A) Jamie\\n(B) Lola\\n(C) Izzi\\n(D) Rodrigo\\n(E) Ophelia   \n",
       "3  Alice, Bob, Claire, Dave, and Eve are friends and avid readers who occasionally trade books. At the start of the semester, they each buy one new book: Alice gets Catch-22, Bob gets Hound of the Baskervilles, Claire gets Frankenstein, Dave gets The Pearl, and Eve gets The Fellowship of the Ring.\\nAs the semester proceeds, they start trading around the new books. First, Eve and Alice swap books. Then, Alice and Claire swap books. Then, Alice and Bob swap books. Then, Dave and Alice swap books. Finally, Dave and Claire swap books. At the end of the semester, Dave has\\nOptions:\\n(A) Catch-22\\n(B) Hound of the Baskervilles\\n(C) Frankenstein\\n(D) The Pearl\\n(E) The Fellowship of the Ring   \n",
       "4                                                    Alice, Bob, Claire, Dave, and Eve are friends and avid readers who occasionally trade books. At the start of the semester, they each buy one new book: Alice gets Moby Dick, Bob gets Ulysses, Claire gets The Fellowship of the Ring, Dave gets Lolita, and Eve gets Catch-22.\\nAs the semester proceeds, they start trading around the new books. First, Claire and Bob swap books. Then, Claire and Dave swap books. Then, Dave and Alice swap books. Then, Dave and Bob swap books. Finally, Eve and Dave swap books. At the end of the semester, Claire has\\nOptions:\\n(A) Moby Dick\\n(B) Ulysses\\n(C) The Fellowship of the Ring\\n(D) Lolita\\n(E) Catch-22   \n",
       "\n",
       "  target  \n",
       "0    (A)  \n",
       "1    (C)  \n",
       "2    (A)  \n",
       "3    (E)  \n",
       "4    (D)  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_tracking_five = tracking_five.copy()\n",
    "groq_tracking_five.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n"
     ]
    }
   ],
   "source": [
    "groq_tracking_five = groq_line_generate(raw_dataset = tracking_five, output_dataset = groq_tracking_five, start_idx=0, end_idx=9, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_five = groq_line_generate(raw_dataset = tracking_five, output_dataset = groq_tracking_five, start_idx=10, end_idx=19, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_five = groq_line_generate(raw_dataset = tracking_five, output_dataset = groq_tracking_five, start_idx=20, end_idx=29, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_five = groq_line_generate(raw_dataset = tracking_five, output_dataset = groq_tracking_five, start_idx=30, end_idx=39, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_five = groq_line_generate(raw_dataset = tracking_five, output_dataset = groq_tracking_five, start_idx=40, end_idx=49, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_five = groq_line_generate(raw_dataset = tracking_five, output_dataset = groq_tracking_five, start_idx=50, end_idx=59, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_five = groq_line_generate(raw_dataset = tracking_five, output_dataset = groq_tracking_five, start_idx=60, end_idx=69, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_five = groq_line_generate(raw_dataset = tracking_five, output_dataset = groq_tracking_five, start_idx=70, end_idx=79, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_five = groq_line_generate(raw_dataset = tracking_five, output_dataset = groq_tracking_five, start_idx=80, end_idx=89, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_five = groq_line_generate(raw_dataset = tracking_five, output_dataset = groq_tracking_five, start_idx=90, end_idx=99, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_five = groq_line_generate(raw_dataset = tracking_five, output_dataset = groq_tracking_five, start_idx=100, end_idx=109, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_five = groq_line_generate(raw_dataset = tracking_five, output_dataset = groq_tracking_five, start_idx=110, end_idx=119, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_five = groq_line_generate(raw_dataset = tracking_five, output_dataset = groq_tracking_five, start_idx=120, end_idx=129, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "\n",
    "groq_tracking_five = groq_line_generate(raw_dataset = tracking_five, output_dataset = groq_tracking_five, start_idx=130, end_idx=139, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_five = groq_line_generate(raw_dataset = tracking_five, output_dataset = groq_tracking_five, start_idx=140, end_idx=149, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_five = groq_line_generate(raw_dataset = tracking_five, output_dataset = groq_tracking_five, start_idx=150, end_idx=159, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "\n",
    "groq_tracking_five = groq_line_generate(raw_dataset = tracking_five, output_dataset = groq_tracking_five, start_idx=160, end_idx=169, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_five = groq_line_generate(raw_dataset = tracking_five, output_dataset = groq_tracking_five, start_idx=170, end_idx=179, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_five = groq_line_generate(raw_dataset = tracking_five, output_dataset = groq_tracking_five, start_idx=180, end_idx=189, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_five = groq_line_generate(raw_dataset = tracking_five, output_dataset = groq_tracking_five, start_idx=190, end_idx=199, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_five = groq_line_generate(raw_dataset = tracking_five, output_dataset = groq_tracking_five, start_idx=200, end_idx=209, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_five = groq_line_generate(raw_dataset = tracking_five, output_dataset = groq_tracking_five, start_idx=210, end_idx=219, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_five = groq_line_generate(raw_dataset = tracking_five, output_dataset = groq_tracking_five, start_idx=220, end_idx=229, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_five = groq_line_generate(raw_dataset = tracking_five, output_dataset = groq_tracking_five, start_idx=230, end_idx=239, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_five = groq_line_generate(raw_dataset = tracking_five, output_dataset = groq_tracking_five, start_idx=240, end_idx=249, system_message=\"You only answer the options provided to the following questions.\", model_name=\"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame exported successfully to /Users/ezishr/Library/CloudStorage/OneDrive-UniversityofCincinnati/Undergraduate Research/Check points/Big Bench Hard/groq_tracking_five.csv!\n"
     ]
    }
   ],
   "source": [
    "df_to_csv(\"Big Bench Hard\", groq_tracking_five, file_name = \"groq_tracking_five\", output_col=\"llama_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "      <th>llama_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice, Bob, Claire, Dave, and Eve are dancers at a square dance. At the start of a song, they each have a partner: Alice is dancing with Patrick, Bob is dancing with Sam, Claire is dancing with Jamie, Dave is dancing with Lola, and Eve is dancing with Melissa.\\nThroughout the song, the dancers often trade partners. First, Dave and Eve switch partners. Then, Dave and Alice switch partners. Then, Eve and Alice switch partners. Then, Claire and Bob switch partners. Finally, Dave and Alice switch partners. At the end of the dance, Alice is dancing with\\nOptions:\\n(A) Patrick\\n(B) Sam\\n(C) Jamie\\n(D) Lola\\n(E) Melissa</td>\n",
       "      <td>(A)</td>\n",
       "      <td>(E) Melissa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alice, Bob, Claire, Dave, and Eve are dancers at a square dance. At the start of a song, they each have a partner: Alice is dancing with Ophelia, Bob is dancing with Jamie, Claire is dancing with Melissa, Dave is dancing with Rodrigo, and Eve is dancing with Patrick.\\nThroughout the song, the dancers often trade partners. First, Claire and Bob switch partners. Then, Claire and Eve switch partners. Then, Claire and Bob switch partners. Then, Eve and Dave switch partners. Finally, Claire and Alice switch partners. At the end of the dance, Alice is dancing with\\nOptions:\\n(A) Ophelia\\n(B) Jamie\\n(C) Melissa\\n(D) Rodrigo\\n(E) Patrick</td>\n",
       "      <td>(C)</td>\n",
       "      <td>(B) Jamie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alice, Bob, Claire, Dave, and Eve are dancers at a square dance. At the start of a song, they each have a partner: Alice is dancing with Jamie, Bob is dancing with Lola, Claire is dancing with Izzi, Dave is dancing with Rodrigo, and Eve is dancing with Ophelia.\\nThroughout the song, the dancers often trade partners. First, Bob and Eve switch partners. Then, Alice and Bob switch partners. Then, Dave and Alice switch partners. Then, Dave and Claire switch partners. Finally, Bob and Claire switch partners. At the end of the dance, Claire is dancing with\\nOptions:\\n(A) Jamie\\n(B) Lola\\n(C) Izzi\\n(D) Rodrigo\\n(E) Ophelia</td>\n",
       "      <td>(A)</td>\n",
       "      <td>(B) Lola</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alice, Bob, Claire, Dave, and Eve are friends and avid readers who occasionally trade books. At the start of the semester, they each buy one new book: Alice gets Catch-22, Bob gets Hound of the Baskervilles, Claire gets Frankenstein, Dave gets The Pearl, and Eve gets The Fellowship of the Ring.\\nAs the semester proceeds, they start trading around the new books. First, Eve and Alice swap books. Then, Alice and Claire swap books. Then, Alice and Bob swap books. Then, Dave and Alice swap books. Finally, Dave and Claire swap books. At the end of the semester, Dave has\\nOptions:\\n(A) Catch-22\\n(B) Hound of the Baskervilles\\n(C) Frankenstein\\n(D) The Pearl\\n(E) The Fellowship of the Ring</td>\n",
       "      <td>(E)</td>\n",
       "      <td>To find out which book Dave has at the end of the semester, let's follow the trades step by step:\\n\\n1. Eve and Alice swap books: Alice gets The Fellowship of the Ring, and Eve gets Catch-22.\\n2. Alice and Claire swap books: Alice gets Frankenstein, and Claire gets The Fellowship of the Ring.\\n3. Alice and Bob swap books: Alice gets Hound of the Baskervilles, and Bob gets Frankenstein.\\n4. Dave and Alice swap books: Dave gets Hound of the Baskervilles, and Alice gets The Pearl.\\n5. Dave and Claire swap books: Dave gets The Fellowship of the Ring (because Claire had The Fellowship of the Ring from the previous swap), and Claire gets Hound of the Baskervilles.\\n\\nSo, at the end of the semester, Dave has The Fellowship of the Ring.\\n\\nThe correct answer is:\\n(E) The Fellowship of the Ring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alice, Bob, Claire, Dave, and Eve are friends and avid readers who occasionally trade books. At the start of the semester, they each buy one new book: Alice gets Moby Dick, Bob gets Ulysses, Claire gets The Fellowship of the Ring, Dave gets Lolita, and Eve gets Catch-22.\\nAs the semester proceeds, they start trading around the new books. First, Claire and Bob swap books. Then, Claire and Dave swap books. Then, Dave and Alice swap books. Then, Dave and Bob swap books. Finally, Eve and Dave swap books. At the end of the semester, Claire has\\nOptions:\\n(A) Moby Dick\\n(B) Ulysses\\n(C) The Fellowship of the Ring\\n(D) Lolita\\n(E) Catch-22</td>\n",
       "      <td>(D)</td>\n",
       "      <td>(B) Ulysses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                input  \\\n",
       "0                                                                        Alice, Bob, Claire, Dave, and Eve are dancers at a square dance. At the start of a song, they each have a partner: Alice is dancing with Patrick, Bob is dancing with Sam, Claire is dancing with Jamie, Dave is dancing with Lola, and Eve is dancing with Melissa.\\nThroughout the song, the dancers often trade partners. First, Dave and Eve switch partners. Then, Dave and Alice switch partners. Then, Eve and Alice switch partners. Then, Claire and Bob switch partners. Finally, Dave and Alice switch partners. At the end of the dance, Alice is dancing with\\nOptions:\\n(A) Patrick\\n(B) Sam\\n(C) Jamie\\n(D) Lola\\n(E) Melissa   \n",
       "1                                                       Alice, Bob, Claire, Dave, and Eve are dancers at a square dance. At the start of a song, they each have a partner: Alice is dancing with Ophelia, Bob is dancing with Jamie, Claire is dancing with Melissa, Dave is dancing with Rodrigo, and Eve is dancing with Patrick.\\nThroughout the song, the dancers often trade partners. First, Claire and Bob switch partners. Then, Claire and Eve switch partners. Then, Claire and Bob switch partners. Then, Eve and Dave switch partners. Finally, Claire and Alice switch partners. At the end of the dance, Alice is dancing with\\nOptions:\\n(A) Ophelia\\n(B) Jamie\\n(C) Melissa\\n(D) Rodrigo\\n(E) Patrick   \n",
       "2                                                                     Alice, Bob, Claire, Dave, and Eve are dancers at a square dance. At the start of a song, they each have a partner: Alice is dancing with Jamie, Bob is dancing with Lola, Claire is dancing with Izzi, Dave is dancing with Rodrigo, and Eve is dancing with Ophelia.\\nThroughout the song, the dancers often trade partners. First, Bob and Eve switch partners. Then, Alice and Bob switch partners. Then, Dave and Alice switch partners. Then, Dave and Claire switch partners. Finally, Bob and Claire switch partners. At the end of the dance, Claire is dancing with\\nOptions:\\n(A) Jamie\\n(B) Lola\\n(C) Izzi\\n(D) Rodrigo\\n(E) Ophelia   \n",
       "3  Alice, Bob, Claire, Dave, and Eve are friends and avid readers who occasionally trade books. At the start of the semester, they each buy one new book: Alice gets Catch-22, Bob gets Hound of the Baskervilles, Claire gets Frankenstein, Dave gets The Pearl, and Eve gets The Fellowship of the Ring.\\nAs the semester proceeds, they start trading around the new books. First, Eve and Alice swap books. Then, Alice and Claire swap books. Then, Alice and Bob swap books. Then, Dave and Alice swap books. Finally, Dave and Claire swap books. At the end of the semester, Dave has\\nOptions:\\n(A) Catch-22\\n(B) Hound of the Baskervilles\\n(C) Frankenstein\\n(D) The Pearl\\n(E) The Fellowship of the Ring   \n",
       "4                                                    Alice, Bob, Claire, Dave, and Eve are friends and avid readers who occasionally trade books. At the start of the semester, they each buy one new book: Alice gets Moby Dick, Bob gets Ulysses, Claire gets The Fellowship of the Ring, Dave gets Lolita, and Eve gets Catch-22.\\nAs the semester proceeds, they start trading around the new books. First, Claire and Bob swap books. Then, Claire and Dave swap books. Then, Dave and Alice swap books. Then, Dave and Bob swap books. Finally, Eve and Dave swap books. At the end of the semester, Claire has\\nOptions:\\n(A) Moby Dick\\n(B) Ulysses\\n(C) The Fellowship of the Ring\\n(D) Lolita\\n(E) Catch-22   \n",
       "\n",
       "  target  \\\n",
       "0    (A)   \n",
       "1    (C)   \n",
       "2    (A)   \n",
       "3    (E)   \n",
       "4    (D)   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   llama_output  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   (E) Melissa  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     (B) Jamie  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      (B) Lola  \n",
       "3  To find out which book Dave has at the end of the semester, let's follow the trades step by step:\\n\\n1. Eve and Alice swap books: Alice gets The Fellowship of the Ring, and Eve gets Catch-22.\\n2. Alice and Claire swap books: Alice gets Frankenstein, and Claire gets The Fellowship of the Ring.\\n3. Alice and Bob swap books: Alice gets Hound of the Baskervilles, and Bob gets Frankenstein.\\n4. Dave and Alice swap books: Dave gets Hound of the Baskervilles, and Alice gets The Pearl.\\n5. Dave and Claire swap books: Dave gets The Fellowship of the Ring (because Claire had The Fellowship of the Ring from the previous swap), and Claire gets Hound of the Baskervilles.\\n\\nSo, at the end of the semester, Dave has The Fellowship of the Ring.\\n\\nThe correct answer is:\\n(E) The Fellowship of the Ring  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   (B) Ulysses  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_tracking_five.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Testing - tracking_shuffled_objects_seven"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_seven = Big_Bench_Json_Processor_my('Big Bench Hard', 'tracking_shuffled_objects_seven_objects.json').convert_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_seven.info()\n",
    "tracking_seven.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GEMINI Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_tracking_seven = gemini_generator(tracking_seven, \"You only answer the options provided to the following questions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_csv(df = gemini_tracking_seven, folder_name = \"Big Bench Hard\", file_name = \"gemini_tracking_seven\", output_col=\"gemini_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GROQ - llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice, Bob, Claire, Dave, Eve, Fred, and Gertrude are on the same team in a soccer match. At the start of the match, they are each assigned to a position: Alice is playing striker, Bob is playing right winger, Claire is playing left winger, Dave is playing benchwarmer, Eve is playing goalkeeper, Fred is playing center midfielder, and Gertrude is playing cheerleader.\\nAs the game progresses, pairs of players occasionally swap positions. First, Eve and Claire trade positions. Then, Gertrude and Alice trade positions. Then, Fred and Bob trade positions. Then, Dave and Fred trade positions. Then, Fred and Bob trade positions. Then, Bob and Eve trade positions. Finally, Claire and Alice trade positions. At the end of the match, Gertrude is playing\\nOptions:\\n(A) striker\\n(B) right winger\\n(C) left winger\\n(D) benchwarmer\\n(E) goalkeeper\\n(F) center midfielder\\n(G) cheerleader</td>\n",
       "      <td>(A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alice, Bob, Claire, Dave, Eve, Fred, and Gertrude are playing a game. At the start of the game, they are each holding a ball: Alice has a orange ball, Bob has a yellow ball, Claire has a brown ball, Dave has a white ball, Eve has a black ball, Fred has a red ball, and Gertrude has a purple ball.\\nAs the game progresses, pairs of players trade balls. First, Claire and Bob swap balls. Then, Claire and Dave swap balls. Then, Fred and Gertrude swap balls. Then, Eve and Claire swap balls. Then, Eve and Fred swap balls. Then, Alice and Dave swap balls. Finally, Eve and Claire swap balls. At the end of the game, Eve has the\\nOptions:\\n(A) orange ball\\n(B) yellow ball\\n(C) brown ball\\n(D) white ball\\n(E) black ball\\n(F) red ball\\n(G) purple ball</td>\n",
       "      <td>(E)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alice, Bob, Claire, Dave, Eve, Fred, and Gertrude are dancers at a square dance. At the start of a song, they each have a partner: Alice is dancing with Melissa, Bob is dancing with Ophelia, Claire is dancing with Patrick, Dave is dancing with Jamie, Eve is dancing with Lola, Fred is dancing with Helga, and Gertrude is dancing with Izzi.\\nThroughout the song, the dancers often trade partners. First, Alice and Fred switch partners. Then, Gertrude and Eve switch partners. Then, Gertrude and Alice switch partners. Then, Bob and Alice switch partners. Then, Dave and Fred switch partners. Then, Eve and Alice switch partners. Finally, Eve and Claire switch partners. At the end of the dance, Gertrude is dancing with\\nOptions:\\n(A) Melissa\\n(B) Ophelia\\n(C) Patrick\\n(D) Jamie\\n(E) Lola\\n(F) Helga\\n(G) Izzi</td>\n",
       "      <td>(F)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alice, Bob, Claire, Dave, Eve, Fred, and Gertrude are dancers at a square dance. At the start of a song, they each have a partner: Alice is dancing with Ophelia, Bob is dancing with Melissa, Claire is dancing with Jamie, Dave is dancing with Sam, Eve is dancing with Patrick, Fred is dancing with Rodrigo, and Gertrude is dancing with Karl.\\nThroughout the song, the dancers often trade partners. First, Dave and Claire switch partners. Then, Alice and Eve switch partners. Then, Eve and Bob switch partners. Then, Claire and Bob switch partners. Then, Fred and Eve switch partners. Then, Gertrude and Dave switch partners. Finally, Dave and Alice switch partners. At the end of the dance, Dave is dancing with\\nOptions:\\n(A) Ophelia\\n(B) Melissa\\n(C) Jamie\\n(D) Sam\\n(E) Patrick\\n(F) Rodrigo\\n(G) Karl</td>\n",
       "      <td>(E)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alice, Bob, Claire, Dave, Eve, Fred, and Gertrude are friends and avid readers who occasionally trade books. At the start of the semester, they each buy one new book: Alice gets Lolita, Bob gets Frankenstein, Claire gets Moby Dick, Dave gets The Pearl, Eve gets Hound of the Baskervilles, Fred gets The Fellowship of the Ring, and Gertrude gets The Odyssey.\\nAs the semester proceeds, they start trading around the new books. First, Dave and Gertrude swap books. Then, Claire and Bob swap books. Then, Alice and Dave swap books. Then, Fred and Claire swap books. Then, Dave and Fred swap books. Then, Bob and Claire swap books. Finally, Eve and Fred swap books. At the end of the semester, Eve has\\nOptions:\\n(A) Lolita\\n(B) Frankenstein\\n(C) Moby Dick\\n(D) The Pearl\\n(E) Hound of the Baskervilles\\n(F) The Fellowship of the Ring\\n(G) The Odyssey</td>\n",
       "      <td>(A)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 input  \\\n",
       "0  Alice, Bob, Claire, Dave, Eve, Fred, and Gertrude are on the same team in a soccer match. At the start of the match, they are each assigned to a position: Alice is playing striker, Bob is playing right winger, Claire is playing left winger, Dave is playing benchwarmer, Eve is playing goalkeeper, Fred is playing center midfielder, and Gertrude is playing cheerleader.\\nAs the game progresses, pairs of players occasionally swap positions. First, Eve and Claire trade positions. Then, Gertrude and Alice trade positions. Then, Fred and Bob trade positions. Then, Dave and Fred trade positions. Then, Fred and Bob trade positions. Then, Bob and Eve trade positions. Finally, Claire and Alice trade positions. At the end of the match, Gertrude is playing\\nOptions:\\n(A) striker\\n(B) right winger\\n(C) left winger\\n(D) benchwarmer\\n(E) goalkeeper\\n(F) center midfielder\\n(G) cheerleader   \n",
       "1                                                                                                                                          Alice, Bob, Claire, Dave, Eve, Fred, and Gertrude are playing a game. At the start of the game, they are each holding a ball: Alice has a orange ball, Bob has a yellow ball, Claire has a brown ball, Dave has a white ball, Eve has a black ball, Fred has a red ball, and Gertrude has a purple ball.\\nAs the game progresses, pairs of players trade balls. First, Claire and Bob swap balls. Then, Claire and Dave swap balls. Then, Fred and Gertrude swap balls. Then, Eve and Claire swap balls. Then, Eve and Fred swap balls. Then, Alice and Dave swap balls. Finally, Eve and Claire swap balls. At the end of the game, Eve has the\\nOptions:\\n(A) orange ball\\n(B) yellow ball\\n(C) brown ball\\n(D) white ball\\n(E) black ball\\n(F) red ball\\n(G) purple ball   \n",
       "2                                                                            Alice, Bob, Claire, Dave, Eve, Fred, and Gertrude are dancers at a square dance. At the start of a song, they each have a partner: Alice is dancing with Melissa, Bob is dancing with Ophelia, Claire is dancing with Patrick, Dave is dancing with Jamie, Eve is dancing with Lola, Fred is dancing with Helga, and Gertrude is dancing with Izzi.\\nThroughout the song, the dancers often trade partners. First, Alice and Fred switch partners. Then, Gertrude and Eve switch partners. Then, Gertrude and Alice switch partners. Then, Bob and Alice switch partners. Then, Dave and Fred switch partners. Then, Eve and Alice switch partners. Finally, Eve and Claire switch partners. At the end of the dance, Gertrude is dancing with\\nOptions:\\n(A) Melissa\\n(B) Ophelia\\n(C) Patrick\\n(D) Jamie\\n(E) Lola\\n(F) Helga\\n(G) Izzi   \n",
       "3                                                                                   Alice, Bob, Claire, Dave, Eve, Fred, and Gertrude are dancers at a square dance. At the start of a song, they each have a partner: Alice is dancing with Ophelia, Bob is dancing with Melissa, Claire is dancing with Jamie, Dave is dancing with Sam, Eve is dancing with Patrick, Fred is dancing with Rodrigo, and Gertrude is dancing with Karl.\\nThroughout the song, the dancers often trade partners. First, Dave and Claire switch partners. Then, Alice and Eve switch partners. Then, Eve and Bob switch partners. Then, Claire and Bob switch partners. Then, Fred and Eve switch partners. Then, Gertrude and Dave switch partners. Finally, Dave and Alice switch partners. At the end of the dance, Dave is dancing with\\nOptions:\\n(A) Ophelia\\n(B) Melissa\\n(C) Jamie\\n(D) Sam\\n(E) Patrick\\n(F) Rodrigo\\n(G) Karl   \n",
       "4                                      Alice, Bob, Claire, Dave, Eve, Fred, and Gertrude are friends and avid readers who occasionally trade books. At the start of the semester, they each buy one new book: Alice gets Lolita, Bob gets Frankenstein, Claire gets Moby Dick, Dave gets The Pearl, Eve gets Hound of the Baskervilles, Fred gets The Fellowship of the Ring, and Gertrude gets The Odyssey.\\nAs the semester proceeds, they start trading around the new books. First, Dave and Gertrude swap books. Then, Claire and Bob swap books. Then, Alice and Dave swap books. Then, Fred and Claire swap books. Then, Dave and Fred swap books. Then, Bob and Claire swap books. Finally, Eve and Fred swap books. At the end of the semester, Eve has\\nOptions:\\n(A) Lolita\\n(B) Frankenstein\\n(C) Moby Dick\\n(D) The Pearl\\n(E) Hound of the Baskervilles\\n(F) The Fellowship of the Ring\\n(G) The Odyssey   \n",
       "\n",
       "  target  \n",
       "0    (A)  \n",
       "1    (E)  \n",
       "2    (F)  \n",
       "3    (E)  \n",
       "4    (A)  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_tracking_seven = tracking_seven.copy()\n",
    "groq_tracking_seven.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice, Bob, Claire, Dave, Eve, Fred, and Gertrude are playing a game. At the start of the game, they are each holding a ball: Alice has a orange ball, Bob has a yellow ball, Claire has a brown ball, Dave has a white ball, Eve has a black ball, Fred has a red ball, and Gertrude has a purple ball.\n",
      "As the game progresses, pairs of players trade balls. First, Claire and Bob swap balls. Then, Claire and Dave swap balls. Then, Fred and Gertrude swap balls. Then, Eve and Claire swap balls. Then, Eve and Fred swap balls. Then, Alice and Dave swap balls. Finally, Eve and Claire swap balls. At the end of the game, Eve has the\n",
      "Options:\n",
      "(A) orange ball\n",
      "(B) yellow ball\n",
      "(C) brown ball\n",
      "(D) white ball\n",
      "(E) black ball\n",
      "(F) red ball\n",
      "(G) purple ball\n"
     ]
    }
   ],
   "source": [
    "print(groq_tracking_seven.loc[1, 'input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 10\n",
      "Successful requests: 10\n",
      "Total requests made: 49\n",
      "Successful requests: 3\n",
      "Total requests made: 55\n",
      "Successful requests: 1\n",
      "Total requests made: 55\n",
      "Successful requests: 1\n",
      "Total requests made: 59\n",
      "Successful requests: 1\n",
      "Total requests made: 57\n",
      "Successful requests: 1\n",
      "Total requests made: 59\n",
      "Successful requests: 1\n",
      "Total requests made: 60\n",
      "Successful requests: 0\n",
      "Total requests made: 55\n",
      "Successful requests: 1\n"
     ]
    }
   ],
   "source": [
    "groq_tracking_seven = groq_line_generate(raw_dataset = tracking_seven, output_dataset = groq_tracking_seven, start_idx=0, end_idx=9, system_message=\"You only answer A,B,C,D,E,F,G to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_seven = groq_line_generate(raw_dataset = tracking_seven, output_dataset = groq_tracking_seven, start_idx=10, end_idx=19, system_message=\"You only answer A,B,C,D,E,F,G to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_seven = groq_line_generate(raw_dataset = tracking_seven, output_dataset = groq_tracking_seven, start_idx=20, end_idx=29, system_message=\"You only answer A,B,C,D,E,F,G to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_seven = groq_line_generate(raw_dataset = tracking_seven, output_dataset = groq_tracking_seven, start_idx=30, end_idx=39, system_message=\"You only answer A,B,C,D,E,F,G to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_seven = groq_line_generate(raw_dataset = tracking_seven, output_dataset = groq_tracking_seven, start_idx=40, end_idx=49, system_message=\"You only answer A,B,C,D,E,F,G to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_seven = groq_line_generate(raw_dataset = tracking_seven, output_dataset = groq_tracking_seven, start_idx=50, end_idx=59, system_message=\"You only answer A,B,C,D,E,F,G to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_seven = groq_line_generate(raw_dataset = tracking_seven, output_dataset = groq_tracking_seven, start_idx=60, end_idx=69, system_message=\"You only answer A,B,C,D,E,F,G to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_seven = groq_line_generate(raw_dataset = tracking_seven, output_dataset = groq_tracking_seven, start_idx=70, end_idx=79, system_message=\"You only answer A,B,C,D,E,F,G to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_seven = groq_line_generate(raw_dataset = tracking_seven, output_dataset = groq_tracking_seven, start_idx=80, end_idx=89, system_message=\"You only answer A,B,C,D,E,F,G to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_seven = groq_line_generate(raw_dataset = tracking_seven, output_dataset = groq_tracking_seven, start_idx=90, end_idx=99, system_message=\"You only answer A,B,C,D,E,F,G to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_seven = groq_line_generate(raw_dataset = tracking_seven, output_dataset = groq_tracking_seven, start_idx=100, end_idx=109, system_message=\"You only answer A,B,C,D,E,F,G to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_seven = groq_line_generate(raw_dataset = tracking_seven, output_dataset = groq_tracking_seven, start_idx=110, end_idx=119, system_message=\"You only answer A,B,C,D,E,F,G to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_seven = groq_line_generate(raw_dataset = tracking_seven, output_dataset = groq_tracking_seven, start_idx=120, end_idx=129, system_message=\"You only answer A,B,C,D,E,F,G to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_seven = groq_line_generate(raw_dataset = tracking_seven, output_dataset = groq_tracking_seven, start_idx=130, end_idx=139, system_message=\"You only answer A,B,C,D,E,F,G to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_seven = groq_line_generate(raw_dataset = tracking_seven, output_dataset = groq_tracking_seven, start_idx=140, end_idx=149, system_message=\"You only answer A,B,C,D,E,F,G to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_seven = groq_line_generate(raw_dataset = tracking_seven, output_dataset = groq_tracking_seven, start_idx=150, end_idx=159, system_message=\"You only answer A,B,C,D,E,F,G to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_seven = groq_line_generate(raw_dataset = tracking_seven, output_dataset = groq_tracking_seven, start_idx=160, end_idx=169, system_message=\"You only answer A,B,C,D,E,F,G to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_seven = groq_line_generate(raw_dataset = tracking_seven, output_dataset = groq_tracking_seven, start_idx=170, end_idx=179, system_message=\"You only answer A,B,C,D,E,F,G to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_seven = groq_line_generate(raw_dataset = tracking_seven, output_dataset = groq_tracking_seven, start_idx=180, end_idx=189, system_message=\"You only answer A,B,C,D,E,F,G to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_seven = groq_line_generate(raw_dataset = tracking_seven, output_dataset = groq_tracking_seven, start_idx=190, end_idx=199, system_message=\"You only answer A,B,C,D,E,F,G to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_seven = groq_line_generate(raw_dataset = tracking_seven, output_dataset = groq_tracking_seven, start_idx=200, end_idx=209, system_message=\"You only answer A,B,C,D,E,F,G to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_seven = groq_line_generate(raw_dataset = tracking_seven, output_dataset = groq_tracking_seven, start_idx=210, end_idx=219, system_message=\"You only answer A,B,C,D,E,F,G to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_seven = groq_line_generate(raw_dataset = tracking_seven, output_dataset = groq_tracking_seven, start_idx=220, end_idx=229, system_message=\"You only answer A,B,C,D,E,F,G to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_seven = groq_line_generate(raw_dataset = tracking_seven, output_dataset = groq_tracking_seven, start_idx=230, end_idx=239, system_message=\"You only answer A,B,C,D,E,F,G to the following questions.\", model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_tracking_seven = groq_line_generate(raw_dataset = tracking_seven, output_dataset = groq_tracking_seven, start_idx=240, end_idx=249, system_message=\"You only answer A,B,C,D,E,F,G to the following questions.\", model_name=\"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   input         250 non-null    object\n",
      " 1   target        250 non-null    object\n",
      " 2   llama_output  179 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "groq_tracking_seven.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_tracking_seven.to_csv('groq_tracking_seven_NOTDONE.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Testing - tracking_shuffled_objects_three"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_three = Big_Bench_Json_Processor_my('Big Bench Hard', 'tracking_shuffled_objects_three_objects.json').convert_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   250 non-null    object\n",
      " 1   target  250 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 4.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice, Bob, and Claire are friends and avid readers who occasionally trade books. At the start of the semester, they each buy one new book: Alice gets Ulysses, Bob gets Frankenstein, and Claire gets Lolita.\\nAs the semester proceeds, they start trading around the new books. First, Claire and Bob swap books. Then, Bob and Alice swap books. Finally, Claire and Bob swap books. At the end of the semester, Bob has\\nOptions:\\n(A) Ulysses\\n(B) Frankenstein\\n(C) Lolita</td>\n",
       "      <td>(B)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alice, Bob, and Claire are friends and avid readers who occasionally trade books. At the start of the semester, they each buy one new book: Alice gets Hound of the Baskervilles, Bob gets The Odyssey, and Claire gets Catch-22.\\nAs the semester proceeds, they start trading around the new books. First, Claire and Alice swap books. Then, Bob and Claire swap books. Finally, Alice and Bob swap books. At the end of the semester, Alice has\\nOptions:\\n(A) Hound of the Baskervilles\\n(B) The Odyssey\\n(C) Catch-22</td>\n",
       "      <td>(A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alice, Bob, and Claire are friends and avid readers who occasionally trade books. At the start of the semester, they each buy one new book: Alice gets Frankenstein, Bob gets Catch-22, and Claire gets Ulysses.\\nAs the semester proceeds, they start trading around the new books. First, Bob and Alice swap books. Then, Alice and Claire swap books. Finally, Claire and Bob swap books. At the end of the semester, Alice has\\nOptions:\\n(A) Frankenstein\\n(B) Catch-22\\n(C) Ulysses</td>\n",
       "      <td>(C)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alice, Bob, and Claire are dancers at a square dance. At the start of a song, they each have a partner: Alice is dancing with Helga, Bob is dancing with Lola, and Claire is dancing with Ophelia.\\nThroughout the song, the dancers often trade partners. First, Alice and Bob switch partners. Then, Bob and Claire switch partners. Finally, Alice and Bob switch partners. At the end of the dance, Alice is dancing with\\nOptions:\\n(A) Helga\\n(B) Lola\\n(C) Ophelia</td>\n",
       "      <td>(C)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alice, Bob, and Claire are friends and avid readers who occasionally trade books. At the start of the semester, they each buy one new book: Alice gets Frankenstein, Bob gets The Odyssey, and Claire gets Lolita.\\nAs the semester proceeds, they start trading around the new books. First, Alice and Claire swap books. Then, Bob and Alice swap books. Finally, Claire and Bob swap books. At the end of the semester, Bob has\\nOptions:\\n(A) Frankenstein\\n(B) The Odyssey\\n(C) Lolita</td>\n",
       "      <td>(A)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         input  \\\n",
       "0                                            Alice, Bob, and Claire are friends and avid readers who occasionally trade books. At the start of the semester, they each buy one new book: Alice gets Ulysses, Bob gets Frankenstein, and Claire gets Lolita.\\nAs the semester proceeds, they start trading around the new books. First, Claire and Bob swap books. Then, Bob and Alice swap books. Finally, Claire and Bob swap books. At the end of the semester, Bob has\\nOptions:\\n(A) Ulysses\\n(B) Frankenstein\\n(C) Lolita   \n",
       "1  Alice, Bob, and Claire are friends and avid readers who occasionally trade books. At the start of the semester, they each buy one new book: Alice gets Hound of the Baskervilles, Bob gets The Odyssey, and Claire gets Catch-22.\\nAs the semester proceeds, they start trading around the new books. First, Claire and Alice swap books. Then, Bob and Claire swap books. Finally, Alice and Bob swap books. At the end of the semester, Alice has\\nOptions:\\n(A) Hound of the Baskervilles\\n(B) The Odyssey\\n(C) Catch-22   \n",
       "2                                    Alice, Bob, and Claire are friends and avid readers who occasionally trade books. At the start of the semester, they each buy one new book: Alice gets Frankenstein, Bob gets Catch-22, and Claire gets Ulysses.\\nAs the semester proceeds, they start trading around the new books. First, Bob and Alice swap books. Then, Alice and Claire swap books. Finally, Claire and Bob swap books. At the end of the semester, Alice has\\nOptions:\\n(A) Frankenstein\\n(B) Catch-22\\n(C) Ulysses   \n",
       "3                                                    Alice, Bob, and Claire are dancers at a square dance. At the start of a song, they each have a partner: Alice is dancing with Helga, Bob is dancing with Lola, and Claire is dancing with Ophelia.\\nThroughout the song, the dancers often trade partners. First, Alice and Bob switch partners. Then, Bob and Claire switch partners. Finally, Alice and Bob switch partners. At the end of the dance, Alice is dancing with\\nOptions:\\n(A) Helga\\n(B) Lola\\n(C) Ophelia   \n",
       "4                                  Alice, Bob, and Claire are friends and avid readers who occasionally trade books. At the start of the semester, they each buy one new book: Alice gets Frankenstein, Bob gets The Odyssey, and Claire gets Lolita.\\nAs the semester proceeds, they start trading around the new books. First, Alice and Claire swap books. Then, Bob and Alice swap books. Finally, Claire and Bob swap books. At the end of the semester, Bob has\\nOptions:\\n(A) Frankenstein\\n(B) The Odyssey\\n(C) Lolita   \n",
       "\n",
       "  target  \n",
       "0    (B)  \n",
       "1    (A)  \n",
       "2    (C)  \n",
       "3    (C)  \n",
       "4    (A)  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_three.info()\n",
    "track_three.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GEMINI Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total requests made: 340\n",
      "Successful requests: 236\n"
     ]
    }
   ],
   "source": [
    "gemini_track_three = gemini_generator(track_three, \"You only answer A, B, C to the following questions.\")\n",
    "# df_to_csv(\"Big Bench Hard\", gemini_track_three, file_name = \"gemini_track_three\", output_col=\"gemini_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   input          250 non-null    object\n",
      " 1   target         250 non-null    object\n",
      " 2   gemini_output  236 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "gemini_track_three.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "\n",
      "A\n",
      "\n",
      "A\n",
      "\n",
      "A\n",
      "\n",
      "A\n",
      "\n",
      "A\n",
      "\n",
      "A\n",
      "\n",
      "A\n",
      "\n",
      "A\n",
      "\n",
      "A\n",
      "\n",
      "A\n",
      "\n",
      "A\n",
      "\n",
      "A\n",
      "\n",
      "A\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in gemini_track_three[gemini_track_three['gemini_output'].isnull()].index.to_list():\n",
    "    model = genai.GenerativeModel(\n",
    "        model_name=\"gemini-1.5-flash\",\n",
    "        system_instruction=\"You only answer A, B, C to the following questions.\",\n",
    "    )\n",
    "\n",
    "    response = model.generate_content(track_three['input'][i])\n",
    "    print(response.text)\n",
    "    gemini_track_three.loc[i, 'gemini_output'] = response.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "      <th>gemini_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [input, target, gemini_output]\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemini_track_three[gemini_track_three['gemini_output'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Testing - web_of_lies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_of_lies = Big_Bench_Json_Processor_my('Big Bench Hard', 'web_of_lies.json').convert_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   250 non-null    object\n",
      " 1   target  250 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 4.0+ KB\n",
      "['No' 'Yes']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sherrie tells the truth. Vernell says Sherrie tells the truth. Alexis says Vernell lies. Michaela says Alexis tells the truth. Elanor says Michaela tells the truth. Does Elanor tell the truth?</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kristian lies. Sherrie says Kristian lies. Delbert says Sherrie lies. Jerry says Delbert tells the truth. Shalonda says Jerry tells the truth. Does Shalonda tell the truth?</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vina tells the truth. Helene says Vina lies. Kandi says Helene tells the truth. Jamey says Kandi lies. Ka says Jamey lies. Does Ka tell the truth?</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Christie tells the truth. Ka says Christie tells the truth. Delbert says Ka lies. Leda says Delbert tells the truth. Lorine says Leda tells the truth. Does Lorine tell the truth?</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tamika lies. Raymond says Tamika tells the truth. Willian says Raymond tells the truth. Shaunda says Willian lies. Elanor says Shaunda tells the truth. Does Elanor tell the truth?</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                               input  \\\n",
       "0   Sherrie tells the truth. Vernell says Sherrie tells the truth. Alexis says Vernell lies. Michaela says Alexis tells the truth. Elanor says Michaela tells the truth. Does Elanor tell the truth?   \n",
       "1                       Kristian lies. Sherrie says Kristian lies. Delbert says Sherrie lies. Jerry says Delbert tells the truth. Shalonda says Jerry tells the truth. Does Shalonda tell the truth?   \n",
       "2                                                 Vina tells the truth. Helene says Vina lies. Kandi says Helene tells the truth. Jamey says Kandi lies. Ka says Jamey lies. Does Ka tell the truth?   \n",
       "3                 Christie tells the truth. Ka says Christie tells the truth. Delbert says Ka lies. Leda says Delbert tells the truth. Lorine says Leda tells the truth. Does Lorine tell the truth?   \n",
       "4                Tamika lies. Raymond says Tamika tells the truth. Willian says Raymond tells the truth. Shaunda says Willian lies. Elanor says Shaunda tells the truth. Does Elanor tell the truth?   \n",
       "\n",
       "  target  \n",
       "0     No  \n",
       "1     No  \n",
       "2     No  \n",
       "3     No  \n",
       "4    Yes  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_of_lies.info()\n",
    "print(web_of_lies['target'].unique())\n",
    "web_of_lies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GEMINI Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_web_of_lies = gemini_generator(web_of_lies, \"You only answer Yes or No to the following questions.\")\n",
    "df_to_csv(\"Big Bench Hard\", gemini_web_of_lies, file_name = \"gemini_web_of_lies\", output_col=\"gemini_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GROQ - llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_web_of_lies = web_of_lies.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_web_of_lies['llama_output'] = groq_line_generate(web_of_lies, groq_web_of_lies, 0, 9, \"You only answer Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_web_of_lies['llama_output'] = groq_line_generate(web_of_lies, groq_web_of_lies, 10, 19, \"You only answer Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_web_of_lies['llama_output'] = groq_line_generate(web_of_lies, groq_web_of_lies, 20, 29, \"You only answer Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_web_of_lies['llama_output'] = groq_line_generate(web_of_lies, groq_web_of_lies, 30, 39, \"You only answer Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")\n",
    "\n",
    "groq_web_of_lies['llama_output'] = groq_line_generate(web_of_lies, groq_web_of_lies, 40, 49, \"You only answer Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")[\"llama-3.3-70b-versatile\"]\n",
    "\n",
    "groq_web_of_lies['llama_output'] = groq_line_generate(web_of_lies, groq_web_of_lies, 50, 59, \"You only answer Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")[\"llama-3.3-70b-versatile\"]\n",
    "\n",
    "groq_web_of_lies['llama_output'] = groq_line_generate(web_of_lies, groq_web_of_lies, 60, 69, \"You only answer Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")[\"llama-3.3-70b-versatile\"]\n",
    "\n",
    "groq_web_of_lies['llama_output'] = groq_line_generate(web_of_lies, groq_web_of_lies, 70, 79, \"You only answer Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")[\"llama-3.3-70b-versatile\"]\n",
    "\n",
    "groq_web_of_lies['llama_output'] = groq_line_generate(web_of_lies, groq_web_of_lies, 80, 89, \"You only answer Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")[\"llama-3.3-70b-versatile\"]\n",
    "\n",
    "groq_web_of_lies['llama_output'] = groq_line_generate(web_of_lies, groq_web_of_lies, 90, 99, \"You only answer Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")[\"llama-3.3-70b-versatile\"]\n",
    "\n",
    "groq_web_of_lies['llama_output'] = groq_line_generate(web_of_lies, groq_web_of_lies, 100, 109, \"You only answer Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")[\"llama-3.3-70b-versatile\"]\n",
    "\n",
    "groq_web_of_lies['llama_output'] = groq_line_generate(web_of_lies, groq_web_of_lies, 110, 119, \"You only answer Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")[\"llama-3.3-70b-versatile\"]\n",
    "\n",
    "groq_web_of_lies['llama_output'] = groq_line_generate(web_of_lies, groq_web_of_lies, 120, 129, \"You only answer Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")[\"llama-3.3-70b-versatile\"]\n",
    "\n",
    "groq_web_of_lies['llama_output'] = groq_line_generate(web_of_lies, groq_web_of_lies, 130, 139, \"You only answer Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")[\"llama-3.3-70b-versatile\"]\n",
    "\n",
    "groq_web_of_lies['llama_output'] = groq_line_generate(web_of_lies, groq_web_of_lies, 140, 149, \"You only answer Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")[\"llama-3.3-70b-versatile\"]\n",
    "\n",
    "groq_web_of_lies['llama_output'] = groq_line_generate(web_of_lies, groq_web_of_lies, 150, 159, \"You only answer Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")[\"llama-3.3-70b-versatile\"]\n",
    "\n",
    "groq_web_of_lies['llama_output'] = groq_line_generate(web_of_lies, groq_web_of_lies, 160, 169, \"You only answer Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")[\"llama-3.3-70b-versatile\"]\n",
    "\n",
    "groq_web_of_lies['llama_output'] = groq_line_generate(web_of_lies, groq_web_of_lies, 170, 179, \"You only answer Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")[\"llama-3.3-70b-versatile\"]\n",
    "\n",
    "groq_web_of_lies['llama_output'] = groq_line_generate(web_of_lies, groq_web_of_lies, 180, 189, \"You only answer Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")[\"llama-3.3-70b-versatile\"]\n",
    "\n",
    "groq_web_of_lies['llama_output'] = groq_line_generate(web_of_lies, groq_web_of_lies, 190, 199, \"You only answer Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")[\"llama-3.3-70b-versatile\"]\n",
    "\n",
    "groq_web_of_lies['llama_output'] = groq_line_generate(web_of_lies, groq_web_of_lies, 200, 209, \"You only answer Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")[\"llama-3.3-70b-versatile\"]\n",
    "\n",
    "groq_web_of_lies['llama_output'] = groq_line_generate(web_of_lies, groq_web_of_lies, 210, 219, \"You only answer Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")[\"llama-3.3-70b-versatile\"]\n",
    "\n",
    "groq_web_of_lies['llama_output'] = groq_line_generate(web_of_lies, groq_web_of_lies, 220, 229, \"You only answer Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")[\"llama-3.3-70b-versatile\"]\n",
    "\n",
    "groq_web_of_lies['llama_output'] = groq_line_generate(web_of_lies, groq_web_of_lies, 230, 239, \"You only answer Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")[\"llama-3.3-70b-versatile\"]\n",
    "\n",
    "groq_web_of_lies['llama_output'] = groq_line_generate(web_of_lies, groq_web_of_lies, 240, 249, \"You only answer Yes or No to the following questions.\", \"llama-3.3-70b-versatile\")[\"llama-3.3-70b-versatile\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_web_of_lies.info()\n",
    "df_to_csv(\"Big Bench Hard\", groq_web_of_lies, file_name = \"groq_web_of_lies\", output_col=\"llama_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Testing - word_sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   250 non-null    object\n",
      " 1   target  250 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 4.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sort the following words alphabetically: List: syndrome therefrom</td>\n",
       "      <td>syndrome therefrom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sort the following words alphabetically: List: thrill splutter panicking scorch same dot prod obstetric malton onus drumhead delmarva barn embezzle it&amp;t damp guru subsist entirety greene</td>\n",
       "      <td>barn damp delmarva dot drumhead embezzle entirety greene guru it&amp;t malton obstetric onus panicking prod same scorch splutter subsist thrill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sort the following words alphabetically: List: vegetate artillery harm fda doris prosody bainite incongruous monkey vivian</td>\n",
       "      <td>artillery bainite doris fda harm incongruous monkey prosody vegetate vivian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sort the following words alphabetically: List: sioux fortescue purloin percept helmsman</td>\n",
       "      <td>fortescue helmsman percept purloin sioux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sort the following words alphabetically: List: indifferent trainman bootlegging</td>\n",
       "      <td>bootlegging indifferent trainman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                        input  \\\n",
       "0                                                                                                                           Sort the following words alphabetically: List: syndrome therefrom   \n",
       "1  Sort the following words alphabetically: List: thrill splutter panicking scorch same dot prod obstetric malton onus drumhead delmarva barn embezzle it&t damp guru subsist entirety greene   \n",
       "2                                                                  Sort the following words alphabetically: List: vegetate artillery harm fda doris prosody bainite incongruous monkey vivian   \n",
       "3                                                                                                     Sort the following words alphabetically: List: sioux fortescue purloin percept helmsman   \n",
       "4                                                                                                             Sort the following words alphabetically: List: indifferent trainman bootlegging   \n",
       "\n",
       "                                                                                                                                        target  \n",
       "0                                                                                                                           syndrome therefrom  \n",
       "1  barn damp delmarva dot drumhead embezzle entirety greene guru it&t malton obstetric onus panicking prod same scorch splutter subsist thrill  \n",
       "2                                                                  artillery bainite doris fda harm incongruous monkey prosody vegetate vivian  \n",
       "3                                                                                                     fortescue helmsman percept purloin sioux  \n",
       "4                                                                                                             bootlegging indifferent trainman  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_sorting = Big_Bench_Json_Processor_my('Big Bench Hard', 'word_sorting.json').convert_df()\n",
    "word_sorting.info()\n",
    "word_sorting.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. fortescue\n",
      "2. helmsman\n",
      "3. percept\n",
      "4. purloin\n",
      "5. sioux\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    ")\n",
    "response = model.generate_content(word_sorting['input'][3])\n",
    "print(response.text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GEMINI Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total requests made: 250\n",
      "Successful requests: 250\n"
     ]
    }
   ],
   "source": [
    "gemini_word_sorting = gemini_generator(word_sorting, \"You do what the input tells.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame exported successfully to /Users/ezishr/Library/CloudStorage/OneDrive-UniversityofCincinnati/Undergraduate Research/Check points/Big Bench Hard/gemini_word_sorting.csv!\n"
     ]
    }
   ],
   "source": [
    "df_to_csv(\"Big Bench Hard\", gemini_word_sorting, file_name = \"gemini_word_sorting\", output_col=\"gemini_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Professor Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = os.listdir('../../Big Bench Hard/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_lst = [file for file in os.listdir('../../Big Bench Hard/data') if file.endswith(\"json\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('../../Big Bench Hard/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = 'output.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_credit_card_number(card_number):\n",
    "    \"\"\"\n",
    "    Checks if a credit card number is valid using Luhn's Algorithm.\n",
    "\n",
    "    Args:\n",
    "        card_number: The credit card number as a string, with or without dashes.\n",
    "\n",
    "    Returns:\n",
    "        True if the card number is valid, False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove dashes and spaces\n",
    "    card_number = card_number.replace(\"-\", \"\").replace(\" \", \"\")\n",
    "\n",
    "    # Check if the card number contains only digits and has a valid length\n",
    "    if not card_number.isdigit() or not (13 <= len(card_number) <= 19):  # Common card lengths\n",
    "        return False\n",
    "\n",
    "    # Reverse the card number\n",
    "    reversed_card_number = card_number[::-1]\n",
    "\n",
    "    # Calculate the sum according to Luhn's algorithm\n",
    "    total = 0\n",
    "    for i, digit in enumerate(reversed_card_number):\n",
    "        digit = int(digit)\n",
    "        if (i + 1) % 2 == 0:  # Double every second digit\n",
    "            doubled_digit = digit * 2\n",
    "            if doubled_digit > 9:\n",
    "                total += doubled_digit - 9  # Subtract 9 if the doubled digit is greater than 9\n",
    "            else:\n",
    "                total += doubled_digit\n",
    "        else:\n",
    "            total += digit\n",
    "\n",
    "    # Check if the total is divisible by 10\n",
    "    return total % 10 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cases \n",
    "print(check_credit_card_number(\"49927398716\")) # Valid \n",
    "print(check_credit_card_number(\"4992-7398-716\")) # Valid (with dashes) \n",
    "print(check_credit_card_number(\"4992 7398 716\")) # Valid (with spaces) \n",
    "print(check_credit_card_number(\"49927398717\")) # Invalid \n",
    "print(check_credit_card_number(\"1234567890123456\")) # Valid \n",
    "print(check_credit_card_number(\"1234-5678-9012-3457\")) # Invalid \n",
    "print(check_credit_card_number(\"abc1234567890\")) # Invalid (non-digit characters) \n",
    "print(check_credit_card_number(\"1234\")) # Invalid (too short) \n",
    "print(check_credit_card_number(\"1234567890123456789\")) # Invalid (too long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
