{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../Modules/')\n",
    "sys.path.append('../../Modules/Processors from Prof')\n",
    "from Packages import *\n",
    "from My_CSV_processor import *\n",
    "from Semantic_functions import *\n",
    "from Wordcloud import *\n",
    "\n",
    "# Import processors from Prof\n",
    "from ipynb.fs.full.Utilities import *\n",
    "from ipynb.fs.full.Json_Processor import *\n",
    "from ipynb.fs.full.CSV_Processor import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyCM-GWMhMPoBZpvlXWqKr5nKnY02OIVdf4\"\n",
    "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "farel_bench = FarelBench_CSV_Processor_my('Farel-Bench', 'farel_bench.csv').convert_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['child', 'parent', 'grandchild', 'sibling', 'grandparent',\n",
       "       'great grandchild', 'niece or nephew', 'aunt or uncle',\n",
       "       'great grandparent', 'great great grandchild',\n",
       "       'grand-niece or grand-nephew', '1st cousin',\n",
       "       'grand-aunt or grand-uncle', 'great great grandparent',\n",
       "       '3rd great grandchild', 'great grand-niece or great grand-nephew',\n",
       "       '1st cousin 1x removed', 'great grand-aunt or great grand-uncle',\n",
       "       '3rd great grandparent'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "farel_bench['topic'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "GEMINI\n",
    "\n",
    "The function is to generate Gemini answers for the given data.\n",
    "\n",
    "@params: data(initial dataframe), system_message(message for Gemini system)\n",
    "@return: sample(dataframe with gemini_output column)\n",
    "\"\"\"\n",
    "\n",
    "def gemini_generator(data, system_message):\n",
    "\n",
    "    import time\n",
    "    total_requests = 0\n",
    "    successful_requests = 0\n",
    "\n",
    "\n",
    "    model=genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    system_instruction=system_message,\n",
    "    )\n",
    "\n",
    "    sample = data.copy()\n",
    "    sample['gemini_output'] = None\n",
    "\n",
    "    for i in range(len(sample)):\n",
    "        success = False\n",
    "        retries = 3\n",
    "\n",
    "        while not success and retries > 0:\n",
    "            try:\n",
    "                total_requests += 1\n",
    "\n",
    "                # Make API request\n",
    "                response = model.generate_content(sample['input'][i])\n",
    "                # print(response.text)\n",
    "                sample.loc[i, 'gemini_output'] = response.text.strip()\n",
    "                success = True\n",
    "                successful_requests += 1\n",
    "                time.sleep(5)\n",
    "\n",
    "            except Exception as e:\n",
    "                # print(f\"Error: {e}\")\n",
    "                retries -= 1\n",
    "                time.sleep(5)\n",
    "                total_requests += 1\n",
    "\n",
    "    print(f\"Total requests made: {total_requests}\")\n",
    "    print(f\"Successful requests: {successful_requests}\")\n",
    "\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gemini_line_generator(input_df, input_idx, output_df, message):\n",
    "    model=genai.GenerativeModel(\n",
    "        model_name=\"gemini-1.5-flash\",\n",
    "        system_instruction= message,\n",
    "    )\n",
    "\n",
    "    response = model.generate_content(input_df.loc[input_idx, \"input\"])\n",
    "\n",
    "    print(response.text)\n",
    "\n",
    "    output_df.loc[input_idx,\"gemini_output\"] = response.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
    "client = Groq(\n",
    "    api_key=os.environ['GROQ_API_KEY'],\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "GROQ\n",
    "\n",
    "The function is to generate GROQ answers for the given data.\n",
    "\n",
    "@params: data(initial dataframe), system_message(message for Gemini system)\n",
    "@return: sample(dataframe with gemini_output column)\n",
    "\"\"\"\n",
    "\n",
    "def groq(data, system_message, model_name):\n",
    "\n",
    "    import time\n",
    "    total_requests = 0\n",
    "    successful_requests = 0\n",
    "    client = Groq(api_key=os.environ['GROQ_API_KEY'],)\n",
    "\n",
    "    sample = data.copy()\n",
    "    sample[model_name] = None\n",
    "\n",
    "\n",
    "    for i in range(len(sample)):\n",
    "        success = False\n",
    "        retries = 3\n",
    "\n",
    "        while not success and retries > 0:\n",
    "            try:\n",
    "                total_requests += 1\n",
    "                \n",
    "                # Make a request to the GROQ API\n",
    "                chat_completion = client.chat.completions.create(\n",
    "                    messages=[\n",
    "                        {\n",
    "                            \"role\":\"user\",\n",
    "                            \"content\": sample.loc[i, 'input']\n",
    "                        },\n",
    "                        {\n",
    "                            'role': 'system',\n",
    "                            'content': system_message\n",
    "                        }\n",
    "                    ],\n",
    "                    model = model_name\n",
    "                )\n",
    "\n",
    "                response = chat_completion.choices[0].message.content\n",
    "\n",
    "                sample.loc[i, model_name] = response.strip()\n",
    "                success = True\n",
    "                successful_requests += 1\n",
    "                # print(response)\n",
    "                time.sleep(5)\n",
    "\n",
    "            except Exception as e:\n",
    "                # print(f\"Error: {e}\")\n",
    "                retries -= 1\n",
    "                time.sleep(5)\n",
    "                total_requests += 1\n",
    "\n",
    "    print(f\"Total requests made: {total_requests}\")\n",
    "    print(f\"Successful requests: {successful_requests}\")\n",
    "\n",
    "    return sample\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "GROQ\n",
    "\n",
    "The function is to generate GROQ answers for the given data ROWS.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def groq_line_generate(raw_dataset, output_dataset, start_idx, end_idx, system_message, model_name):\n",
    "    sample = raw_dataset.loc[start_idx:end_idx, ].copy()\n",
    "    sample.reset_index(drop=True, inplace=True)\n",
    "    groq_sample = groq(sample, system_message, model_name)\n",
    "    output_dataset.loc[start_idx:end_idx, \"llama_output\"] = groq_sample[model_name].values\n",
    "    return output_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GEMINI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>child</td>\n",
       "      <td>Given the family relationships:\\n* Ralph is Anthony's parent.\\n* Albert is Ralph's parent.\\nWhat is Anthony's relationship to Ralph?\\nSelect the correct answer:\\n1. Anthony is Ralph's child.\\n2. Anthony is Ralph's parent.\\nEnclose the selected answer number in the &lt;ANSWER&gt; tag, for example: &lt;ANSWER&gt;1&lt;/ANSWER&gt;.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>child</td>\n",
       "      <td>Given the family relationships:\\n* Jessica is John's parent.\\n* John is Lawrence's parent.\\nWhat is Lawrence's relationship to John?\\nSelect the correct answer:\\n1. Lawrence is John's parent.\\n2. Lawrence is John's child.\\nEnclose the selected answer number in the &lt;ANSWER&gt; tag, for example: &lt;ANSWER&gt;1&lt;/ANSWER&gt;.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>child</td>\n",
       "      <td>Given the family relationships:\\n* Raymond is William's parent.\\n* Denise is Raymond's parent.\\nWhat is William's relationship to Raymond?\\nSelect the correct answer:\\n1. William is Raymond's parent.\\n2. William is Raymond's child.\\nEnclose the selected answer number in the &lt;ANSWER&gt; tag, for example: &lt;ANSWER&gt;1&lt;/ANSWER&gt;.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>child</td>\n",
       "      <td>Given the family relationships:\\n* Samantha is Elijah's parent.\\n* Elijah is Joshua's parent.\\nWhat is Joshua's relationship to Elijah?\\nSelect the correct answer:\\n1. Joshua is Elijah's parent.\\n2. Joshua is Elijah's child.\\nEnclose the selected answer number in the &lt;ANSWER&gt; tag, for example: &lt;ANSWER&gt;1&lt;/ANSWER&gt;.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>child</td>\n",
       "      <td>Given the family relationships:\\n* Anna is Charlotte's parent.\\n* Marie is Anna's parent.\\nWhat is Charlotte's relationship to Anna?\\nSelect the correct answer:\\n1. Charlotte is Anna's parent.\\n2. Charlotte is Anna's child.\\nEnclose the selected answer number in the &lt;ANSWER&gt; tag, for example: &lt;ANSWER&gt;1&lt;/ANSWER&gt;.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic  \\\n",
       "0  child   \n",
       "1  child   \n",
       "2  child   \n",
       "3  child   \n",
       "4  child   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                               input  \\\n",
       "0            Given the family relationships:\\n* Ralph is Anthony's parent.\\n* Albert is Ralph's parent.\\nWhat is Anthony's relationship to Ralph?\\nSelect the correct answer:\\n1. Anthony is Ralph's child.\\n2. Anthony is Ralph's parent.\\nEnclose the selected answer number in the <ANSWER> tag, for example: <ANSWER>1</ANSWER>.   \n",
       "1            Given the family relationships:\\n* Jessica is John's parent.\\n* John is Lawrence's parent.\\nWhat is Lawrence's relationship to John?\\nSelect the correct answer:\\n1. Lawrence is John's parent.\\n2. Lawrence is John's child.\\nEnclose the selected answer number in the <ANSWER> tag, for example: <ANSWER>1</ANSWER>.   \n",
       "2  Given the family relationships:\\n* Raymond is William's parent.\\n* Denise is Raymond's parent.\\nWhat is William's relationship to Raymond?\\nSelect the correct answer:\\n1. William is Raymond's parent.\\n2. William is Raymond's child.\\nEnclose the selected answer number in the <ANSWER> tag, for example: <ANSWER>1</ANSWER>.   \n",
       "3         Given the family relationships:\\n* Samantha is Elijah's parent.\\n* Elijah is Joshua's parent.\\nWhat is Joshua's relationship to Elijah?\\nSelect the correct answer:\\n1. Joshua is Elijah's parent.\\n2. Joshua is Elijah's child.\\nEnclose the selected answer number in the <ANSWER> tag, for example: <ANSWER>1</ANSWER>.   \n",
       "4          Given the family relationships:\\n* Anna is Charlotte's parent.\\n* Marie is Anna's parent.\\nWhat is Charlotte's relationship to Anna?\\nSelect the correct answer:\\n1. Charlotte is Anna's parent.\\n2. Charlotte is Anna's child.\\nEnclose the selected answer number in the <ANSWER> tag, for example: <ANSWER>1</ANSWER>.   \n",
       "\n",
       "  target  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "farel_bench.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_farel_bench = farel_bench.copy()\n",
    "gemini_farel_bench['gemini_output'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ANSWER>1</ANSWER>\n",
      "\n",
      "<ANSWER>1</ANSWER>\n",
      "\n",
      "<ANSWER>2</ANSWER>\n",
      "\n",
      "<ANSWER>2</ANSWER>\n",
      "\n",
      "<ANSWER>1</ANSWER>\n",
      "\n",
      "<ANSWER>2</ANSWER>\n",
      "\n",
      "<ANSWER>2</ANSWER>\n",
      "\n",
      "<ANSWER>1</ANSWER>\n",
      "\n",
      "<ANSWER>1</ANSWER>\n",
      "\n",
      "<ANSWER>1</ANSWER>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gemini_line_generator(farel_bench, 60, gemini_farel_bench, message='Provide answers only.')\n",
    "gemini_line_generator(farel_bench, 61, gemini_farel_bench, message='Provide answers only.')\n",
    "gemini_line_generator(farel_bench, 62, gemini_farel_bench, message='Provide answers only.')\n",
    "gemini_line_generator(farel_bench, 63, gemini_farel_bench, message='Provide answers only.')\n",
    "gemini_line_generator(farel_bench, 64, gemini_farel_bench, message='Provide answers only.')\n",
    "gemini_line_generator(farel_bench, 65, gemini_farel_bench, message='Provide answers only.')\n",
    "gemini_line_generator(farel_bench, 66, gemini_farel_bench, message='Provide answers only.')\n",
    "gemini_line_generator(farel_bench, 67, gemini_farel_bench, message='Provide answers only.')\n",
    "gemini_line_generator(farel_bench, 68, gemini_farel_bench, message='Provide answers only.')\n",
    "gemini_line_generator(farel_bench, 69, gemini_farel_bench, message='Provide answers only.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   topic          1000 non-null   object\n",
      " 1   input          1000 non-null   object\n",
      " 2   target         1000 non-null   object\n",
      " 3   gemini_output  70 non-null     object\n",
      "dtypes: object(4)\n",
      "memory usage: 31.4+ KB\n"
     ]
    }
   ],
   "source": [
    "gemini_farel_bench.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = build_text_from_questions(farel_bench, write_to = None, remove_stopwords = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = Wordcloud()\n",
    "wc.generate01(benchmark_name=\"Farel-Bench\", text=text, myStopwords = None, file_name = \"wordcloud\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Sense Disambiguation (WSD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = build_text_from_questions(farel_bench)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsd_farel_bench = auto_wsd(farel_bench)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsd_farel_bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wsd_farel_bench)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_synset_def('solution.n.02')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Role Labeling (SRL)\n",
    "Assigns roles to words in a sentence (who did what to whom, when, and how).\n",
    "Example: \"John gave Mary a book.\"\n",
    "Agent (Who?): John\n",
    "Action (What Happened?): Gave\n",
    "Recipient (To Whom?): Mary\n",
    "Object (What?): A book\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latent Semantic Analysis (LSA)\n",
    "Captures hidden relationships between words in a large text corpus using Singular Value Decomposition (SVD).\n",
    "Use Case: Document similarity, topic modeling.\n",
    "Example:\n",
    "\"Car\" and \"Automobile\" are grouped as related words based on their occurrences in different contexts.\n",
    "Libraries: scikit-learn, gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings (Word2Vec, GloVe, FastText)\n",
    "- Represents words as dense vectors, capturing meaning based on usage.\n",
    "\n",
    "- Libraries: gensim, spaCy\n",
    "\n",
    "Example:\n",
    "Word2Vec captures similarity:\n",
    "vec(\"king\") - vec(\"man\") + vec(\"woman\") ≈ vec(\"queen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
